{"meta":{"title":"King   James","subtitle":"筚路蓝缕，以启山林","description":"stay hungry foolish and curious","author":"Mr.Yi","url":"http://github.com"},"pages":[{"title":"","date":"2018-04-14T10:44:51.552Z","updated":"2018-04-14T10:44:20.596Z","comments":true,"path":"google3dffa6b302a39571.html","permalink":"http://github.com/google3dffa6b302a39571.html","excerpt":"","text":"google-site-verification: google3dffa6b302a39571.html"},{"title":"about","date":"2018-04-13T07:50:16.000Z","updated":"2018-04-13T08:20:10.135Z","comments":false,"path":"about/index.html","permalink":"http://github.com/about/index.html","excerpt":"","text":"Alongside the benefits, AI will also bring dangers, like powerful autonomous weapons, or new ways for the few to oppress the many."},{"title":"分类","date":"2018-04-13T07:29:19.000Z","updated":"2018-04-13T07:42:40.521Z","comments":false,"path":"categories/index.html","permalink":"http://github.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-04-13T07:45:37.000Z","updated":"2018-04-13T07:47:09.308Z","comments":false,"path":"tags/index.html","permalink":"http://github.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"矩阵的 SVD 分解","slug":"矩阵的-SVD-分解","date":"2018-04-15T05:49:07.000Z","updated":"2018-04-15T07:12:53.924Z","comments":true,"path":"2018/04/15/矩阵的-SVD-分解/","link":"","permalink":"http://github.com/2018/04/15/矩阵的-SVD-分解/","excerpt":"看似高大上的人工智能、机器学习，实际上都脱不开数学的支持。在这些数学内容中，最重要的无疑是两个部分：代数和概率论。我无法在博客中完整地介绍代数（特别是矩阵论）和概率论，但是将其中部分有趣又重要的内容提出来讲解，还是可行的。 此篇，我们谈谈矩阵的 SVD 分解。","text":"看似高大上的人工智能、机器学习，实际上都脱不开数学的支持。在这些数学内容中，最重要的无疑是两个部分：代数和概率论。我无法在博客中完整地介绍代数（特别是矩阵论）和概率论，但是将其中部分有趣又重要的内容提出来讲解，还是可行的。 此篇，我们谈谈矩阵的 SVD 分解。 一些矩阵知识首先我们来看一些基本的矩阵知识。 转置与共轭转置矩阵的转置（transpose）是最简单的一种矩阵变换。简单来说，若 $m\\times n$ 的矩阵 $\\mathbf M$ 的转置记为 $\\mathbf M^{\\mathsf T}$；则 $\\mathbf M^{\\mathsf T}$ 是一个 $n\\times m$ 的矩阵，并且 $\\mathbf M_{i,j} = \\mathbf M^{\\mathsf T}_{j,i}$。 因此，矩阵的转置相当于将矩阵按照主对角线翻转；同时，我们不难得出 $\\mathbf M = \\bigl(\\mathbf M^{\\mathsf T}\\bigr)^{\\mathsf T}$。 矩阵的共轭转置（conjugate transpose）可能是倒数第二简单的矩阵变换。共轭转置只需要在转置的基础上，再叠加复数的共轭即可。因此，若以 $\\mathbf M^{\\mathsf H}$ 记矩阵 $\\mathbf M$ 的共轭转置，则有 $\\mathbf M_{i,j} = \\overline{\\bigl(\\mathbf M^{\\mathsf H}\\bigr)_{j,i}}$。 酉矩阵酉矩阵（unitary matrix）是一种特殊的方阵，它满足 $$ \\mathbf U\\mathbf U^{\\mathsf H} = \\mathbf U^{\\mathsf H}\\mathbf U = I_n.$$ 不难看出，酉矩阵实际上是推广的正交矩阵（orthogonal matrix）；当酉矩阵中的元素均为实数时，酉矩阵实际就是正交矩阵。另一方面，由于 $\\mathbf M\\mathbf M^{-1} = \\mathbf M^{-1}\\mathbf M = I_n$，所以酉矩阵 $\\mathbf U$ 满足 $\\mathbf U^{-1} = \\mathbf U^{\\mathsf H}$；事实上，这是一个矩阵是酉矩阵的充分必要条件。 正规矩阵同酉矩阵一样，正规矩阵（normal matrix）也是一种特殊的方阵，它要求在矩阵乘法的意义下与它的共轭转置矩阵满足交换律。这也就是说，若矩阵 $\\mathbf M$ 满足如下条件，则称其为正规矩阵： $$\\mathbf M\\mathbf M^{\\mathsf H} = \\mathbf M^{\\mathsf H}\\mathbf M.$$ 显而易见，复系数的酉矩阵和实系数的正交矩阵都是正规矩阵。显而易见，正规矩阵并不只有酉矩阵或正交矩阵。例如说，矩阵 $\\mathbf M = \\begin{pmatrix}1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1\\end{pmatrix}$ 即是一个正规矩阵，但它显然不是酉矩阵或正交矩阵；因为 $$\\mathbf M\\mathbf M^{\\mathsf H} = \\begin{pmatrix}2 &amp; 1 &amp; 1 \\ 1 &amp; 2 &amp; 1 \\ 1 &amp; 1 &amp; 2\\end{pmatrix} = \\mathbf M^{\\mathsf H}\\mathbf M.$$ 谱定理和谱分解矩阵的对角化是线性代数中的一个重要命题。谱定理（spectral theorem）给出了方阵对角化的一个结论：若矩阵 $\\mathbf M$ 是一个正规矩阵，则存在酉矩阵 $\\mathbf U$，以及对角矩阵 $\\mathbf \\Lambda$，使得 $$\\mathbf M = \\mathbf U\\mathbf \\Lambda\\mathbf U^{\\mathsf H}.$$ 这也就是说，正规矩阵，可经由酉变换，分解为对角矩阵；这种矩阵分解的方式，称为谱分解（spectral decomposition）。 SVD 分解谱定理给出了正规矩阵分解的可能性以及分解形式。然而，对于矩阵来说，正规矩阵是要求非常高的。因此，谱定理是一个非常弱的定理，它的适用范围有限。在实际生产中，我们遇到的很多矩阵都不是正规矩阵。对于这些矩阵，谱定理就失效了。作为谱定理的泛化，SVD 分解对于原矩阵的要求就要弱得多。 SVD 分解说的是：假设 $\\mathbf M$ 是一个 $ m\\times n$ 的矩阵，其中的元素全部属于数域 $\\mathbb K$（实数域 $\\mathbb R$ 或复数域 $\\mathbb C$）。那么，存在 $m\\times m$ 的酉矩阵 $\\mathbf U$ 和 $n\\times n$ 的酉矩阵 $\\mathbf V$ 使得 $$\\mathbf M = \\mathbf U\\mathbf\\Sigma\\mathbf V^{\\mathsf H},$$ 其中 $\\mathbf\\Sigma$ 是 $m\\times n$ 的非负实数对角矩阵；并且 $\\mathbf\\Sigma$ 对角线上的元素 $\\mathbf\\Sigma_{i, i}$ 是 $\\mathbf M$ 的奇异值。一般来说，我们偏好将这些奇异值按从大到小的顺序排列，这样一来 $\\mathbf\\Sigma$ 就由 $\\mathbf M$ 唯一确定了。 另一方面，因为 $\\mathbf U$ 和 $\\mathbf V$ 都是酉矩阵，所以 $\\mathbf U$ 和 $\\mathbf V$ 的列向量分别张成 $\\mathbb K^{m}$ 和 $\\mathbb K^{n}$ 的一组标准正交基。我们将 $\\mathbf U$ 的列向量记作 $\\vec u_i,\\; 1 \\leqslant i\\leqslant m$；将 $\\mathbf V$ 的列向量记作 $\\vec v_j,\\; 1\\leqslant j\\leqslant n$；同时，将 $\\mathbf\\Sigma$ 对角线上的第 $i$ 个元素记作 $\\sigma_k,\\; 1\\leqslant k\\leqslant\\min(m,n)$。那么，SVD 分解实际可以将矩阵 $\\mathbf M$ 写作一个求和形式 $$\\mathbf M = \\sum_{i = 1}^{\\min(m, n)}\\sigma_i\\vec u_i\\vec v_i^{\\mathsf T}.$$ SVD 的计算方法了解了 SVD 的介绍和相关几何解释之后，接下来最直接想要知道的就是如何计算一个矩阵的 SVD 了。我们分成几步来探讨这个问题。 SVD 与特征值现在，假设矩阵 $\\mathbf M_{m\\times n}$ 的 SVD 分解是 $$\\mathbf M = \\mathbf U\\mathbf\\Sigma\\mathbf V^{\\mathsf H};$$ 那么，我们有 $$\\begin{aligned}\\mathbf M\\mathbf M^{\\mathsf H} &amp;{}= \\mathbf U\\mathbf\\Sigma\\mathbf V^{\\mathsf H}\\mathbf V\\mathbf\\Sigma^{\\mathsf H}\\mathbf U^{\\mathsf H} = \\mathbf U(\\mathbf\\Sigma\\mathbf\\Sigma^{\\mathsf H})\\mathbf U^{\\mathsf H}\\\\mathbf M^{\\mathsf H}\\mathbf M &amp;{}= \\mathbf V\\mathbf\\Sigma^{\\mathsf H}\\mathbf U^{\\mathsf H}\\mathbf U\\mathbf\\Sigma\\mathbf V^{\\mathsf H} = \\mathbf V(\\mathbf\\Sigma^{\\mathsf H}\\mathbf\\Sigma)\\mathbf V^{\\mathsf H}\\\\end{aligned}$$ 这也就是说，$\\mathbf U$ 的列向量（左奇异向量），是 $\\mathbf M\\mathbf M^{\\mathsf H}$ 的特征向量；同时，$\\mathbf V$ 的列向量（右奇异向量），是 $\\mathbf M^{\\mathsf H}\\mathbf M$ 的特征向量；另一方面，$\\mathbf M$ 的奇异值（$\\mathbf\\Sigma$ 的非零对角元素）则是 $\\mathbf M\\mathbf M^{\\mathsf H}$ 或者 $\\mathbf M^{\\mathsf H}\\mathbf M$ 的非零特征值的平方根。 如何计算 SVD有了这些知识，我们就能手工计算出任意矩阵的 SVD 分解了；具体来说，算法如下 计算 $\\mathbf M\\mathbf M^{\\mathsf H}$ 和 $\\mathbf M^{\\mathsf H}\\mathbf M$； 分别计算 $\\mathbf M\\mathbf M^{\\mathsf H}$ 和 $\\mathbf M^{\\mathsf H}\\mathbf M$ 的特征向量及其特征值； $\\mathbf M\\mathbf M^{\\mathsf H}$ 的特征向量组成 $\\mathbf U$；而 $\\mathbf M^{\\mathsf H}\\mathbf M$ 的特征向量组成 $\\mathbf V$； 对 $\\mathbf M\\mathbf M^{\\mathsf H}$ 和 $\\mathbf M^{\\mathsf H}\\mathbf M$ 的非零特征值求平方根，对应上述特征向量的位置，填入 $\\mathbf\\Sigma$ 的对角元。 实际计算看看现在，我们来试着计算 $\\mathbf M = \\begin{bmatrix}2 &amp; 4 \\ 1 &amp; 3 \\ 0 &amp; 0 \\ 0 &amp; 0\\end{bmatrix}$ 的奇异值分解。计算奇异值分解，需要计算 $\\mathbf M$ 与其共轭转置的左右积；这里主要以 $\\mathbf M\\mathbf M^{\\mathsf H}$ 为例。 首先，我们需要计算 $\\mathbf M\\mathbf M^{\\mathsf H}$， $$\\mathbf W = \\mathbf M\\mathbf M^{\\mathsf H} = \\begin{bmatrix}2 &amp; 4 \\ 1 &amp; 3 \\ 0 &amp; 0 \\ 0 &amp; 0\\end{bmatrix}\\begin{bmatrix}2 &amp; 1 &amp; 0 &amp; 0 \\ 4 &amp; 3 &amp; 0 &amp; 0\\end{bmatrix} = \\begin{bmatrix}20 &amp; 14 &amp; 0 &amp; 0 \\ 14 &amp; 10 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0\\end{bmatrix}.$$ 现在，我们要求 $\\mathbf W$ 的特征值与特征向量。根据定义 $\\mathbf W\\vec x = \\lambda \\vec x$；因此 $(\\mathbf W - \\lambda\\mathbf I)\\vec x = \\vec 0$。这也就是说 $$\\begin{bmatrix}20 - \\lambda &amp; 14 &amp; 0 &amp; 0 \\14 &amp; 10 - \\lambda &amp; 0 &amp; 0 \\0 &amp; 0 &amp; -\\lambda &amp; 0 \\0 &amp; 0 &amp; 0 &amp; -\\lambda\\end{bmatrix}\\vec x = \\vec 0.$$ 根据线性方程组的理论，若要该关于 $\\vec x$ 的方程有非零解，则要求系数矩阵的行列式为 0；也就是 $$\\begin{vmatrix}20 - \\lambda &amp; 14 &amp; 0 &amp; 0 \\14 &amp; 10 - \\lambda &amp; 0 &amp; 0 \\0 &amp; 0 &amp; -\\lambda &amp; 0 \\0 &amp; 0 &amp; 0 &amp; -\\lambda\\end{vmatrix} =\\begin{vmatrix}20 - \\lambda &amp; 14 \\14 &amp; 10 - \\lambda \\\\end{vmatrix}\\begin{vmatrix}-\\lambda &amp; 0 \\0 &amp; -\\lambda \\\\end{vmatrix}= 0,$$ 这也就是 $\\bigl((20 - \\lambda)(10 - \\lambda) - 196\\bigr)\\lambda^2 = 0$；解得 $\\lambda{1} = \\lambda{2} = 0$, $\\lambda{3} = 15 + \\sqrt{221} \\approx 29.866$, $\\lambda{4} = 15 - \\sqrt{221} \\approx 0.134$。将特征值代入原方程，可解得对应的特征向量；这些特征向量即作为列向量，形成矩阵 $$\\mathbf U = \\begin{bmatrix}-0.82 &amp; -0.58 &amp; 0 &amp; 0 \\ -0.58 &amp; 0.82 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}.$$ 同理可解得（注意，$\\mathbf M\\mathbf M^{\\mathsf T}$ 和 $\\mathbf M^{\\mathsf T}\\mathbf M$ 的特征值相同） $$\\mathbf V = \\begin{bmatrix}-0.40 &amp; -0.91 \\ -0.91 &amp; 0.40\\end{bmatrix}.$$ 以及 $\\mathbf\\Sigma$ 上的对角线元素由 $\\mathbf W$ 的特征值的算术平方根组成；因此有 $$\\mathbf\\Sigma = \\begin{bmatrix}5.46 &amp; 0 \\ 0 &amp; 0.37 \\ 0 &amp; 0 \\ 0 &amp; 0\\end{bmatrix}.$$ 因此我们得到矩阵 $\\mathbf M$ 的 SVD 分解（数值上做了近似）： $$\\begin{bmatrix}2 &amp; 4 \\ 1 &amp; 3 \\ 0 &amp; 0 \\ 0 &amp; 0\\end{bmatrix} \\approx \\begin{bmatrix}-0.82 &amp; -0.58 &amp; 0 &amp; 0 \\ -0.58 &amp; 0.82 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}\\begin{bmatrix}5.46 &amp; 0 \\ 0 &amp; 0.37 \\ 0 &amp; 0 \\ 0 &amp; 0\\end{bmatrix}\\begin{bmatrix}-0.40 &amp; -0.91 \\ -0.91 &amp; 0.40\\end{bmatrix}$$ 几何上的直观解释我们先来看一个例子。假设 $\\mathbf M$ 是一个 $m\\times n$ 的矩阵，而 $\\mathbf x$ 是线性空间 $\\mathbb K^n$ 中的向量，则 $$\\mathbf y = \\mathbf M\\cdot\\mathbf x$$ 是线性空间 $\\mathbb K^m$ 中的向量。这样一来，矩阵 $\\mathbb A$ 就对应了一个从 $\\mathbb K^n$ 到 $\\mathbb K^m$ 的变换 $T: \\mathbb K^n \\to \\mathbb K^m$，具体来说既是 $\\mathbf x\\mapsto \\mathbf M\\cdot\\mathbf x$。 这也就是说，在线性代数中，任意矩阵都能看做是一种变换。这样一来，我们就统一了矩阵和变换。 旋转变换和反射变换（镜像）在线性空间中进行旋转，实际是要改变向量的方向，但是不改变向量的长度和手性。现在假设矩阵 $\\mathbf M_{n\\times n}$ 是线性空间 $\\mathbf R^{n}$ 中的一个旋转变换对应的矩阵，我们来看看它应该是什么样子。 首先，我们考虑向量内积 $\\vec a\\cdot\\vec b = \\lvert\\vec a\\rvert\\lvert\\vec b\\rvert\\cos\\langle\\vec a,\\vec b\\rangle$。因为旋转不改变向量的长度，且两个向量经过相同的旋转之后，其夹角保持不变。因此，若 $\\mathbf M$ 对应一个旋转变换，那么就必须有 $$\\vec a\\cdot\\vec b = \\mathbf M\\vec a\\cdot \\mathbf M\\vec b,$$ 也就是 $$\\vec a\\cdot\\vec b^{\\mathsf T} = \\mathbf M\\vec a\\cdot (\\mathbf M\\vec b)^{\\mathsf T},$$ 这也就是说 $\\mathbf M\\mathbf M^{\\mathsf T} = \\mathbf I_{n}$，亦即 $\\mathbf M$ 是正交矩阵。 因此，对于二维的情况，$\\mathbf M$ 可以写作 $\\begin{bmatrix}\\cos\\varphi &amp; -\\sin\\varphi \\\\ \\sin\\varphi &amp; \\cos\\varphi\\end{bmatrix}$ 或 $\\begin{bmatrix}\\cos\\varphi &amp; \\sin\\varphi \\\\ \\sin\\varphi &amp; -\\cos\\varphi\\end{bmatrix}$。前者行列式为 $1$ 而后者行列式为 $-1$。既然 $\\mathbf M$ 是正交矩阵，那么它的行列式值必然是 $\\pm 1$。现在的问题是，行列式为 $1$ 和 $-1$ 究竟哪一个才是旋转？或者两个都是旋转？ 回过头，我们需要注意两件事情。其一，在旋转的定义中，我们提出了旋转保持「手性」；其二，在得出旋转矩阵是正交矩阵的过程中，我们并没有运用到「手性不变」这一特性——因为 $\\cos\\langle\\vec a,\\vec b\\rangle = \\cos\\langle\\vec b,\\vec a\\rangle$。 事实上，若 $\\mathbf M$ 的行列式为 $-1$，则该矩阵对应了一个瑕旋转——先旋转 $\\varphi$ 而后按直线 $r = k\\varphi$ 镜像。考虑 $\\varphi - \\alpha = 2\\varphi - (\\varphi + \\alpha)$，这一瑕旋转实质上就是按直线 $r = k(\\varphi / 2)$ 镜像。 因此我们说，旋转矩阵是一个行列式为 $1$ 的正定矩阵，其形式为 $$\\begin{bmatrix}\\cos\\varphi &amp; -\\sin\\varphi \\\\ \\sin\\varphi &amp; \\cos\\varphi\\end{bmatrix},$$ 表示向正方向（通常是逆时针方向）旋转 $\\varphi$。对于 $\\mathbb R^{2}$ 上的标准正交基 $\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$, $\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$，他们分别被变换为 $\\begin{bmatrix}\\cos\\varphi \\\\ \\sin\\varphi\\end{bmatrix}$ 和 $\\begin{bmatrix}-\\sin\\varphi \\\\ \\cos\\varphi\\end{bmatrix}$。 行列式为 $-1$ 的正定矩阵，其形式为 $$\\begin{bmatrix}\\cos\\varphi &amp; \\sin\\varphi \\\\ \\sin\\varphi &amp; -\\cos\\varphi\\end{bmatrix},$$ 表示按直线 $r = k(\\varphi / 2)$ 镜像。 缩放变换在线性空间中进行缩放，实质就是要让线性空间中的每一维独立地进行变换，而不受其他维度影响。这样一来，很显然，对应的矩阵应该是对角矩阵。 SVD 分解的几何解释现在回过头来看 SVD 分解 $$\\mathbf M = \\mathbf U\\mathbf\\Sigma\\mathbf V^{\\mathsf H},$$ 在实数范围内讨论，我们实质上是将一个复杂的变换 $M:\\mathbb R^{m}\\to\\mathbb R^{n}$ 分解成了三个变换：旋转/镜像 $U:\\mathbb R^{m}\\to\\mathbb R^{m}$、缩放 $\\Sigma:\\mathbb R^{m}\\to\\mathbb R^{n}$、旋转/镜像 $V:\\mathbb R^{n}\\to\\mathbb R^{n}$。 不失一般性，我们假设 $m = n$ 以及 $U$ 和 $V$ 都是旋转矩阵，则这个过程可以表示为 不难发现，$\\mathbf V^{\\mathsf H}$ 首先将（可能是退化的）单位球旋转（旋转标准正交基），而后经由 $\\mathbf \\Sigma$ 将单位圆缩放拉伸成椭圆（超空间中的超椭球），再经由 $\\mathbf U$ 将超椭球在 $\\mathbb K^{m}$ 空间中旋转。而这个超椭球的各个半轴的长度，就是矩阵 $\\mathbf M$ 的奇异值，也就是矩阵 $\\mathbf \\Sigma$ 对角线上的元素。 SVD 分解的应用在化学中，有所谓「结构决定性质、性质决定用途」的说法；这反应了一个事物由内而外的特性和人类运用事物的普遍规律。这一规律放在数学上也一样适用。 SVD 将矩阵分解成累加求和的形式，其中每一项的系数即是原矩阵的奇异值。这些奇异值，按之前的几何解释，实际上就是空间超椭球各短轴的长度。现在想象二维平面中一个非常扁的椭圆（离心率非常高），它的长轴远远长于短轴，以至于整个椭圆看起来和一条线段没有什么区别。这时候，如果将椭圆的短轴强行置为零，从直观上看，椭圆退化为线段的过程并不突兀。回到 SVD 分解当中，较大的奇异值反映了矩阵本身的主要特征和信息；较小的奇异值则如例中椭圆非常短的短轴，几乎没有体现矩阵的特征和携带的信息。因此，若我们将 SVD 分解中较小的奇异值强行置为零，则相当于丢弃了矩阵中不重要的一部分信息。 因此，SVD 分解至少有两方面作用： 分析了解原矩阵的主要特征和携带的信息（取若干最大的奇异值），这引出了主成分分析（PCA）； 丢弃忽略原矩阵的次要特征和携带的次要信息（丢弃若干较小的奇异值），这引出了信息有损压缩、矩阵低秩近似等话题。 这两方面的应用实际上是对偶的：因为，按重要度排序之后，一方面我们可以知道哪些信息（奇异值）重要，另一方面我就很自然地就可以丢弃不重要的部分。这里我们以信息的有损压缩为例。 在实际生活和工作当中，很多信息都能被表示为矩阵形式。例如：图像（参见 PIL 简明教程 - 像素操作与图像滤镜）信息，机器学习任务中巨大的特征矩阵等。此处我们循着前文的轨迹，以图像信息的形式直观地展现 SVD 分解在图形压缩中的应用。 首先让我们回顾一下曾经见过的猫咪，它长这样： 经过 SVD 分解之后，RGB 三通道的奇异值值分别形如（代码）： 123456789101112131415161718192021222324[ 8.29754663e+04 1.43568761e+04 8.28098602e+03 7.94075752e+03 6.87204550e+03 4.64118946e+03 3.07326587e+03 2.64043230e+03 2.34251575e+03 2.08293043e+03 1.81457650e+03 1.73772694e+03 1.55535238e+03 1.44987605e+03 1.28556279e+03 1.18657598e+03 1.15156737e+03 1.10588319e+03 1.04069060e+03 9.63555279e+02 ... 2.07308001e+00 2.03810704e+00 2.01670137e+00 1.89766075e+00 1.78169821e+00][ 7.52035286e+04 1.45096769e+04 1.02416708e+04 7.99187399e+03 5.55763091e+03 4.82795595e+03 3.22590281e+03 2.81678573e+03 2.47269533e+03 2.05484885e+03 1.87922653e+03 1.67558281e+03 1.55022246e+03 1.48494502e+03 1.30714569e+03 1.19338672e+03 1.17078655e+03 1.07687752e+03 1.04558020e+03 9.93807772e+02 ... 2.08166328e+00 2.03020090e+00 1.95633445e+00 1.88738236e+00 1.80539295e+00][ 7.15164941e+04 1.60372342e+04 1.20401757e+04 8.69602152e+03 5.69604800e+03 3.76913288e+03 3.48390702e+03 3.17683272e+03 2.73730517e+03 2.32005514e+03 2.08571764e+03 1.76733763e+03 1.55393096e+03 1.47436741e+03 1.39202168e+03 1.21607022e+03 1.17991116e+03 1.16377337e+03 1.01255317e+03 9.97811473e+02 ... 2.17604369e+00 2.13041080e+00 1.99837012e+00 1.88718778e+00 1.80040166e+00] 当我们从大到小开始截断，丢弃较小的奇异值并重建图像之后，我们就能得到「压缩之后」的图像了。 当只取 1 个奇异值时，重建图像如下。基本啥也看不出。 当只取 5 个奇异值时，重建图像如下。此时已经勉强能看出一只猫咪的形象了。 按照观察，在第 20 个奇异值附近，奇异值的大小有数量级的变化（从 +03 跌落至 +02）。因此，当取 20 个奇异值时，重建图像如下；此时猫咪的形象已经很清晰了。 当取用 50 个奇异值时，重建的图像和原图已经相当接近了。 类似地，我们还可以观察取用 100/200/300/400 个奇异值时，重建图像得到的结果。","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://github.com/categories/Machine-Learning/"}],"tags":[{"name":"Matrix","slug":"Matrix","permalink":"http://github.com/tags/Matrix/"},{"name":"SVD","slug":"SVD","permalink":"http://github.com/tags/SVD/"}]},{"title":"C++学习(二)","slug":"C++学习(二)","date":"2018-04-14T15:30:54.000Z","updated":"2018-04-15T07:21:33.390Z","comments":true,"path":"2018/04/14/C++学习(二)/","link":"","permalink":"http://github.com/2018/04/14/C++学习(二)/","excerpt":"整形溢出和提升 大部分 C 程序员都以为基本的整形操作都是安全的其实不然,看下面这个例子,你觉得输出结果是什么:123456789101112int main(int argc, char** argv) &#123; long i = -1; if (i &lt; sizeof(i)) &#123; printf(\"OK\\n\"); &#125; else &#123; printf(\"error\\n\"); &#125; return 0;&#125;","text":"整形溢出和提升 大部分 C 程序员都以为基本的整形操作都是安全的其实不然,看下面这个例子,你觉得输出结果是什么:123456789101112int main(int argc, char** argv) &#123; long i = -1; if (i &lt; sizeof(i)) &#123; printf(\"OK\\n\"); &#125; else &#123; printf(\"error\\n\"); &#125; return 0;&#125; 当一个变量转换成无符号整形时,i的值不再是-1,而是 size_t的最大值,因为sizeof操作返回的是一个 size_t类型的无符号数。在C99/C11标准里写道: “If the operand that has unsigned integer type has rank greater orequal to the rank of the type of the other operand, then the operandwith signed integer type is converted to the type of the operand withunsigned integer type.” 在C标准里面 size_t至少是一个 16 位的无符号整数,对于给定的架构 size_t 一般对应long,所以sizeof（int）和size_t至少相等,这就带来了可移植性的问题,C标准没有定义 short, int,long,longlong的大小,只是说明了他们的最小长度,对于 x86_64 架构,long在Linux下是64位,而在64位Windows下是32位。一般的方法是采用固定长度的类型比如定义在C99头文件stdint.h中的uint16_t,int32_t,uint_least16_t,uint_fast16_t等。 如果 int可以表示原始类型的所有值,那么这个操作数会转换成 int,否则他会转换成 unsigned int。下面这个函数在 32 位平台返回 65536,但是在 16 位系统返回 0。123456uint32_t sum()&#123; uint16_t a = 65535; uint16_t b = 1; return a+b;&#125; 对于char 类型到底是 signed 还是 unsigned 取决于硬件架构和操作系统,通常由特定平台的 ABI(Application Binary Interface) 指定,如果是 signed char,下面的代码输出-128 和-127,否则输出 128,129(x86 架构)。123char c = 128;char d = 129;printf(\"%d,%d\\n\",c,d); ##内存管理和分配 malloc 函数分配制定字节大小的内存,对象未被初始化,如果 size 是 0 取决与系统实现。malloc(0)返回一个空指针或者 unique pointer,如果 size 是表达式的运算结果,确保没有整形溢出。 “If the size of the space requested is 0, the behavior isimplementation- defined: the value returned shall be either a nullpointer or a unique pointer.”12345678size_t computed_size;if (elem_size &amp;&amp; num &gt; SIZE_MAX / elem_size) &#123; errno = ENOMEM; err(1, \"overflow\");&#125;computed_size = elem_size*num; malloc不会给分配的内存初始化，如果要对新分配的内存初始化，可以用calloc代替malloc,一般情况下给序列分配相等大小的元素时,用calloc来代替用表达式计算大小,calloc 会把内存初始化为 0。 realloc 用来对已经分配内存的对象改变大小,如果新的 size 更大,额外的空间没 有 被 初 始 化 , 如 果 提 供 给 realloc 的 指 针 是 空 指 针 , realloc 就 等 效 于malloc,如果原指针非空而 new size是0,结果依赖于操作系统的具体实现。 “In case of failure realloc shall return NULL and leave provided memoryobject intact. Thus it is important not only to check for integeroverflow of size argument, but also to correctly handle object size ifrealloc fails.” 下面这段代码可以带你领会malloc,calloc，realloc,free的用法：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;stdio.h&gt;#include &lt;stdint.h&gt;#include &lt;malloc.h&gt;#include &lt;errno.h&gt;#define VECTOR_OK 0#define VECTOR_NULL_ERROR 1#define VECTOR_SIZE_ERROR 2#define VECTOR_ALLOC_ERROR 3struct vector &#123; int *data; size_t size;&#125;;int create_vector(struct vector *vc, size_t num) &#123; if (vc == NULL) &#123; return VECTOR_NULL_ERROR; &#125; vc-&gt;data = 0; vc-&gt;size = 0; /* check for integer and SIZE_MAX overflow */ if (num == 0 || SIZE_MAX / num &lt; sizeof(int)) &#123; errno = ENOMEM; return VECTOR_SIZE_ERROR; &#125; vc-&gt;data = calloc(num, sizeof(int)); /* calloc faild */ if (vc-&gt;data == NULL) &#123; return VECTOR_ALLOC_ERROR; &#125; vc-&gt;size = num * sizeof(int); return VECTOR_OK;&#125;int grow_vector(struct vector *vc) &#123; void *newptr = 0; size_t newsize; if (vc == NULL) &#123; return VECTOR_NULL_ERROR; &#125; /* check for integer and SIZE_MAX overflow */ if (vc-&gt;size == 0 || SIZE_MAX / 2 &lt; vc-&gt;size) &#123; errno = ENOMEM; return VECTOR_SIZE_ERROR; &#125; newsize = vc-&gt;size * 2; newptr = realloc(vc-&gt;data, newsize); /* realloc faild; vector stays intact size was not changed */ if (newptr == NULL) &#123; return VECTOR_ALLOC_ERROR; &#125; /* upon success; update new address and size */ vc-&gt;data = newptr; vc-&gt;size = newsize; return VECTOR_OK;&#125; ##避免重大错误 使用未初始化的变量，C语言要求所有变量在使用之前要初始化，使用未初始化的变量会造成为定义的行为，这和C++不同，C++保证所有变量在使用之前都得到初始化，Java尽量保证变量使用前的得到初始化，如类基本数据成员会被初始化为默认值。 free错误对空指针调用 free,对不是由 malloc family 函数分配的指针调用 free,或者对已经调用 free 的指针再次调用 free。一开始初始化指针为NULL可以减少错误,GCC和Clang编译器有-Wuninitialized 选项来对未初始化的变量显示警告信息,另外不要将同一个指针用于静态变量和动态变量。 1234567&gt; char *ptr = NULL;&gt; void nullfree(void **pptr) &#123;&gt; void *ptr = *pptr;&gt; assert(ptr != NULL)&gt; free(ptr);&gt; *pptr = NULL;&gt; &#125; 3.对空指针解引用，数组越界访问 对NULL指针或者free’d内存解引用，数组越界访问，是很明显的错误，为了消除这种错误，一般的做法就是增加数组越界检查的功能，比如Java里的array就有下标检查的功能，但是这样会带来严重的性能代价，我们要修改ABI（application binary interface），让每个指针都跟随着它的范围信息，在数值计算中cost is terrible。 4.违反类型规则 把int×指针cast成float×，然后对它解引用，在C里面会引发undefined behavior，C规定这种类型的转换需要使用memset，C++里面有个reinterpret_cast函数用于无关类型之间的转换，reinterpret_cast (expression) ##防止内存泄漏 内存泄漏发生在程序不再使用的动态内存没有得到释放，这需要我们掌握动态分配对象的作用域，尤其是什么时候该调用free来释放内存，常用的集中方法如下： 在程序启动的时候分配在程序启动的时候分配需要的heap memory，程序退出时把释放的任务交给操作系统，这种方法一般适用于程序运行后马上退出的那种。 使用变长数组（VLA）如果你需要一块变长大小的空间并且作用域在函数中，变长数组可以帮到你，但是也有一个限制，一个函数中的变长数组内存大小一般不超过几百字节，这个数字C标准没有明确的定义，最好是把内存分配到栈上，在栈上允许分配的最大VLA内存是SIZE_MAX，掌握目标平台的栈大小可以有效的防止栈溢出。 使用引用计数引用计数是一个很好的管理内存的方法，特别是当你不希望自己定义的对象被复制时，每一次赋值把引用计数加1,每次失去引用就把引用计数减1,当引用计数等于0时，以为的对象已经不再需要了，我们需要释放对象占用的内存，由于C不提供自动的析构函数，我们必须手动释放内存，看一个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;#define MAX_REF_OBJ 100#define RC_ERROR -1struct mem_obj_t&#123; void *ptr; uint16_t count;&#125;;static struct mem_obj_t references[MAX_REF_OBJ];static uint16_t reference_count = 0;/* create memory object and return handle */uint16_t create(size_t size)&#123; if (reference_count &gt;= MAX_REF_OBJ) return RC_ERROR;if (size)&#123; void *ptr = calloc(1, size);if (ptr != NULL)&#123; references[reference_count].ptr = ptr; references[reference_count].count = 0; return reference_count++; &#125; &#125; return RC_ERROR;&#125;/* get memory object and increment reference counter */void* retain(uint16_t handle)&#123;if(handle &lt; reference_count &amp;&amp; handle &gt;= 0)&#123; references[handle].count++; return references[handle].ptr; &#125; else &#123; return NULL; &#125;&#125;/* decrement reference counter */void release(uint16_t handle)&#123;printf(\"release\\n\");if(handle &lt; reference_count &amp;&amp; handle &gt;= 0)&#123; struct mem_obj_t *object = &amp;references[handle]; if (object-&gt;count &lt;= 1)&#123; printf(\"released\\n\"); free(object-&gt;ptr); reference_count--;&#125; else &#123; printf(\"decremented\\n\"); object-&gt;count--; &#125; &#125;&#125; C++标准库有个auto_ptr智能指针，能够自动释放指针所指对象的内存，C++ boost库有个boost：：shared_ptr智能指针，内置引用计数，支持拷贝和赋值，看下面这个例子： “Objects of shared_ptr types have the ability of taking ownership of a pointer and share that ownership: once they take ownership, the group of owners of a pointer become responsible for its deletion when the last one of them releases that ownership.” 123456789101112131415#include &lt;boost/smart_ptr.hpp&gt;#include &lt;iostream&gt;int main()&#123; // Basic useage boost::shared_ptr&lt;int&gt; p1(new int(10)); std::cout &lt;&lt; \"ref count of p1: \" &lt;&lt; p1.use_count() &lt;&lt; std::endl; boost::shared_ptr&lt;int&gt; p2(p1); // or p2 = p1; std::cout &lt;&lt; \"ref count of p1: \" &lt;&lt; p1.use_count() &lt;&lt; std::endl; *p1 = 999; std::cout &lt;&lt; \"*p2: \" &lt;&lt; *p2 &lt;&lt; std::endl; p2.reset(); std::cout &lt;&lt; \"ref count of p1: \" &lt;&lt; p1.use_count() &lt;&lt; std::endl; return 0;&#125; 4.内存池，有利于减少内存碎片，看下面这个例子：1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;struct mem_pool_t&#123;void* ptr;//指向内存池起始地址size_t size;//内存池大小size_t used;//已用内存大小&#125;;//create memory poolstruct mem_pool_t* create_pool(size_t size)&#123;mem_pool_t* pool=calloc(1,sizeof(struct men_pool_t));if(pool!=NULL)&#123;void* mem=calloc(1,size);if(mem!=NULL)&#123;pool-&gt;ptr=mem;pool-&gt;size=size;pool-&gt;used=0;return pool; &#125; &#125;return NULL;&#125;//allocate memory from poolvoid* pool_alloc(mem_pool_t* pool,size_t size)&#123;if(pool=NULL) return NULL;size_t bytes_left=pool-&gt;size-pool-&gt;used;if(size&amp;&amp;size&lt;=bytes_left)&#123; void* mem=pool-&gt;ptr+pool-&gt;used; pool-&gt;used+=size; return mem; &#125;return NULL；&#125;／／release memory of the poolvoid pool_free(mem_pool_t* pool)&#123;if(pool!=NULL)&#123;free(pool-&gt;ptr);free(pool); &#125;&#125; 5.垃圾回收机制 引用计数采用的方法是当内存不再需要时得到手动释放，垃圾回收发生在内存分配失败或者内存到达一定的水位（watermarks），实现垃圾回收最简单的一个算法是MARK AND SWEEP算法，该算法的思路是遍历所有动态分配对象的内存，标记那些还能继续使用的，回收那些没有被标记的内存。 Java采用的垃圾回收机制就更复杂了，思路也是回收那些不再使用的内存，JAVA的垃圾回收和C++的析构函数又不一样，C++保证对象在使用之前得到初始化，对象超出作用域之后内存得到释放，而JAVA不能保证对象一定被析构。 ##指针和数组 我们一般的概念里指针和数组名是可互换的，但是在编译器里他们被不同的对待，当我们说一个对象或者表达式具有某种类型的时候我们一般是说这个对象是个左值（lvalue），当对象不是const的时候，左值是可以修改的，比如对象是复制操作符的左参数，而数组名是一个const左值，指向地一个元素的const指针，所以你不能给数组名赋值或者意图改变数组名，如果表达式是数组类型，数组名通常转换成指向地一个元素的指针。 但是也有例外，什么情况下数组名不是一个指针呢？1.当它是sizeof操作符的操作数时，返回数组占的内存字节数2.当它是取地址操作&amp;的操作数时，返回一个数组的地址 看下面这个例子：123456789101112short a[] = &#123;1,2,3&#125;;short *pa;short (*px)[];void init()&#123; pa = a; px = &amp;a; printf(\"a:%p; pa:%p; px:%p\\n\", a, pa, px); printf(\"a[1]:%i; pa[1]:%i (*px)[1]:%i\\n\", a[1], pa[1],(*px)[1]);&#125; a是一个short类型数组，pa是一个指向short类型的指针，px呢？px是一个指向数组类型的指针，在a被赋值给pa之前，他的值被转换成一个指向数组第一个元素的指针，下面那个a却没有转换，因为遇到的是&amp;操作符。数组下标a[1]等价于(a+1),和p[1]一样，也指向(p+1)，但是两者还是有区别的，a是一个数组，它实际上存储的是第一个元素的地址，所以数组a是用来定位第一个元素的，而pa不一样，它就是一个指针，不是用来定位的。再比如：1234567int a[10];int b[10];int *a;c=&amp;a[0];//c是指向数组a地一个元素的指针c=a;//a自动转换成指向第一个元素的指针，实际上是指针拷贝b=a;//非法的，你不能用赋值符把一个数组的所有元素赋给另一个数组a=c;//非法的，你不能修改const指针的值","categories":[{"name":"C++","slug":"C","permalink":"http://github.com/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://github.com/tags/C/"}]},{"title":"算法--图算法介绍","slug":"算法-图算法介绍","date":"2018-04-14T15:17:46.000Z","updated":"2018-04-15T07:19:05.038Z","comments":true,"path":"2018/04/14/算法-图算法介绍/","link":"","permalink":"http://github.com/2018/04/14/算法-图算法介绍/","excerpt":"图的定义：图（graph）由顶点（vertex）和边（edge）的集合组成，每一条边就是一个点对（v,w)。 图的种类：地图，电路图，调度图，事物，网络，程序结构 图的属性：有V个顶点的图最多有V*（V-1）/2条边","text":"图的定义：图（graph）由顶点（vertex）和边（edge）的集合组成，每一条边就是一个点对（v,w)。 图的种类：地图，电路图，调度图，事物，网络，程序结构 图的属性：有V个顶点的图最多有V*（V-1）/2条边 邻接矩阵：邻接矩阵是一个元素为bool值的VV矩阵，若图中存在一条连接顶点V和W的边，折矩阵adj[v][w]=1,否则为0。占用的空间为VV，当图是稠密时，邻接矩阵是比较合适的表达方法。 邻接表的表示对于非稠密的图，使用邻接矩阵有点浪费存储空间，可以使用邻接表，我们维护一个链表向量，给定一个顶点时，可以立即访问其链表,占用的空间为O(V+E)。 深度优先搜索深度优先搜索介绍图的深度优先搜索(Depth First Search)，和树的先序遍历比较类似。 它的思想：假设初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。 显然，深度优先搜索是一个递归的过程。 深度优先搜索图解无向图的深度优先搜索下面以”无向图”为例，来对深度优先搜索进行演示。对上面的图G1进行深度优先遍历，从顶点A开始。 第1步：访问A。 第2步：访问(A的邻接点)C。 在第1步访问A之后，接下来应该访问的是A的邻接点，即”C,D,F”中的一个。但在本文的实现中，顶点ABCDEFG是按照顺序存储，C在”D和F”的前面，因此，先访问C。 第3步：访问(C的邻接点)B。 在第2步访问C之后，接下来应该访问C的邻接点，即”B和D”中一个(A已经被访问过，就不算在内)。而由于B在D之前，先访问B。 第4步：访问(C的邻接点)D。 在第3步访问了C的邻接点B之后，B没有未被访问的邻接点；因此，返回到访问C的另一个邻接点D。 第5步：访问(A的邻接点)F。 前面已经访问了A，并且访问完了”A的邻接点B的所有邻接点(包括递归的邻接点在内)”；因此，此时返回到访问A的另一个邻接点F。 第6步：访问(F的邻接点)G。 第7步：访问(G的邻接点)E。 因此访问顺序是：A -&gt; C -&gt; B -&gt; D -&gt; F -&gt; G -&gt; E 有向图的深度优先搜索下面以”有向图”为例，来对深度优先搜索进行演示。对上面的图G2进行深度优先遍历，从顶点A开始。 第1步：访问A。 第2步：访问B。 在访问了A之后，接下来应该访问的是A的出边的另一个顶点，即顶点B。 第3步：访问C。 在访问了B之后，接下来应该访问的是B的出边的另一个顶点，即顶点C,E,F。在本文实现的图中，顶点ABCDEFG按照顺序存储，因此先访问C。 第4步：访问E。 接下来访问C的出边的另一个顶点，即顶点E。 第5步：访问D。 接下来访问E的出边的另一个顶点，即顶点B,D。顶点B已经被访问过，因此访问顶点D。 第6步：访问F。 接下应该回溯”访问A的出边的另一个顶点F”。 第7步：访问G。 因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; D -&gt; F -&gt; G 广度优先搜索广度优先搜索介绍广度优先搜索算法(Breadth First Search)，又称为”宽度优先搜索”或”横向优先搜索”，简称BFS。 它的思想是：从图中某顶点v出发，在访问了v之后依次访问v的各个未曾访问过的邻接点，然后分别从这些邻接点出发依次访问它们的邻接点，并使得“先被访问的顶点的邻接点先于后被访问的顶点的邻接点被访问，直至图中所有已被访问的顶点的邻接点都被访问到。如果此时图中尚有顶点未被访问，则需要另选一个未曾被访问过的顶点作为新的起始点，重复上述过程，直至图中所有顶点都被访问到为止。 换句话说，广度优先搜索遍历图的过程是以v为起点，由近至远，依次访问和v有路径相通且路径长度为1,2…的顶点。 广度优先搜索图解无向图的广度优先搜索下面以”无向图”为例，来对广度优先搜索进行演示。还是以上面的图G1为例进行说明。 第1步：访问A。 第2步：依次访问C,D,F。 在访问了A之后，接下来访问A的邻接点。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，C在”D和F”的前面，因此，先访问C。再访问完C之后，再依次访问D,F。 第3步：依次访问B,G。 在第2步访问完C,D,F之后，再依次访问它们的邻接点。首先访问C的邻接点B，再访问F的邻接点G。 第4步：访问E。 在第3步访问完B,G之后，再依次访问它们的邻接点。只有G有邻接点E，因此访问G的邻接点E。 因此访问顺序是：A -&gt; C -&gt; D -&gt; F -&gt; B -&gt; G -&gt; E 有向图的广度优先搜索下面以”有向图”为例，来对广度优先搜索进行演示。还是以上面的图G2为例进行说明。 第1步：访问A。 第2步：访问B。 第3步：依次访问C,E,F。 在访问了B之后，接下来访问B的出边的另一个顶点，即C,E,F。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，因此会先访问C，再依次访问E,F。 第4步：依次访问D,G。 在访问完C,E,F之后，再依次访问它们的出边的另一个顶点。还是按照C,E,F的顺序访问，C的已经全部访问过了，那么就只剩下E,F；先访问E的邻接点D，再访问F的邻接点G。 因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; F -&gt; D -&gt; G 搜索算法的源码1.邻接矩阵表示的”无向图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318 /** * C++: 邻接矩阵表示的\"无向图(Matrix Undirected Graph)\" * * @author LippiOuYang * @date 2013/04/19 */ #include &lt;iomanip&gt; #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; #define MAX 100 class MatrixUDG &#123; private: char mVexs[MAX]; // 顶点集合 int mVexNum; // 顶点数 int mEdgNum; // 边数 int mMatrix[MAX][MAX]; // 邻接矩阵 public: // 创建图(自己输入数据) MatrixUDG(); // 创建图(用已提供的矩阵) MatrixUDG(char vexs[], int vlen, char edges[][2], int elen); ~MatrixUDG(); // 深度优先搜索遍历图 void DFS(); // 广度优先搜索（类似于树的层次遍历） void BFS(); // 打印矩阵队列图 void print(); private: // 读取一个输入字符 char readChar(); // 返回ch在mMatrix矩阵中的位置 int getPosition(char ch); // 返回顶点v的第一个邻接顶点的索引，失败则返回-1 int firstVertex(int v); // 返回顶点v相对于w的下一个邻接顶点的索引，失败则返回-1 int nextVertex(int v, int w); // 深度优先搜索遍历图的递归实现 void DFS(int i, int *visited);&#125;;/* * 创建图(自己输入数据) */MatrixUDG::MatrixUDG()&#123; char c1, c2; int i, p1, p2; // 输入\"顶点数\"和\"边数\" cout &lt;&lt; \"input vertex number: \"; cin &gt;&gt; mVexNum; cout &lt;&lt; \"input edge number: \"; cin &gt;&gt; mEdgNum; if ( mVexNum &lt; 1 || mEdgNum &lt; 1 || (mEdgNum &gt; (mVexNum * (mVexNum-1)))) &#123; cout &lt;&lt; \"input error: invalid parameters!\" &lt;&lt; endl; return ; &#125; // 初始化\"顶点\" for (i = 0; i &lt; mVexNum; i++) &#123; cout &lt;&lt; \"vertex(\" &lt;&lt; i &lt;&lt; \"): \"; mVexs[i] = readChar(); &#125; // 初始化\"边\" for (i = 0; i &lt; mEdgNum; i++) &#123; // 读取边的起始顶点和结束顶点 cout &lt;&lt; \"edge(\" &lt;&lt; i &lt;&lt; \"): \"; c1 = readChar(); c2 = readChar(); p1 = getPosition(c1); p2 = getPosition(c2); if (p1==-1 || p2==-1) &#123; cout &lt;&lt; \"input error: invalid edge!\" &lt;&lt; endl; return ; &#125; mMatrix[p1][p2] = 1; mMatrix[p2][p1] = 1; &#125;&#125;/* * 创建图(用已提供的矩阵) * * 参数说明： * vexs -- 顶点数组 * vlen -- 顶点数组的长度 * edges -- 边数组 * elen -- 边数组的长度 */MatrixUDG::MatrixUDG(char vexs[], int vlen, char edges[][2], int elen)&#123; int i, p1, p2; // 初始化\"顶点数\"和\"边数\" mVexNum = vlen; mEdgNum = elen; // 初始化\"顶点\" for (i = 0; i &lt; mVexNum; i++) mVexs[i] = vexs[i]; // 初始化\"边\" for (i = 0; i &lt; mEdgNum; i++) &#123; // 读取边的起始顶点和结束顶点 p1 = getPosition(edges[i][0]); p2 = getPosition(edges[i][1]); mMatrix[p1][p2] = 1; mMatrix[p2][p1] = 1; &#125;&#125;/* * 析构函数 */MatrixUDG::~MatrixUDG()&#123;&#125;/* * 返回ch在mMatrix矩阵中的位置 */int MatrixUDG::getPosition(char ch)&#123; int i; for(i=0; i&lt;mVexNum; i++) if(mVexs[i]==ch) return i; return -1;&#125;/* * 读取一个输入字符 */char MatrixUDG::readChar()&#123; char ch; do &#123; cin &gt;&gt; ch; &#125; while(!((ch&gt;='a'&amp;&amp;ch&lt;='z') || (ch&gt;='A'&amp;&amp;ch&lt;='Z'))); return ch;&#125;/* * 返回顶点v的第一个邻接顶点的索引，失败则返回-1 */int MatrixUDG::firstVertex(int v)&#123; int i; if (v&lt;0 || v&gt;(mVexNum-1)) return -1; for (i = 0; i &lt; mVexNum; i++) if (mMatrix[v][i] == 1) return i; return -1;&#125;/* * 返回顶点v相对于w的下一个邻接顶点的索引，失败则返回-1 */int MatrixUDG::nextVertex(int v, int w)&#123; int i; if (v&lt;0 || v&gt;(mVexNum-1) || w&lt;0 || w&gt;(mVexNum-1)) return -1; for (i = w + 1; i &lt; mVexNum; i++) if (mMatrix[v][i] == 1) return i; return -1;&#125;/* * 深度优先搜索遍历图的递归实现 */void MatrixUDG::DFS(int i, int *visited)&#123; int w; visited[i] = 1; cout &lt;&lt; mVexs[i] &lt;&lt; \" \"; // 遍历该顶点的所有邻接顶点。若是没有访问过，那么继续往下走 for (w = firstVertex(i); w &gt;= 0; w = nextVertex(i, w)) &#123; if (!visited[w]) DFS(w, visited); &#125;&#125;/* * 深度优先搜索遍历图 */void MatrixUDG::DFS()&#123; int i; int visited[MAX]; // 顶点访问标记 // 初始化所有顶点都没有被访问 for (i = 0; i &lt; mVexNum; i++) visited[i] = 0; cout &lt;&lt; \"DFS: \"; for (i = 0; i &lt; mVexNum; i++) &#123; //printf(\"\\n== LOOP(%d)\\n\", i); if (!visited[i]) DFS(i, visited); &#125; cout &lt;&lt; endl;&#125;/* * 广度优先搜索（类似于树的层次遍历） */void MatrixUDG::BFS()&#123; int head = 0; int rear = 0; int queue[MAX]; // 辅组队列 int visited[MAX]; // 顶点访问标记 int i, j, k; for (i = 0; i &lt; mVexNum; i++) visited[i] = 0; cout &lt;&lt; \"BFS: \"; for (i = 0; i &lt; mVexNum; i++) &#123; if (!visited[i]) &#123; visited[i] = 1; cout &lt;&lt; mVexs[i] &lt;&lt; \" \"; queue[rear++] = i; // 入队列 &#125; while (head != rear) &#123; j = queue[head++]; // 出队列 for (k = firstVertex(j); k &gt;= 0; k = nextVertex(j, k)) //k是为访问的邻接顶点 &#123; if (!visited[k]) &#123; visited[k] = 1; cout &lt;&lt; mVexs[k] &lt;&lt; \" \"; queue[rear++] = k; &#125; &#125; &#125; &#125; cout &lt;&lt; endl;&#125;/* * 打印矩阵队列图 */void MatrixUDG::print()&#123; int i,j; cout &lt;&lt; \"Martix Graph:\" &lt;&lt; endl; for (i = 0; i &lt; mVexNum; i++) &#123; for (j = 0; j &lt; mVexNum; j++) cout &lt;&lt; mMatrix[i][j] &lt;&lt; \" \"; cout &lt;&lt; endl; &#125;&#125;int main()&#123; char vexs[] = &#123;'A', 'B', 'C', 'D', 'E', 'F', 'G'&#125;; char edges[][2] = &#123; &#123;'A', 'C'&#125;, &#123;'A', 'D'&#125;, &#123;'A', 'F'&#125;, &#123;'B', 'C'&#125;, &#123;'C', 'D'&#125;, &#123;'E', 'G'&#125;, &#123;'F', 'G'&#125;&#125;; int vlen = sizeof(vexs)/sizeof(vexs[0]); int elen = sizeof(edges)/sizeof(edges[0]); MatrixUDG* pG; // 自定义\"图\"(输入矩阵队列) //pG = new MatrixUDG(); // 采用已有的\"图\" pG = new MatrixUDG(vexs, vlen, edges, elen); pG-&gt;print(); // 打印图 pG-&gt;DFS(); // 深度优先遍历 pG-&gt;BFS(); // 广度优先遍历 return 0;&#125; 2.邻接表表示的”无向图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345/** * C++: 邻接表表示的\"无向图(List Undirected Graph)\" * * @author LippiOuYang * @date 2013/04/19 */ #include &lt;iomanip&gt; #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std;#define MAX 100// 邻接表class ListUDG&#123; private: // 内部类 // 邻接表中表对应的链表的顶点 class ENode &#123; public: int ivex; // 该边所指向的顶点的位置 ENode *nextEdge; // 指向下一条弧的指针 &#125;; // 邻接表中表的顶点 class VNode &#123; public: char data; // 顶点信息 ENode *firstEdge; // 指向第一条依附该顶点的弧 &#125;; private: // 私有成员 int mVexNum; // 图的顶点的数目 int mEdgNum; // 图的边的数目 VNode mVexs[MAX]; public: // 创建邻接表对应的图(自己输入) ListUDG(); // 创建邻接表对应的图(用已提供的数据) ListUDG(char vexs[], int vlen, char edges[][2], int elen); ~ListUDG(); // 深度优先搜索遍历图 void DFS(); // 广度优先搜索（类似于树的层次遍历） void BFS(); // 打印邻接表图 void print(); private: // 读取一个输入字符 char readChar(); // 返回ch的位置 int getPosition(char ch); // 深度优先搜索遍历图的递归实现 void DFS(int i, int *visited); // 将node节点链接到list的最后 void linkLast(ENode *list, ENode *node);&#125;;/* * 创建邻接表对应的图(自己输入) */ListUDG::ListUDG()&#123; char c1, c2; int v, e; int i, p1, p2; ENode *node1, *node2; // 输入\"顶点数\"和\"边数\" cout &lt;&lt; \"input vertex number: \"; cin &gt;&gt; mVexNum; cout &lt;&lt; \"input edge number: \"; cin &gt;&gt; mEdgNum; if ( mVexNum &lt; 1 || mEdgNum &lt; 1 || (mEdgNum &gt; (mVexNum * (mVexNum-1)))) &#123; cout &lt;&lt; \"input error: invalid parameters!\" &lt;&lt; endl; return ; &#125; // 初始化\"邻接表\"的顶点 for(i=0; i&lt;mVexNum; i++) &#123; cout &lt;&lt; \"vertex(\" &lt;&lt; i &lt;&lt; \"): \"; mVexs[i].data = readChar(); mVexs[i].firstEdge = NULL; &#125; // 初始化\"邻接表\"的边 for(i=0; i&lt;mEdgNum; i++) &#123; // 读取边的起始顶点和结束顶点 cout &lt;&lt; \"edge(\" &lt;&lt; i &lt;&lt; \"): \"; c1 = readChar(); c2 = readChar(); p1 = getPosition(c1); p2 = getPosition(c2); // 初始化node1 node1 = new ENode(); node1-&gt;ivex = p2; // 将node1链接到\"p1所在链表的末尾\" if(mVexs[p1].firstEdge == NULL) mVexs[p1].firstEdge = node1; else linkLast(mVexs[p1].firstEdge, node1); // 初始化node2 node2 = new ENode(); node2-&gt;ivex = p1; // 将node2链接到\"p2所在链表的末尾\" if(mVexs[p2].firstEdge == NULL) mVexs[p2].firstEdge = node2; else linkLast(mVexs[p2].firstEdge, node2); &#125;&#125;/* * 创建邻接表对应的图(用已提供的数据) */ListUDG::ListUDG(char vexs[], int vlen, char edges[][2], int elen)&#123; char c1, c2; int i, p1, p2; ENode *node1, *node2; // 初始化\"顶点数\"和\"边数\" mVexNum = vlen; mEdgNum = elen; // 初始化\"邻接表\"的顶点 for(i=0; i&lt;mVexNum; i++) &#123; mVexs[i].data = vexs[i]; mVexs[i].firstEdge = NULL; &#125; // 初始化\"邻接表\"的边 for(i=0; i&lt;mEdgNum; i++) &#123; // 读取边的起始顶点和结束顶点 c1 = edges[i][0]; c2 = edges[i][1]; p1 = getPosition(c1); p2 = getPosition(c2); // 初始化node1 node1 = new ENode(); node1-&gt;ivex = p2; // 将node1链接到\"p1所在链表的末尾\" if(mVexs[p1].firstEdge == NULL) mVexs[p1].firstEdge = node1; else linkLast(mVexs[p1].firstEdge, node1); // 初始化node2 node2 = new ENode(); node2-&gt;ivex = p1; // 将node2链接到\"p2所在链表的末尾\" if(mVexs[p2].firstEdge == NULL) mVexs[p2].firstEdge = node2; else linkLast(mVexs[p2].firstEdge, node2); &#125;&#125;/* * 析构函数 */ListUDG::~ListUDG()&#123;&#125;/* * 将node节点链接到list的最后 */void ListUDG::linkLast(ENode *list, ENode *node)&#123; ENode *p = list; while(p-&gt;nextEdge) p = p-&gt;nextEdge; p-&gt;nextEdge = node;&#125;/* * 返回ch的位置 */int ListUDG::getPosition(char ch)&#123; int i; for(i=0; i&lt;mVexNum; i++) if(mVexs[i].data==ch) return i; return -1;&#125;/* * 读取一个输入字符 */char ListUDG::readChar()&#123; char ch; do &#123; cin &gt;&gt; ch; &#125; while(!((ch&gt;='a'&amp;&amp;ch&lt;='z') || (ch&gt;='A'&amp;&amp;ch&lt;='Z'))); return ch;&#125;/* * 深度优先搜索遍历图的递归实现 */void ListUDG::DFS(int i, int *visited)&#123; ENode *node; visited[i] = 1; cout &lt;&lt; mVexs[i].data &lt;&lt; \" \"; node = mVexs[i].firstEdge; while (node != NULL) &#123; if (!visited[node-&gt;ivex]) DFS(node-&gt;ivex, visited); node = node-&gt;nextEdge; &#125;&#125;/* * 深度优先搜索遍历图 */void ListUDG::DFS()&#123; int i; int visited[MAX]; // 顶点访问标记 // 初始化所有顶点都没有被访问 for (i = 0; i &lt; mVexNum; i++) visited[i] = 0; cout &lt;&lt; \"DFS: \"; for (i = 0; i &lt; mVexNum; i++) &#123; if (!visited[i]) DFS(i, visited); &#125; cout &lt;&lt; endl;&#125;/* * 广度优先搜索（类似于树的层次遍历） */void ListUDG::BFS()&#123; int head = 0; int rear = 0; int queue[MAX]; // 辅组队列 int visited[MAX]; // 顶点访问标记 int i, j, k; ENode *node; for (i = 0; i &lt; mVexNum; i++) visited[i] = 0; cout &lt;&lt; \"BFS: \"; for (i = 0; i &lt; mVexNum; i++) &#123; if (!visited[i]) &#123; visited[i] = 1; cout &lt;&lt; mVexs[i].data &lt;&lt; \" \"; queue[rear++] = i; // 入队列 &#125; while (head != rear) &#123; j = queue[head++]; // 出队列 node = mVexs[j].firstEdge; while (node != NULL) &#123; k = node-&gt;ivex; if (!visited[k]) &#123; visited[k] = 1; cout &lt;&lt; mVexs[k].data &lt;&lt; \" \"; queue[rear++] = k; &#125; node = node-&gt;nextEdge; &#125; &#125; &#125; cout &lt;&lt; endl;&#125;/* * 打印邻接表图 */void ListUDG::print()&#123; int i,j; ENode *node; cout &lt;&lt; \"List Graph:\" &lt;&lt; endl; for (i = 0; i &lt; mVexNum; i++) &#123; cout &lt;&lt; i &lt;&lt; \"(\" &lt;&lt; mVexs[i].data &lt;&lt; \"): \"; node = mVexs[i].firstEdge; while (node != NULL) &#123; cout &lt;&lt; node-&gt;ivex &lt;&lt; \"(\" &lt;&lt; mVexs[node-&gt;ivex].data &lt;&lt; \") \"; node = node-&gt;nextEdge; &#125; cout &lt;&lt; endl; &#125;&#125;int main()&#123; char vexs[] = &#123;'A', 'B', 'C', 'D', 'E', 'F', 'G'&#125;; char edges[][2] = &#123; &#123;'A', 'C'&#125;, &#123;'A', 'D'&#125;, &#123;'A', 'F'&#125;, &#123;'B', 'C'&#125;, &#123;'C', 'D'&#125;, &#123;'E', 'G'&#125;, &#123;'F', 'G'&#125;&#125;; int vlen = sizeof(vexs)/sizeof(vexs[0]); int elen = sizeof(edges)/sizeof(edges[0]); ListUDG* pG; // 自定义\"图\"(输入矩阵队列) //pG = new ListUDG(); // 采用已有的\"图\" pG = new ListUDG(vexs, vlen, edges, elen); pG-&gt;print(); // 打印图 pG-&gt;DFS(); // 深度优先遍历 pG-&gt;BFS(); // 广度优先遍历 return 0;&#125; 迪杰斯特拉算法迪杰斯特拉(Dijkstra)算法是典型最短路径算法，用于计算一个节点到其他节点的最短路径。它的主要特点是以起始点为中心向外层层扩展(广度优先搜索思想)，直到扩展到终点为止。 基本思想 通过Dijkstra计算图G中的最短路径时，需要指定起点s(即从顶点s开始计算)。 此外，引进两个集合S和U。S的作用是记录已求出最短路径的顶点(以及相应的最短路径长度)，而U则是记录还未求出最短路径的顶点(以及该顶点到起点s的距离)。 初始时，S中只有起点s；U中是除s之外的顶点，并且U中顶点的路径是”起点s到该顶点的路径”。然后，从U中找出路径最短的顶点，并将其加入到S中；接着，更新U中的顶点和顶点对应的路径。 然后，再从U中找出路径最短的顶点，并将其加入到S中；接着，更新U中的顶点和顶点对应的路径。 … 重复该操作，直到遍历完所有顶点。 操作步骤 (1)初始时，S只包含起点s；U包含除s外的其他顶点，且U中顶点的距离为”起点s到该顶点的距离”[例如，U中顶点v的距离为(s,v)的长度，然后s和v不相邻，则v的距离为∞]。 (2) 从U中选出”距离最短的顶点k”，并将顶点k加入到S中；同时，从U中移除顶点k。 (3)更新U中各个顶点到起点s的距离。之所以更新U中顶点的距离，是由于上一步中确定了k是求出最短路径的顶点，从而可以利用k来更新其它顶点的距离；例如，(s,v)的距离可能大于(s,k)+(k,v)的距离。 (4) 重复步骤(2)和(3)，直到遍历完所有顶点。 单纯的看上面的理论可能比较难以理解，下面通过实例来对该算法进行说明。 5.3迪杰斯特拉算法图解以上图G4为例，来对迪杰斯特拉进行算法演示(以第4个顶点D为起点)。 初始状态：S是已计算出最短路径的顶点集合，U是未计算除最短路径的顶点的集合！ 第1步：将顶点D加入到S中。 此时，S={D(0)}, U={A(∞),B(∞),C(3),E(4),F(∞),G(∞)}。 注:C(3)表示C到起点D的距离是3。 第2步：将顶点C加入到S中。 上一步操作之后，U中顶点C到起点D的距离最短；因此，将C加入到S中，同时更新U中顶点的距离。以顶点F为例，之前F到D的距离为∞；但是将C加入到S之后，F到D的距离为9=(F,C)+(C,D)。 此时，S={D(0),C(3)}, U={A(∞),B(23),E(4),F(9),G(∞)}。 第3步：将顶点E加入到S中。 上一步操作之后，U中顶点E到起点D的距离最短；因此，将E加入到S中，同时更新U中顶点的距离。还是以顶点F为例，之前F到D的距离为9；但是将E加入到S之后，F到D的距离为6=(F,E)+(E,D)。 此时，S={D(0),C(3),E(4)}, U={A(∞),B(23),F(6),G(12)}。 第4步：将顶点F加入到S中。 此时，S={D(0),C(3),E(4),F(6)}, U={A(22),B(13),G(12)}。 第5步：将顶点G加入到S中。 此时，S={D(0),C(3),E(4),F(6),G(12)}, U={A(22),B(13)}。 第6步：将顶点B加入到S中。 此时，S={D(0),C(3),E(4),F(6),G(12),B(13)}, U={A(22)}。 第7步：将顶点A加入到S中。 此时，S={D(0),C(3),E(4),F(6),G(12),B(13),A(22)}。 此时，起点D到各个顶点的最短距离就计算出来了：A(22) B(13) C(3) D(0) E(4) F(6) G(12)。 代码 本文以”邻接矩阵”为例对迪杰斯特拉算法进行说明， 基本定义// 邻接矩阵 typedef struct _graph { char vexs[MAX]; // 顶点集合 int vexnum; // 顶点数 int edgnum; // 边数 int matrix[MAX][MAX]; // 邻接矩阵 }Graph, *PGraph; // 边的结构体 typedef struct _EdgeData { char start; // 边的起点 char end; // 边的终点 int weight; // 边的权重 }EData; Graph是邻接矩阵对应的结构体。vexs用于保存顶点，vexnum是顶点数，edgnum是边数；matrix则是用于保存矩阵信息的二维数组。例如，matrix[i][j]=1，则表示”顶点i(即vexs[i])”和”顶点j(即vexs[j])”是邻接点；matrix[i][j]=0，则表示它们不是邻接点。EData是邻接矩阵边对应的结构体。 迪杰斯特拉算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/* * Dijkstra最短路径。 * 即，统计图(G)中\"顶点vs\"到其它各个顶点的最短路径。 * * 参数说明： * G -- 图 * vs -- 起始顶点(start vertex)。即计算\"顶点vs\"到其它顶点的最短路径。 * prev -- 前驱顶点数组。即，prev[i]的值是\"顶点vs\"到\"顶点i\"的最短路径所经历的全部顶点中，位于\"顶点i\"之前的那个顶点。 * dist -- 长度数组。即，dist[i]是\"顶点vs\"到\"顶点i\"的最短路径的长度。 */ void dijkstra(Graph G, int vs, int prev[], int dist[]) &#123; int i,j,k; int min; int tmp; int flag[MAX]; // flag[i]=1表示\"顶点vs\"到\"顶点i\"的最短路径已成功获取。 // 初始化 for (i = 0; i &lt; G.vexnum; i++) &#123; flag[i] = 0; // 顶点i的最短路径还没获取到。 prev[i] = 0; // 顶点i的前驱顶点为0。 dist[i] = G.matrix[vs][i];// 顶点i的最短路径为\"顶点vs\"到\"顶点i\"的权。 &#125; // 对\"顶点vs\"自身进行 初始化 flag[vs] = 1; dist[vs] = 0; // 遍历G.vexnum-1次；每次找出一个顶点的最短路径。 for (i = 1; i &lt; G.vexnum; i++) &#123; // 寻找当前最小的路径； // 即，在未获取最短路径的顶点中，找到离vs最近的顶点(k)。 min = INF; for (j = 0; j &lt; G.vexnum; j++) &#123; if (flag[j]==0 &amp;&amp; dist[j]&lt;min) &#123; min = dist[j]; k = j; &#125; &#125; // 标记\"顶点k\"为已经获取到最短路径 flag[k] = 1; // 修正当前最短路径和前驱顶点 // 即，当已经\"顶点k的最短路径\"之后，更新\"未获取最短路径的顶点的最短路径和前驱顶点\"。 for (j = 0; j &lt; G.vexnum; j++) &#123; tmp = (G.matrix[k][j]==INF ? INF : (min + G.matrix[k][j])); // 防止溢出 if (flag[j] == 0 &amp;&amp; (tmp &lt; dist[j]) ) &#123; dist[j] = tmp; prev[j] = k; &#125; &#125;&#125; // 打印dijkstra最短路径的结果 printf(\"dijkstra(%c): \\n\", G.vexs[vs]); for (i = 0; i &lt; G.vexnum; i++) printf(\" shortest(%c, %c)=%d\\n\", G.vexs[vs], G.vexs[i], dist[i]);&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://github.com/categories/算法/"}],"tags":[{"name":"图算法","slug":"图算法","permalink":"http://github.com/tags/图算法/"}]},{"title":"Linux学习（五）常用命令","slug":"Linux学习（五）常用命令","date":"2018-04-14T15:08:43.000Z","updated":"2018-04-14T15:09:39.429Z","comments":true,"path":"2018/04/14/Linux学习（五）常用命令/","link":"","permalink":"http://github.com/2018/04/14/Linux学习（五）常用命令/","excerpt":"cat命令很多时候我们通过cat命令来查看文件内容，它会将文件的所有内容显示出来。当然，cat也可以通过管道接收数据，它主要完成的是将从管道接收的输入导到输出。 more跟less命令有时候用cat命令来显示一个较大的文件并不方便，整个文件内容一次性显示出来简直就是刷屏了。如果需要一页页的显示内容，可以使用more或者less命令，这两个命令会以分页的形式显示文件内容，至于使用哪个命令完全看个人习惯了。此外，这两个命令不仅可以分页显示，而且在分页模式下，你可以用快捷键方便的浏览及搜索： * 按`d`下翻页 * 按空格下翻页 * 按回车下移一行 * 按`/`进入搜索模式，输入要搜索的关键字，按回车搜索。 * 按`n`搜索下一个 * 按`q`退出查看","text":"cat命令很多时候我们通过cat命令来查看文件内容，它会将文件的所有内容显示出来。当然，cat也可以通过管道接收数据，它主要完成的是将从管道接收的输入导到输出。 more跟less命令有时候用cat命令来显示一个较大的文件并不方便，整个文件内容一次性显示出来简直就是刷屏了。如果需要一页页的显示内容，可以使用more或者less命令，这两个命令会以分页的形式显示文件内容，至于使用哪个命令完全看个人习惯了。此外，这两个命令不仅可以分页显示，而且在分页模式下，你可以用快捷键方便的浏览及搜索： * 按`d`下翻页 * 按空格下翻页 * 按回车下移一行 * 按`/`进入搜索模式，输入要搜索的关键字，按回车搜索。 * 按`n`搜索下一个 * 按`q`退出查看 tee命令tee命令一般从管道接收数据，这点与cat类似，将stdin导到stdout。不同的是，tee同时还可以指定一个文件作为输出。这点非常有用，有时候我们想一般看到命令的输出，同时又希望将输出保存到文件中，这时候用tee最为合适。 1234# date | tee time.logMon Nov 20 14:05:02 EST 2017# cat time.logMon Nov 20 14:05:02 EST 2017 date命令date命令用来显示时间跟时区，比较常见的用法有： 默认显示 1234# dateSun Nov 19 20:08:21 EST 2017# date -uMon Nov 20 01:08:28 UTC 2017 其中，-u参数表示显示UTC标准时间，即时区为0的时间。 指定显示格式 除了默认输出，我们也可以指定显示的格式： 12# date +&apos;%A %d-%m-%Y UTC %:z&apos;Sunday 19-11-2017 UTC -05:00 date支持非常多元化的格式，具体可以参考这里。 显示当前时间的秒数 通常，在计算当前时间的秒数的时候，我们通常会以Unix Epoch Time为基准，用date命令可以非常方便的显示当前时间的秒数： 1234# date +%s1511141040# date +%s --date=&apos;2017/11/19 09:56:00&apos;1511103360 其中，也可以通过参数--date指定时间来计算。反过来，如果我们知道了时间的秒数，需要显示其相对于Unix Epoch Time的时间，可以这么做： 12345# date; date +%sMon Nov 20 10:33:07 EST 20171511191987# date --date=@1511191987Mon Nov 20 10:33:07 EST 2017 时间偏移计算 有时候需要知道多少天前是什么时间，这时候需要用到时间偏移计算了： 123456# date --date=&apos;100 seconds ago&apos;Sun Nov 19 20:35:44 EST 2017# date --date=&apos;100 hours ago&apos;Wed Nov 15 16:37:28 EST 2017# date --date=&apos;100 days ago&apos;Fri Aug 11 21:37:34 EDT 2017 date命令可以识别多种时间偏移写法，除了示例中的，还有minutes months years等，当然，也可以这样写: 123456# date --date=&apos;+ 1000 seconds&apos;Sun Nov 19 20:56:28 EST 2017# date --date=&apos;- 1000 seconds&apos;Sun Nov 19 20:23:41 EST 2017# date --date=&apos;2017-11-19 00:00:00 + 1000 seconds&apos;Sat Nov 18 09:00:01 EST 2017 直接用+或者-表示以后或者以前的时间，也可以指定某个时间点然后偏移。 设置时间 当然，你也可以通过date命令来设置时间： 123456# dateSun Nov 19 20:44:11 EST 2017# date --set=&apos;Sun Nov 19 20:44:30 EST 2017&apos;Sun Nov 19 20:44:30 EST 2017# dateSun Nov 19 20:44:31 EST 2017 其中--set也可以简写为-s，时间格式非常灵活： 12# date -s &apos;2017/11/20 10:19:50&apos;Mon Nov 20 10:19:50 EST 2017 cal命令我们用date可以显示时间，同时咱们还可以通过cal命令来显示日历： 12345678# cal November 2017Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 1112 13 14 15 16 17 1819 20 21 22 23 24 2526 27 28 29 30 当然，你也可以指定要显示的日期，比如1949年10月的日历： 123456789# cal 10 1949 October 1949Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31 time命令有时候我们需要知道一个命令运行了多少时间，这时候我们可以用time命令来计时： 12345# time sleep 1real 0m1.018suser 0m0.001ssys 0m0.002s 其中sleep 1用来睡眠1秒，real表示实际用了多少时间，user表示在用户态花了多少时间，sys则表示在内核花了多少时间。详细可以参考这篇问答。 wc命令wc命令是Word Count的简称，顾名思义就是用来统计单词的。 1234# cat test.logNov 17 00:27:20 traffic-base1 named[1212]: managed-keys-zone: Unable to fetch DNSKEY set .: timed out# cat test.log | wc -w14 参数-w表示统计单词数，这里的单词实际上指的是被空格分开的字符串。下面列举出wc命令的有关参数： |——+————————|| 参数 | 说明 ||——+————————|| -w | 统计多少单词 || -l | 统计多少行 || -c | 统计有多少个字节 || -m | 统计有多少个字符 || -L | 统计长度最长的行的长度 ||——+————————| 注意，这里的字节跟字符的差别，在英文中基本上是一样的，但是在多字节语言中，其意义就不一样了： 1234# echo &apos;你好&apos; | wc -c7# echo &apos;你好&apos; | wc -m3 find命令find命令用来查找文件或目录，这又是一个非常强大的且常用的命令，这里只介绍几种常见的用法： 根据名字查找 这是基本且常见的用法： 123# find . -name &quot;test*&quot;./test.log./test2 示例中表示在当前目录（用.表示）下包括其子目录，查找文件名以test开头的文件或者目录。默认情况下，find命令是大小写敏感的，如果需要忽略大小写，则可以改用参数-iname。 根据路径查找 -name参数会根据名字查找，如果需要对路径进行匹配查找，则可以用-path参数： 123456# find . -path &quot;./tmp/*&quot;./tmp/Test1./tmp/test2./tmp/test.log./tmp/test.cpp./tmp/time.log 根据类型查找 可以根据类型查找文件： 1234# find . -type f./Test1./test.log./test2 当然，也可以同时根据类型跟文件名一起查找： 123# find . -type f -name &quot;test*&quot;./test.log./test2 f表示文件，如果是查找目录的话则用d。 根据时间查找 find命令还可以根据时间来查找文件目录，其中一个用法如下： 1find . -newer base_file 表示在当前目录下查找比base_file文件更新的文件或者目录。此外，find还可以根据文件的atime, ctime, mtime来查找文件，如下，根据修改时间来查找： 12345678910111213# dateFri Nov 17 20:34:52 EST 2017# lltotal 20drwxr-xr-x. 2 root root 45 Nov 17 02:46 ./dr-xr-x---. 48 root root 8192 Nov 17 02:46 ../-rw-r--r--. 1 root root 0 Nov 16 00:17 Test1-rw-r--r--. 1 root root 34 Nov 17 02:46 test2-rw-r--r--. 1 root root 102 Nov 17 00:30 test.log# find . -mtime -1../test.log./test2 其中-mtime表示根据修改时间查找，-1表示最近一天。find支持的时间查找总结如下： |——–+———————————————-| | 参数 | 说明 | |——–+———————————————-| | -mtime | 根据修改时间，也就是ls -l显示的时间 | | -atime | 根据访问时间，也就是ls -lu显示的时间 | | -ctime | 根据状态改变的时间，也就是ls -lc显示的时间 | |——–+———————————————-| 时间值的表示说明：基准+0表示一天前，-1.5表示最近1.5天，+1.5表示2.5天前 逻辑查找 find支持与或非逻辑的查找，比如查找所有C++的源文件，实际上需要找出后缀为.cpp跟.h的文件，需要用到find的逻辑或的查找： 1find . -name \"*.cpp\" -o -name \"*.h\" 其中-o是-or的缩写，用来表示逻辑或的关系，而-name &quot;*.cpp&quot;与-name &quot;*.h&quot;为表达式，构成了EXP1 or EXP2的关系，只要文件或者目录满足其中一个表达式就会输出。find支持的逻辑关系如下： |——+——+——————————————————————–| | 逻辑 | 参数 | 说明 | |——+——+——————————————————————–| | 与 | -a | -and的缩写，逻辑与的关系，如find . -type f -a -name &quot;*.log&quot; | | 或 | -o | -or的缩写，逻辑或的关系, 如find . -name &quot;*.cpp&quot; -o -name &quot;*.h&quot; | | 非 | ! | -not的缩写，逻辑非的关系, 如find . ! -name &quot;*.cpp&quot; | |——+——+——————————————————————–| 此外，find命令还有一个非常重要且常见的用法，就是在找到文件后执行某个命令，改用法如下： 1find . -name \"*.log\" -exec rm &#123;&#125; \\; 表示删除当前目录包括子目录中以.log为后缀的所有文件。其中，-exec表示在找到后需要执行命令，而命令为rm {} \\;，实际上此命令就是一般的shell命令，其中{}用来指代找到的文件或目录，这里;必须转义，因为需要传递给find本身，如果不转义，则会直接被shell解析使用了。每找到一个文件或目录，都会执行指定的命令，其中{}部分以文件路径替代。如果需要只执行一次命令，而把所有找到的文件作为参数传递给该命令，则需要用+替代\\;，如： 1find . -name \"*.log\" -exec rm &#123;&#125; + 假定找到的文件有test.log，test1.log，用\\;的方式相当于执行两次：rm test.log跟rm test1.log；如果使用+则只有一次命令rm test.log test1.log。 sort命令顾名思义，这个命令就是用来排序的。 123456# head -n 5 /etc/passwd | sortadm:x:3:4:adm:/var/adm:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinroot:x:0:0:root:/root:/bin/bash 默认情况下，sort命令以字典顺序对每行进行排序，如果不带参数，会将整行作为一个字符串进行比较。当然，你也可以指定以第几列进行排序： 123456# head -n 5 /etc/passwd | tr : &quot; &quot; | sort -k 3root x 0 0 root /root /bin/bashbin x 1 1 bin /bin /sbin/nologindaemon x 2 2 daemon /sbin /sbin/nologinadm x 3 4 adm /var/adm /sbin/nologinlp x 4 7 lp /var/spool/lpd /sbin/nologin 这里先将:换成空格（关于tr命令，请参照本文关于tr命令的章节），然后以-k为参数，指定以第三列进行排序。下面列举其常用的一些参数： |——+————————————————————————————————————|| 参数 | 说明 ||——+————————————————————————————————————|| -k | 以第几列排序，列以空格为分隔 || -r | 默认sort以升序输出，-r参数则可以以降序输出 || -n | 在指定第几列的时候，可以强制sort把列的值以数字值进行排序，如下面的例子 || -t | 默认情况下认为列是以空格为分隔，-t参数则可以指定分隔符，这样，上面的例子其实可以直接写成sort -t : -k 3 || -f | 忽略大小写 || -u | 如果排序后出现重复的行，加上这个参数将只显示一行 ||——+————————————————————————————————————| 12345678910111213141516171819# cat test210353# cat test2 | sort10335# cat test2 | sort -n33510# cat test2 | sort -n -u3510 uniq命令uniq是unique的简写，用来消除sort排序后重复的行，即相当于sort命令中的-u参数。但是，uniq不仅可以消除重复行，它还可以显示分别重复了多少行： 1234# cat test2 | sort -n | uniq -c 2 3 1 5 1 10 还有些常用的参数如下： |——+————————————————————|| 参数 | 说明 ||——+————————————————————|| -i | 忽略大小写 || -d | 只打印有重复的行，每组一个，如果要打印组内所有的，则用-D || -u | 只打印没有重复的行 || -f | 比较的时候，忽略前面的N列 || -s | 比较的时候，忽略前面的N个字符 ||——+————————————————————| od命令od可以用来显示二进制文件： 123456# cat test2abcdefg1234567# od -t x1 test20000000 61 62 63 64 65 66 67 0a 31 32 33 34 35 36 37 0a0000020 当然，也可以直接显示字符： 123# od -c test20000000 a b c d e f g \\n 1 2 3 4 5 6 7 \\n0000020 当然，如果仅仅只是显示二进制内容，还可以使用hexdump命令了。 压缩类命令tar命令在Linux中，用的最多的压缩命令就是tar命令了，在介绍其用法之前，需要清楚几个概念： 存档文件(Archive File) 存档文件用来打包多个文件成一个文件，以方便在网络上传输。请注意，打包成的文件并没有被压缩。在Linux或Unix系统中，TAR文件是最为常用的存档文件（通常以.tar为文件后缀）。TAR文件的更多解释可以参考这里。用tar命令可以生产TAR文件，示例如下： 1tar cvf tmp.tar tmp/ 具体参数在下面会具体解释，不带任何压缩格式的话，tar命令会生成一个TAR文件。相应的，如果需要解开TAR文件，可以这么做： 1tar xvf tmp.tar 压缩文件(Compressed File) TAR文件是没有被压缩的，大小基本保持不变。如果需要对文件进行压缩，则需要在tar命令中加入压缩格式对应的参数，具体在下面会说明。 下面来详细介绍tar命令的用法，tar的用法如下： 12# tar --helpUsage: tar [OPTION...] [FILE]... tar命令支持非常多的参数，这里列举比较常用的几种使用方式： 压缩文件或目录 12345# tar czvf tmp.tgz tmp/tmp/tmp/Test1tmp/test.logtmp/test2 其中，czvf表示参数选项；tmp.tgz表示压缩后的文件名，通常tgz是tar.gz的简写；tmp/表示被压缩的目录。参数的解释如下： |——+————————————————————-| | 参数 | 说明 | |——+————————————————————-| | c | Create的简写，表示生产压缩文件 | | z | 表示采用gzip的压缩格式，文件后缀通常为.tar.gz或者.tgz | | v | 表示显示压缩的过程，会列出所有被压缩的文件 | | f | 指定压缩文件 | |——+————————————————————-| 需要注意的是，tar支持不同的压缩格式，除了gzip之外，还有： |———-+———————————————| | 参数 | 说明 | |———-+———————————————| | j | 采用bzip2的压缩格式，文件后缀通常为.bz2 | | --lzip | 采用lzip的压缩格式，文件后缀通常为.lz | | --xz | 采用xz的压缩格式，文件后缀通常为.xz | | --lzma | 采用lzma的压缩格式，文件后缀通常为.lzma | |———-+———————————————| 更多格式可以参考这里。当然，最为常用的两种格式为gzip跟bzip2，用法示例如下： 12tar czvf tmp.tgz tmp/tar cjvf tmp.bz2 tmp/ 其中v参数可选，如果不需要显示压缩过程的话。需要注意的是，tar压缩目录的时候会保持目录的结构。 解压文件 对应于不同的压缩格式，解压参数稍微不一样，对于gzip跟bzip2分别示例如下： 12tar xzvf tmp.tgztar xjvf tmp.tgz 与压缩不同，c换成x表示解压，其它参数含义与压缩一样。默认情况下，解压的文件会放在当前目录，如果需要解压到某个目录下，则可以用-C参数： 12tar xzvf -C /tmp/ tmp.tgztar xjvf -C /tmp/ tmp.tgz 列出压缩包里面的文件 有时候我们需要先看看压缩包里面有哪些文件，但又并不想解压文件，可以采用-t参数： 123456# tar czf tmp.tgz tmp/# tar tvf tmp.tgzdrwxr-xr-x root/root 0 2017-11-17 02:46 tmp/-rw-r--r-- root/root 0 2017-11-16 00:17 tmp/Test1-rw-r--r-- root/root 102 2017-11-17 00:30 tmp/test.log-rw-r--r-- root/root 34 2017-11-17 02:46 tmp/test2 其中，tvf会列出压缩包中的文件，不论采用何种压缩格式，甚至是没有被压缩的TAR文件。 从压缩包中提取特定的文件 在列出压缩包里面的内容后，如果只想提取里面的某些文件，可以这么做： 123# tar xzvf tmp.tgz tmp/test.log tmp/test2tmp/test.logtmp/test2 其中，根据不同的压缩格式请替换成不同的参数。请务必注意，指定的文件必须是完整的路径，而不能只是文件名。 另外，如果想提取一组匹配某种条件的文件，可以使用--wildcards参数： 12# tar xzvf tmp.tgz --wildcards &quot;*.log&quot;tmp/test.log split命令split命令用来将一个文件分成多个文件，比如将一个特别大的文件分成平均大小为40M的多个文件等。 12345# split -b 40M go1.6.linux-amd64.tar.gz go1.6.linux-amd64.tar.gz.part# ll go1.6.linux-amd64.tar.gz.part*-rw-r--r--. 1 root root 41943040 Nov 20 15:03 go1.6.linux-amd64.tar.gz.partaa-rw-r--r--. 1 root root 41943040 Nov 20 15:03 go1.6.linux-amd64.tar.gz.partab-rw-r--r--. 1 root root 913400 Nov 20 15:03 go1.6.linux-amd64.tar.gz.partac 其中，go1.6.linux-amd64.tar.gz是要被拆分的文件，go1.6.linux-amd64.tar.gz.part是拆分后文件的前缀，可以看到文件被拆分为三部分了。 split非常常见的用法是来将某个被压缩的文件拆分成小的部分，正如上例所示。那么，如何将拆分的文件重新合并呢？我们可以用cat将它们合并： 1cat go1.6.linux-amd64.tar.gz.part* &gt; go1.6.linux-amd64.tar.gz grep命令过滤数据来说，用的最多的估计就是grep命令了，grep命令可以从文件或者管道中搜索数据并打印出来，当然，其也可以直接在目录中搜索所有的文件，并把其中符合条件的行打印出来。 123456# cat test.log | grep hellohello# grep hello test.loghello# grep hello . -r./test.log:hello 上面就是三种方式搜索包括hello关键字的行。 grep是Linux中使用最为频繁的命令之一，其本身也有非常强大的功能，这一节咱们将详细讲述其比较常见的用法。 基本查找查看grep的帮助可以看到： 12# grep --helpUsage: grep [OPTION]... PATTERN [FILE]... 其中OPTION指的是命令参数，PATTERN指的是匹配的字符串，比如关键字搜索。FILE指的是文件，当然，没有文件的时候也可以通过管道接收数据并搜索过滤。grep提供了非常多的命令参数用来控制查找的方式跟效果，下面列举其常用的一些参数： |——+————————————————————————————————————|| 参数 | 说明 ||——+————————————————————————————————————|| -i | 默认情况下，grep命令的搜索是大小写敏感的，如果需要忽略大小写可以用这个参数 || -v | 该参数表示不包含的意思 || -A2 | 其中A是after的意思，表示同时显示搜索出来行后面两行。有时候我们需要知道匹配行后面是什么，可以用这个参数 || -B2 | 与A相反，其是before的意思，表示同时显示匹配行前两行 || -C2 | 有时候我们想既显示前面两行也显示后面两行，这时候就用这个参数 || -r | 搜索目录的时候需要带上这个参数 || -n | 有些时候，我们需要知道匹配到的行是第几行，可以加上这个参数把行号打印出来 ||——+————————————————————————————————————| 对于PATTERN，grep命令也支持不同的用法： 关键字匹配 这个是最常用的基本用法，匹配是否包括该关键字的行。 正则匹配 除了基本的关键字匹配，grep还支持极为强大的正则表达式的匹配。我们将在下一小节专门讲述正则表达式匹配。 或匹配 有时候我们需要匹配某个PATTERN1或者PATTERN2的行，这时候可以这么写PATTERN：PATTERN1\\|PATTERN2。通过\\|将多个PATTERN连在一起表示或的意思，只要匹配其中任一个的行都会被打印出来。 123# grep &apos;12306\\|test&apos; . -r./test2:http://abcdefg.test.com./test2:12306.com 正则表达式匹配grep命令支持非常强大的正则匹配，支持三种不同的正则表达式： ERE(POSIX-Extended Regular Expressions) BRE(POSIX_Basic_Regular_Expressions) Perl Regular expression 当然，比较常用的是ERE正则表达式了。在grep命令中，采用-E参数即可以使用该表达式，正则表达式非常灵活，用法非常多，这里列举几个示例： 匹配以关键字开头的行 1grep -E \"^keyword\" . -r 匹配以关键字结尾的行 1grep -E \"keyword$\" . -r 匹配包含如2017/10/11日期的行 1grep -E \"[0-9]&#123;4&#125;/[0-9]&#123;2&#125;/[0-9]&#123;2&#125;\" . -r 注意的是，对于数字的表示，其不支持如\\d这样的表达方式，而需要[0-9]这样表达。 当然，如果需要熟练掌握grep的正则表达式匹配，你必须对正则表达式非常熟悉，这个就不在本篇的范畴了。 awk命令要说Linux中最为强大的基本命令有哪些，那awk无疑会榜上有名，其强大的流式处理能力，很多人甚至写书来专门讲这个命令。这里咱们暂时介绍基本的功能，以后有机会将专门开辟一文来展开。 一个常见的用法就是把文件中的某几列打印出来： 1234# cat test.logNov 17 00:27:20 traffic-base1 named[1212]: managed-keys-zone: Unable to fetch DNSKEY set .: timed out# cat test.log | awk &apos;&#123;print $1, $2, $3&#125;&apos;Nov 17 00:27:20 如上例，空格将一行分成了不同的列，咱们希望只把时间显示出来，而时间包括了第1，2，3列，因此，通过awk &#39;{print $1, $2, $3}&#39;就实现了此功能，其中$1就是引用第一列。 cut命令有时候，一行内的数据并不是通过空格分隔开的，而是通过其它分隔符，那如何显示想要的列呢？通过cut命令，咱们同样可以轻松实现： 123456789101112# head -n 5 /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin# head -n 5 /etc/passwd | cut -d: -f1rootbindaemonadmlp /etc/passwd中的每一行基本上都是通过:进行分隔，其中第一列表示用户名，如果咱们只想把用户名输出的话，可以通过cut -d: -f1来实现，其中-d:表示以:号为分隔符，-f1表示显示第一列。可见，对于cut命令来说，咱们可以指定分隔符，那么前面通过awk实现的例子也可以通过cut来做： 1234# cat test.logNov 17 00:27:20 traffic-base1 named[1212]: managed-keys-zone: Unable to fetch DNSKEY set .: timed out# cat test.log | cut -d&quot; &quot; -f1-3Nov 17 00:27:20 其中-d&quot; &quot;表示以空格为分隔符（注意，这里的空格必须以引号括起来，不然会被shell展开去除多余空格），-f1-3表示输出第1到3列，这里简用了-来表示范围，当然也可以写成-f1,2,3了。 此外，cut命令还可以指定输出哪些位的字符： 1234# cat test.logNov 17 00:27:20 traffic-base1 named[1212]: managed-keys-zone: Unable to fetch DNSKEY set .: timed out# cat test.log | cut -c1-16Nov 17 00:27:20 其中，-c1-16表示输出第1到16个字符，当然，你同样可以以,来分别列举要输出哪几个。 tr命令tr其实是translate的缩写，这个命令用来将某些字符翻译成另外的字符。 12# tr --helpUsage: tr [OPTION]... SET1 [SET2] 这个命令就是把字符集SET1中的字符对应的转成字符集SET2中的字符。如将小写转成大写： 1234# cat test.logNov 17 00:27:20 traffic-base1 named[1212]: managed-keys-zone: Unable to fetch DNSKEY set .: timed out# cat test.log | tr a-z A-ZNOV 17 00:27:20 TRAFFIC-BASE1 NAMED[1212]: MANAGED-KEYS-ZONE: UNABLE TO FETCH DNSKEY SET .: TIMED OUT 这里用-来方便的表示一定范围的字符集，当然，你完全可以一个个列出来你要的字符集。通常情况下，SET1跟SET2的长度保持一致，因为这个转换实际上是一对一的转换，当然，SET2的长度是可以大于SET1的，多余的字符不会被使用。但是，当SET2长度小于SET1时，tr命令会将SET2中最后一个字符填充不足的位数： 1234# echo &apos;abcdefg&apos; | tr ab wyzwycdefg# echo &apos;abcdefg&apos; | tr abcdefg wyzwyzzzzz 对于tr还有一个常见的用途，就是用来去除字符串中的换行符： 12345678# head -n 5 /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin# head -n 5 /etc/passwd | tr &apos;\\n&apos; &apos; &apos;root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 其中，\\n表示换行符，示例中将换行符全部换成了空格。 最后，tr还有一个常见的用法，可以加上-d参数来删除字符集中的字符。 12# echo abcdeWXYZ | tr -d a-zWXYZ 示例中删除了所有小写字母。 sed命令流式处理中，sed也是一个极为常用的命令，它可以用来替换字串，比之前的tr那是要强大无数倍了。 查看sed的帮助： 12# sed --helpUsage: sed [OPTION]... &#123;script-only-if-no-other-script&#125; [input-file]... 它既可以直接在文件中替换字符串，也可以加收管道的数据。如基本用法： 12# echo abcdefgabcd | sed &apos;s/abc/ABC/&apos;ABCdefgabcd 其中&#39;s/abc/ABC/&#39;指定了替换的规则，默认情况下只替换一次，如果需要全部替换，则需要在规则后面加入g： 12# echo abcdefgabcd | sed &apos;s/abc/ABC/g&apos;ABCdefgABCd 规则中默认使用了/为分隔。当然，你也可以使用其他分隔符，这在要替换的字串中带有/的时候特别有用： 1234# echo &quot;http://abc.test.com&quot; | sed &apos;s/http:\\/\\//https:\\/\\//&apos;https://abc.test.com# echo &quot;http://abc.test.com&quot; | sed &apos;s|http://|https://|&apos;https://abc.test.com 如果不指定新的分隔符|，那么就得使用转义符\\将//进行转义了，这样可读性就差了很多，采用|就自然多了。sed支持的分隔符还包括了:，_。 此外，sed不仅可以用来替换字串，还可以用来删除匹配的行： 12345# cat test2http://abcdefg.test.com12306.com# cat test2 | sed &apos;/12306/d&apos;http://abcdefg.test.com 高级用法 后向引用（Back Referencing） sed规则匹配到的字符串还可以在规则定义中被引用，如下例： 12# echo &quot;hello world&quot; | sed &apos;s/hello/&amp;&amp;/&apos;hellohello world 其中，&amp;可以用来引用被匹配到的字串，在本例中，匹配到的字串是hello，这样通过&amp;就可以引用被匹配到的字串了。此外，我们还可以通过()来指定匹配的字串，并用\\1（数字表示第一个()）来引用（实际上是正则表达式中的Grouping）： 1234# echo Sunday | sed &apos;s/\\(Sun\\)/\\1ny/&apos;Sunnyday# echo Sunday | sed &apos;s/\\(Sun\\)/\\1ny \\1/&apos;Sunny Sunday 正则匹配 由上述可以看出，sed的规则使用了正则表达式规则，但是其书写跟一般的正则书写不一样，你必须将有关的字符转义，否则sed仍然会将其当做普通字符进行匹配： 1234# echo &quot;this is aaaa cat&quot; | sed &apos;s/a&#123;4&#125;/a/&apos;this is aaaa cat# echo &quot;this is aaaa cat&quot; | sed &apos;s/a\\&#123;4\\&#125;/a/&apos;this is a cat 可以看出，在没有转义{及}之前，sed并没有匹配到目标字串aaaa，而将其转义之后，则以正则表达式a{4}匹配到了aaaa并进行了替换。 递归替换 有时候我们需要在项目目录下替换某个字串，比如把手误写错的#include&lt;stdllib.h&gt;全部替换成#include&lt;stdlib.h&gt;，希望被替换的文件包括*.cpp，*.h的文件。其中的一种做法如下： 12345$ head -n 1 test.cpp#include &lt;stdllib.h&gt;$ sed -i &apos;s/#include &lt;stdllib.h&gt;/#include &lt;stdlib.h&gt;/&apos; `find . -name &quot;*.cpp&quot; -o -name &quot;*.h&quot;`$ head -n 1 test.cpp#include &lt;stdlib.h&gt; 这里用到了shell嵌入的用法（可以参看这一篇博文)，通过find命令找出所有的源文件，然后用sed -i进行替换，其中-i表示从文件里面替换。这一用法会将find找到的所有文件作为参数都追加到sed命令后，在项目非常大的情况下可能会导致命令执行失败（因为数量庞大的文件导致追加的参数太大了），通常我们推荐采用find的这种用法： 1find . -name \"*.cpp\" -o -name \"*.h\" -exec sed -i 's/#include &lt;stdllib.h&gt;/#include &lt;stdlib.h&gt;/' &#123;&#125; \\; 具体可以参照本文中关于find命令的介绍。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/tags/Linux/"},{"name":"study","slug":"study","permalink":"http://github.com/tags/study/"}]},{"title":"Linux学习（四）IO重定向与管道","slug":"Linux学习（四）IO重定向与管道","date":"2018-04-14T15:06:32.000Z","updated":"2018-04-14T15:07:22.116Z","comments":true,"path":"2018/04/14/Linux学习（四）IO重定向与管道/","link":"","permalink":"http://github.com/2018/04/14/Linux学习（四）IO重定向与管道/","excerpt":"IO重定向(IO redirection)Linux的有一个强大之处就是可以通过管道(Pipe)跟IO重定向将一系列命令的输出跟输入连接起来。IO重定向是Linux中非常重要的概念，是理解Linux命令，脚本以及Linux IO的基础。 标准输入输出对于shell来说，有三个基础的流，标准输入流(stdin或者stream 0)，标准输出流(stdout或者stream 1)，标准错误流(stderr或者stream2)。 举个例子，当我们用键盘在shell中执行命令的时候，可以如下图： 通常，stdout跟stderr都输出到了屏幕上，但对于Linux来说，其实是两种不同的输出。","text":"IO重定向(IO redirection)Linux的有一个强大之处就是可以通过管道(Pipe)跟IO重定向将一系列命令的输出跟输入连接起来。IO重定向是Linux中非常重要的概念，是理解Linux命令，脚本以及Linux IO的基础。 标准输入输出对于shell来说，有三个基础的流，标准输入流(stdin或者stream 0)，标准输出流(stdout或者stream 1)，标准错误流(stderr或者stream2)。 举个例子，当我们用键盘在shell中执行命令的时候，可以如下图： 通常，stdout跟stderr都输出到了屏幕上，但对于Linux来说，其实是两种不同的输出。 输出重定向可以用&gt;大于号将stdout重定向到另一个IO，比如文件： 123# echo &quot;hello&quot; &gt; test.log# cat test.loghello 上面的命令将stdout重定向到文件test.log中，此时，如果该文件不存在则创建新文件，如果存在则覆盖已有文件。事实上，&gt;重定向是1&gt;的简写，1&gt;可以更清楚的看到实际上是把stdout(stream 1)重定向。 必须注意的是，默认情况下，该重定向会覆盖已有文件，这个在有时候可能不经意间丢失重要数据。shell提供了选项使得我们可以禁止这种覆盖，set -o noclobber可以打开该选项。 12345# cat test.loghello# set -o noclobber# echo &quot;world&quot; &gt; test.log-bash: test.log: cannot overwrite existing file 此外，在打开该选项之后，其实还是可以强制执行覆盖，可以采用&gt;|来强制重定向到已存在的文件： 12345# echo &quot;world&quot; &gt; test.log-bash: test.log: cannot overwrite existing file# echo &quot;world&quot; &gt;| test.log# cat test.logworld 追加输出可以采用&gt;&gt;将输出重定向到文件并追加在文件结尾，这样就可以避免覆盖文件了。 123456# cat test.logworld# echo hello &gt;&gt; test.log# cat test.logworldhello 标准错误重定向如1&gt;一样，我们可以通过2&gt;将stderr重定向到文件，具体行为跟stdout类似。 同时重定向stdout跟stderr我们可以在同一行命令中同时将stdout跟stderr重定向，如： 123456789# ls test* tttt*ls: cannot access tttt*: No such file or directorytest.log test2# ls test* tttt* &gt; stdout.log 2&gt; stderr.log# cat stdout.logtest.logtest2# cat stderr.logls: cannot access tttt*: No such file or directory 可以看出，stdout跟stderr被分别重定向到stdout.log跟stderr.log文件中了。 此外，还有一个常见的用法是将stderr重定向到stdout，这样就可以将所有输出都定向在一起了。 12345678910# ls test* tttt* &gt; stdout.logls: cannot access tttt*: No such file or directory# cat stdout.logtest.logtest2# ls test* tttt* &gt; stdout.log 2&gt;&amp;1# cat stdout.logls: cannot access tttt*: No such file or directorytest.logtest2 可见，通过2&gt;&amp;1将stderr重定向给stdout，而stdout又重定向给文件stdout.log，这样所有的输出都重定向到文件stdout.log中了。另外，还可以通过&amp;&gt;直接将stderr跟stdout合并： 12345# ls -l test* tttt* &amp;&gt; stdout.log# cat stdout.logls: cannot access tttt*: No such file or directory-rw-r--r--. 1 root root 12 Nov 16 01:02 test.log-rw-r--r--. 1 root root 0 Nov 16 00:17 test2 重定向顺序将stderr重定向给stdout的时候，请务必注意其顺序，如上面的重定向如果写成这样，结果就完全不同了： 12345# ls test* tttt* 2&gt;&amp;1 &gt; stdout.logls: cannot access tttt*: No such file or directory# cat stdout.logtest.logtest2 可以看出，stderr其实并没有被重定向到文件stdout.log中，可见顺序是非常重要的。那么，如果理解这种不同呢？咱们可以这么样来理解： 将&gt;看作是shell中的赋值操作= 将stdout跟stderr看作是变量，但对其引用采用&amp;，这样&amp;1表示对stdout变量的引用 假定stdout跟stderr变量的初始值是屏幕，将屏幕记为/dev/tty shell从左到有扫描解释命令，并对stdout跟stderr分别赋值 查看stdout跟stderr的最终值即可知道分别被重定向到哪里了 还是以上面的例子来解释，ls test* tttt* 2&gt;&amp;1 &gt; stdout.log 命令开始前，stdout=/dev/tty, stderr=/dev/tty shell从左到右扫描并重新赋值，首先2&gt;&amp;1就相当于stderr=$stdin，此时stderr的值其实还是/dev/tty &gt; stdout.log就相当于stdout=stdout.log，此时stdout值为stdout.log 最后，stdout值为stdout.log，而stderr值仍然为/dev/tty，所以只有stdout输出到文件stdout.log中了 基于这个原则，在讲述完管道之后咱们将展示如何把stdout跟stderr交换一下。 输入重定向 &lt;符号 既然输出有重定向，那么输入是否也可以呢？答案是肯定的，可以采用&lt;将输入重定向，&lt;其实是0&lt;的简写。 12345678# cat stdout.logls: cannot access tttt*: No such file or directory-rw-r--r--. 1 root root 12 Nov 16 01:02 test.log-rw-r--r--. 1 root root 0 Nov 16 00:17 test2# cat &lt;stdout.logls: cannot access tttt*: No such file or directory-rw-r--r--. 1 root root 12 Nov 16 01:02 test.log-rw-r--r--. 1 root root 0 Nov 16 00:17 test2 &lt;&lt;符号 此外，还可以&lt;&lt;EOF通过手动输入直到输入EOF（或者Ctrl-D）。 &lt;&lt;&lt;符号 该符号可以直接将一个字符串重定向给输入 12# base64 &lt;&lt;&lt; helloaGVsbG8K base64命令参数只接受文件，通过这种方式就可以把字符串直接传给它。 输入输出同时重定向shell是可以支持同时重定向输入跟输出的，以下方式都会被准确解析： 12# cat &lt;test.log &gt; stdout.log 2&gt; stderr.log# &lt;test.log &gt; stdout.log 2&gt; stderr.log cat 快速清除文件内容可以通过重定向快速的清空文件内容： 12345# cat test.loghello world# &gt; test.log# cat test.log# 可见，咱们并不需要写echo &quot;&quot; &gt; test.log这样的命令来清空一个文件。当noclobber选项被打开时，可以通过&gt;|来强制清空。 管道(Pipe)在Linux中，我们可以使用管道(Pipe)将前一个命令的stdout作为输入给后面一个命令，管道由|表示。 123456# ls test* tttt*ls: cannot access tttt*: No such file or directorytest.log test2# ls -l test* tttt* | grep logls: cannot access tttt*: No such file or directory-rw-r--r--. 1 root root 12 Nov 16 01:02 test.log 请务必注意的是，管道只会将stdout传递给下一个命令，stderr并不会传递，为了证明这一点，咱们将后一个命令的stderr重定向到文件： 12345# ls -l test* tttt* | grep log 2&gt; stderr.logls: cannot access tttt*: No such file or directory-rw-r--r--. 1 root root 12 Nov 16 01:02 test.log# cat stderr.log# 这时可以看出，第二个命令的stderr为空，而第一个命令的stderr仍输出到屏幕了。当然，咱们也可以将第一个命令的stderr重定向到stdout上，这样grep命令也可以收到了。 12# ls -l test* tttt* 2&gt;&amp;1 | grep &quot;No &quot;ls: cannot access tttt*: No such file or directory 再回到上一节的问题，咱们如何将stdout跟stderr互相交换一下呢？可以这么做： 123456# ls -l test* tttt* 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3 | grep &quot;No &quot; 2&gt; stderr.logls: cannot access tttt*: No such file or directory-rw-r--r--. 1 root root 12 Nov 16 01:02 test.log-rw-r--r--. 1 root root 0 Nov 16 00:17 test2# cat stderr.log# 如果你的Linux发行版本对grep输出的颜色设置正确，会发现只有第一行是grep出来的，由此可见3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3居然将stdout跟stderr互换了一下，至于怎么解释，可以参照前面的赋值方式自行拆解一下。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/tags/Linux/"},{"name":"study","slug":"study","permalink":"http://github.com/tags/study/"}]},{"title":"Linux学习（三）shell基础","slug":"Linux学习（三）shell基础","date":"2018-04-14T15:03:35.000Z","updated":"2018-04-14T15:05:08.572Z","comments":true,"path":"2018/04/14/Linux学习（三）shell基础/","link":"","permalink":"http://github.com/2018/04/14/Linux学习（三）shell基础/","excerpt":"概述首先，咱们来了解一下，什么是Shell。操作系统内核给我们提供了各种接口，同时也提供了各种用户层的库，理论上我们基于这些可以编写程序实现各种我们想要的功能，不过问题是，咱们不可能做什么事情都要重新编写程序，这样使用起来也太困难了。因此，操作系统（包括Linux）通常都会引入一个Shell这样的特殊程序，这个程序会接受输入的命令然后执行，并可能将执行结果呈现出来。总结来说，Shell是一个从输入设备或者文件读取命令，并且解释、执行的用户态程序。 在Linux系统中，通常使用的Shell程序包括有： Sh (Bourne Shell) Bash (Bourne Again Shell) Csh (C Shell) Ksh (Korn Shell)","text":"概述首先，咱们来了解一下，什么是Shell。操作系统内核给我们提供了各种接口，同时也提供了各种用户层的库，理论上我们基于这些可以编写程序实现各种我们想要的功能，不过问题是，咱们不可能做什么事情都要重新编写程序，这样使用起来也太困难了。因此，操作系统（包括Linux）通常都会引入一个Shell这样的特殊程序，这个程序会接受输入的命令然后执行，并可能将执行结果呈现出来。总结来说，Shell是一个从输入设备或者文件读取命令，并且解释、执行的用户态程序。 在Linux系统中，通常使用的Shell程序包括有： Sh (Bourne Shell) Bash (Bourne Again Shell) Csh (C Shell) Ksh (Korn Shell) 一般来说，Bash应该是使用最多的Shell程序了，本文也主要基于Bash来展开。 Shell展开（Shell Expansion）Shell程序是一个命令解释器，因此在终端输入命令之后，Shell将扫描命令并做适当的修改，这个过程称为Shell展开。Shell展开是Shell解释执行之前极为重要的一步，了解它将有利于你对Shell命令或者脚本的理解，本章节将逐步带大家来了解这个过程。 命令参数解析这里的空格包括了制表符（Tab）。当Shell程序扫描输入的命令时，会以连续的空格为界，将命令切分成一组参数，因此你输入多个空格为界跟输入一个空格的效果是一样的。通常来讲，第一个参数就是要执行的命令，而后面的参数则是改命令的参数。一下几个命令其实是等效的： 123456# echo Hello WorldHello World# echo Hello WorldHello World# echo Hello WorldHello World 引号当然，有时候你需要在一个参数中包括空格，这样的话你就需要将这个参数以引号引起来，引号包括了单引号&#39;跟双引号&quot;，两者都可以。shell会将引号中的字符串视为一个参数，不论里面有没有空格。当然，特别指出的是，不要用反引号` ，反引号将在后面详细讲述。 如命令echo &#39;Hello World!&#39;在shell解析之后会有两个参数，分别为echo跟Hello World!。而如果不用引号echo Hello World!，则将解析为三个参数。 特别提一下，对于echo命令，如果需要输出需要转义的字符，如回车等，则需要执行echo -e &quot;Hello World!\\n&quot;，如果不加-e，则\\n会被直接显示出来。 123456&gt; # echo &quot;hello\\n&quot;&gt; hello\\n&gt; # echo -e &quot;hello\\n&quot;&gt; hello&gt;&gt; 命令对于shell来说，命令有内部命令（Builtin Commands）跟外部命令（External Commands）之分，所谓内部命令指的是包含在shell解析器中的命令。内部命令一般有4种类型： sh内部命令 这些内部命令来源于Bourne Shell，通常包括了以下命令： : . break cd continue eval exec exit export getopts hash pwd readonly return shift test/[ times trap umask unset。 bash内部命令 这些内部命令来源于Bourne Again Shell，通常包括了以下命令： alias bind builtin caller command declare echo enable help let local logout mapfile printf read readarray source type typeset ulimit unalias。 修改shell行为的内部命令 这些内部命令用来修改shell的默认行为。包括了set shopt命令。 特殊内部命令 由于历史原因，POSIX标准将一些内部命令划分为特殊内部命令，特殊的之处在于这些命令的查找时间以及命令运行后的状态等方面，只有当Bash以POSIX模式运行时，这些命令才是特殊命令，否则它们跟其它内部命令没啥区别。特殊内部命令包括了break : . continue eval exec exit export readonly return set shift trap unset。 内部命令可能会被提前至于内存中，因此运行起来会比外部命令要快。对于外部命令，可以认为除了内部命令之后就可以认为是外部命令了，通常来讲，/bin跟/sbin下的都是外部命令，当然，应用有关的通常也是外部命令。 我们可以通过type命令来查看一个命令是否是内部命令： 1234# type cdcd is a shell builtin# type awkawk is /usr/bin/awk 另外，对于很多内部命令，它们可能对应的会有外部命令版本，可以通过type命令来查看： 123456# type -a echoecho is a shell builtinecho is /usr/bin/echo# type -a cdcd is a shell builtincd is /usr/bin/cd 反过来，我们一般可以通过命令which来查询一个命令是否是外部命令： 1234# which awk/usr/bin/awk# which ./usr/bin/which: no . in (/opt/rh/rh-python34/root/usr/bin:/usr/java/default/bin/:/usr/local/git/bin:/opt/ActiveTcl-8.5/bin:/root/perl5/bin:/root/env/maven/apache-maven-3.3.3/bin:/root/soft/wrk/wrk-4.0.1:/root/usr/go/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin) 总结一下，通过which查询出来的是其外部命令版本，通过type默认查询出来的是内部命令： 1234# which echo/usr/bin/echo# type echoecho is a shell builtin 对于内部命令的详细说明，可以查看GNU的文档。 别名可以用alias命令给一个命令取一个别名： 12345# alias print=echo# print &quot;hello&quot;hello# type printprint is aliased to `echo&apos; 别名一个常用的用法是用来缩写已知的命令： 12# type lsls is aliased to `ls --color=auto&apos; 可见ls命令实际上是命令ls --color=auto的别名，这样就相当于改变了ls命令的默认行为了。在这种情况下，如果仍然想用原先的命令，可以在别名前加反斜杠\\： 1234# type lsls is aliased to `ls --color=auto&apos;# \\lsTest1 test2 test.cpp test.log time.log 前面咱们通过type命令来查看命令的别名，实际上更加推荐采用alias或者which来查看： 12345# alias lsalias ls=&apos;ls --color=auto&apos;# which lsalias ls=&apos;ls --color=auto&apos; /usr/bin/ls 如果要取消别名，则可以采用unalias命令: 123456# which lsalias ls=&apos;ls --color=auto&apos; /usr/bin/ls# unalias ls# which ls/usr/bin/ls 显示shell展开的结果由于shell展开的存在，你输入的命令被展开之后可能会发生变化，如果需要知道shell展开之后的命令，可以使用内部命令set来修改shell的默认参数来显示： 123456# set -x++ printf &apos;\\033]0;%s@%s:%s\\007&apos; root traffic-base1 &apos;~&apos;# echo hello world+ echo hello worldhello world++ printf &apos;\\033]0;%s@%s:%s\\007&apos; root traffic-base1 &apos;~&apos; 其中，以+开头的就是展开之后的命令，可见展开之后，shell将多余的空格去掉了。如果不要再显示了，可以输入命令set +x。 shell控制操作符 (Control Operators）$?操作符每个命令执行完后都会有个退出码（Exit Code），其值为0时表示命令成功，否则命令失败。这个退出码可以通过$?来访问，执行完命令后立马访问$?可以获取该命令的退出码，并以此来判断命令是否成功。每个命令的执行都会产生新的退出码，所以请务必在命令执行完，立刻访问$?来获取退出码。 初看起来，$?似乎是一个shell变量，但实际上并非如此，因为你无法对$?赋值。$?准确来说是shell的一个内部参数。 分号;shell命令输入时，你可以将多个命令输入在一行，只要在不同命令之间以分号;隔开，当然分号不能是在引号中。 必须注意的是，如果将多个命令以;连接在一起，执行的结果通过$?查询出来将只是最后一个命令的结果 &amp;符号通常情况下，shell会在前台执行命令，并等待命令结束才返回。如果需要将命令放到后台去执行，可以使用&amp;符号放在命令最后面，这样的话命令会被放在后台执行，shell会立刻返回而不用等待命令结束。 注意的是，即便放在后台执行，但是如果不处理好命令的输入，则命令的输出可能会继续在当前的终端输出，后面会讲述如何处理命令的输出。 &amp;&amp;操作符此操作符表示逻辑与，你可以将两个命令用此操作符连接起来，如cmd1 &amp;&amp; cmd2，只有当cmd1执行成功之后，cmd2才会被执行。这里的成功指的是cmd1的退出码是0。 12345# hello &amp;&amp; echo world-bash: hello: command not found# echo hello &amp;&amp; echo worldhelloworld 当然，&amp;&amp;也可以将多个命令连接起来，其执行类似，只有当前面的命令成功，后面的才会执行。因此，将多个命令写在一行用&amp;&amp;可以实现，只不过&amp;&amp;必须按照逻辑与的关系执行，而;号的话会执行所有的命令。 ||操作符很显然，与&amp;&amp;相对，||操作符表示逻辑或的关系，同样可以连接两个命令，如cmd1 || cmd2，只有当cmd1失败了，才会执行cmd2，这里的失败指的是cmd1的退出码非0。 &amp;&amp;与||混合这两个操作符是可以混合使用的，其遵循的原则保持一致，且是从左向右依次判断，结合这两种操作符，可以实现类似于if then else的逻辑结构。如cmd1 &amp;&amp; cmd2 || cmd3意思就是如果cmd1成功，则执行cmd2，否则执行cmd3。但务必注意的是，此处并非真正意思上的if then else逻辑，因为如果cmd2也执行失败，cmd3其实也会被执行。如下例： 1234567# echo hello &amp;&amp; echo ok || echo worldhellook# echo hello &amp;&amp; rm dfsdf || echo worldhellorm: cannot remove ‘dfsdf’: No such file or directoryworld &amp;&amp;相当于将两条命令逻辑上连成了一条命令，这样就变成了cmd1-2 || cmd3，其中cmd1-2就是cmd1 &amp;&amp; cmd2，因此，cmd3只要在cmd1-2失败的情况下都会被执行，而cmd1-2失败的情况有两种，一种是cmd1失败，一种是cmd1成功但是cmd2失败。同样的，||也会将两条命令连成一条命令，如cmd1-2 || cmd3 &amp;&amp; cmd4就相当于cmd1-2_3 &amp;&amp; cmd4，cmd4是否会执行，决定于cmd1-2_3是否失败，以具体例子说明： 12345# echo hello &amp;&amp; echo ok || echo world &amp;&amp; rm dsdfsf || echo endhellookrm: cannot remove ‘dsdfsf’: No such file or directoryend 这行命令相当于cmd1 &amp;&amp; cmd2 || cmd3 &amp;&amp; cmd4 || cmd5，可以看出cmd1，cmd2，cmd4还是有cmd5被执行了，而cmd3没有执行。咱们来解析一下，为何是如此的执行结果。首先，shell从左往右扫描执行： 发现cmd1 &amp;&amp; cmd2，由&amp;&amp;连成一个命令cmd1-2，因为两个命令都是成功的，所以都被执行了，这样可以认为cmd1-2成功 执行成功之后，接下来是||操作符，这里并不会因为前面的命令是成功的，而不再执行后面所有的命令，而是||操作符相当于将cmd1-2与cmd3连接成了cmd1-2_3，因为cmd1-2成功了，所以cmd3不再执行，但是cmd1-2_3相当于执行成功了 继续执行，发现是&amp;&amp;操作符，同样将cmd1-2_3与cmd4连接起来，记为cmd1-2_3-4，因为cmd1-2_3执行成功了，所以cmd4也被执行，但是cmd4执行失败了，所以cmd1-2_3-4相当于执行失败 继续执行，发现是||操作符，同样将cmd1-2_3-4与cmd5连成cmd1-2_3-4_5，因为cmd1-2_3-4执行失败，所以cmd5被执行 可见，shell永远都是从左往右扫描执行，&amp;&amp;跟||会将前后两个命令连接起来，根据两种操作符的规则就可以知道多个连起来的命令是如何执行的了。 #符号跟其它很多语言一样，#在shell里面用来注释。 \\转义符号\\符号可以用来转义一些特殊符号，如$，#等。 特别指出的是，如果转义符号放在行末单独使用，则用来连接下一行。 shell变量基本概念定义跟引用shell中也可以使用变量，变量不需要像其它语言一样需要预先申明。shell中赋值给一个不存在的变量就相当于定义了变量，如name=&quot;Mr. Hao&quot;，就定义了name变量，后续如果再对name赋值，就相当于改变改变量的值。与很多语言不同的是，shell中变量引用以$符号开头，后面跟变量的名字。如前面的变量，引用如下echo &quot;$name&quot;。需要注意的是，在shell中，变量名是大小写敏感的。 在shell展开中会自动展开变量的引用，即便该变量处在双引号中。但是，如果变量引用在单引号中，shell不会对其进行解析。 1234567# name=&quot;Mr. Hao&quot;# echo &quot;$name&quot;Mr. Hao# set -x# echo &apos;$name&apos;+ echo &apos;Mr. Hao&apos;$name 查找变量可以使用set命令来查找所定义的变量： 12# set | grep -E &apos;^name=&apos;name=&apos;Mr. Hao&apos; 删除变量与很多语言不同的是，在shell中定义的变量是可以删除的，使用unset命令删除定义的变量。 1234# set | grep -E &apos;^name=&apos;name=&apos;Mr. Hao&apos;# unset name# set | grep -E &apos;^name=&apos; export声明通常情况下，shell在执行命令的时候会为该命令创建子进程。如果希望将当前的变量作用到子进程，则需要将变量export声明，这种变量称之为环境变量，如： 12345# var1=&quot;hello&quot;# export var2=&quot;world&quot;# bash# echo &quot;var1=$var1, var2=$var2&quot;var1=, var2=world 其中，bash命令开启了一个新的shell，可见只有export声明的变量在新的shell中才是可见的。环境变量可以通过env命令列举出来，在后面一节会详细讲述。此外，如果需要将非export变量重新声明为export变量，则只需要用export重新声明一下即可： 12345# var1=hello# env | grep var1# export var1# env | grep var1var1=hello env命令如果需要查看当前shell中有哪些export声明的变量，可以使用env命令，该命令会列出当前所有export声明的变量。请注意与set命令的区别，set命令会列出所有的变量，包括哪些不是export声明的变量。通常，我们把env命令输出的变量称之为环境变量。 此外，env也常用来为子shell预先定义一些临时变量，如： 12345# var1=&quot;hello&quot;# env var1=&quot;tmp&quot; bash -c &apos;echo &quot;$var1&quot;&apos;tmp# echo $var1hello 其中，用env命令定义了临时变量var1，然后bash命令开启了一个子shell，并在子shell中执行了echo &quot;$var1&quot;命令。可见，输出了定义的临时变量，在命令结束后，又回到之前的shell，输出的也是之前shell中定义的值。当然，在使用env定义临时变量的时候，为了方便，通常我们可以省略env命令，如： 12345# var1=&quot;hello&quot;# var1=&quot;tmp&quot; bash -c &apos;echo &quot;$var1&quot;&apos;tmp# echo $var1hello 另外，env命令还有一种常用的用法，就是用来开启一个干净的子shell，即在子shell中不继承所有的变量，即便这些变量在之前的shell中采用export声明，此时env命令需要加入-i的参数，如： 12345# export var1=&quot;hello world&quot;# bash -c &apos;echo &quot;var1=$var1&quot;&apos;var1=hello world# env -i bash -c &apos;echo &quot;var1=$var1&quot;&apos;var1= 可见，使用env -i之后，即便var1被export声明，但是在子shell中也没有被继承。 变量解释在前面章节，我们知道shell采用$符号引用变量，在$符号后紧跟变量的名字。而shell在提取变量名字的时候一般以非字母数字（non-alphanumeric）为边界，这有时候就会产生问题，如： 123# prefix=Super# echo Hello $prefixman and $prefixgirlHello and 可见，shell并不能提取我们定义的变量prefix，因为其后并没有非字母数字的字符为界。这种情况下，我们可以使用{}将变量名保护起来。 123# prefix=Super# echo Hello $&#123;prefix&#125;man and $&#123;prefix&#125;girlHello Superman and Supergirl 非绑定（unbound）变量所谓非绑定（unbound）变量其实指的是没有预先定义的变量，或者说不存在的变量。默认情况下，shell在解释这种变量的时候会以空字符串替代： 1# echo $unbound_var 如果需要shell在这种情况下报错，可以配置shell选项set -o nounset，或者简写为set -u： 1234# echo $unbound_varbash: unbound_var: unbound variable# set +u# echo $unbound_var 当然，由例子中可以看到，要取消该配置，可以相应的设置set +o nounset，或者简写为set +u。 特殊变量在shell中预定义了很多特殊的变量，这一节咱们来说一下常见的几个变量。 $PS1变量在shell终端输入命令时，咱们总是可以看到在输入行首总是会有提示符，如： 1mrhao:~$ 其中，mrhao:~$就是提示符，这个字串实际上是由shell变量$PS1决定的。如果咱们改变一下该变量的值，提示符也会相应的改变： 1234mrhao:~$ PS1=&quot;hello &gt; &quot;hello &gt; echo &quot;PS1 value is &apos;$PS1&apos;&quot;PS1 value is &apos;hello &gt; &apos;hello &gt; 为了方便在提示符中显示系统的某些实时信息，$PS1变量定义了一些特殊的字符： |——+——————–|| 字符 | 说明 ||——+——————–|| \\w | 表示工作目录 || \\u | 表示用户名 || \\h | 表示系统的hostname ||——+——————–| 当然，这里只列举了几个，详细的可以查看Linux手册。另外，$PS1中还可以对对其中不同部分采用不同颜色显示，如： 1234567# RED=&apos;\\[\\033[01;31m\\]&apos;# WHITE=&apos;\\[\\033[01;00m\\]&apos;# GREEN=&apos;\\[\\033[01;32m\\]&apos;# BLUE=&apos;\\[\\033[01;34m\\]&apos;# PS1=&quot;$GREEN\\u$WHITE@$BLUE\\h$WHITE\\w\\$ &quot;mrhao@mrhao-host~$ echo &quot;$PS1&quot;\\[\\033[01;32m\\]\\u\\[\\033[01;00m\\]@\\[\\033[01;34m\\]\\h\\[\\033[01;00m\\]\\w$ $PATH变量当我们在Linux的terminal里面输入命令的时候，shell需要在一系列的目录中查找输入的命令，如果没有查找到会直接报command not found的错误。而这些查找的目录就定义在$PATH变量中。 12# echo $PATH/opt/rh/rh-python34/root/usr/bin:/usr/java/default/bin/:/usr/local/git/bin:/opt/ActiveTcl-8.5/bin:/root/perl5/bin:/root/env/maven/apache-maven-3.3.3/bin:/root/soft/wrk/wrk-4.0.1:/root/usr/go/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin 其中，每个目录以:隔开，如果需要增加目录，可以： 123# PATH=$PATH:/opt/local/bin# echo $PATH/opt/rh/rh-python34/root/usr/bin:/usr/java/default/bin/:/usr/local/git/bin:/opt/ActiveTcl-8.5/bin:/root/perl5/bin:/root/env/maven/apache-maven-3.3.3/bin:/root/soft/wrk/wrk-4.0.1:/root/usr/go/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/opt/local/bin 加入新的路径的时候请务必带上之前的路径，$PATH:&lt;new path&gt;否则，很多默认的系统路径将被覆盖，导致很多命令失效。 特别注意的是，$PATH变量中目录的顺序是很重要的，如果shell在前面的目录中找到了命令，则不会查找后面的目录。如果你想把某个重名的命令优先执行，就需要把它对应的目录放在$PATH的前面。 网络代理变量在Linux系统中，很多时候我们需要访问外部网络，比如使用curl命令下载文件等等。而有的时候，访问访问外部网络咱们需要设置代理，在Linux系统中，使用网络代理非常简单，只要配置几个变量即可： |————-+————————————————————————-|| 变量 | 说明 ||————-+————————————————————————-|| http_proxy | 设置访问http请求所需要的代理，如http_proxy=http://10.10.10.100:80 || https_proxy | 设置访问https请求所需要的代理，如https_proxy=http://10.10.10.100:80 || ftp_proxy | 设置访问ftp请求所需要的代理，如ftp_proxy=http://10.10.10.100:80 || no_proxy | 设置哪些域名或者IP不需要走代理，如no_proxy=localhost,127.0.0.1 ||————-+————————————————————————-| $PWD变量PWD变量是一个由shell自动设置的变量，其值表示当前目录的绝对路径，与命令pwd输出相同。 shell嵌入与shell选项shell嵌入（shell embedding）shell可以嵌入在同一个命令行中，也就是shell在扫描解释命令行的时候，可能会从当前的shell进程中fork出一个新的shell进程，并将有关命令放在新进程中运行。如下例： 12345# var1=hello# echo $(var1=world; echo $var1)world# echo $var1hello 如其中$()便开启了一个新的shell进程，或者成为子shell，并在此shell中运行命令var1=world; echo $var1，此时输出的是子shell中定义的var1。当命令结束后，子shell进程退出，并将输出的结果world返回给之前的shell（或者父shell）的echo命令，父shell最后输出world。而且，在子shell中定义相同的var1变量并不会改变父shell中的变量。 特别注意的是，因为子shell是fork出来的进程，根据Linux进程fork的特点，子进程将共享父进程的数据空间，而只在写的时候拷贝新的数据空间，因此，创建出来的子shell是会继承所有父shell的变量，不论该变量是否被export声明 1234# var1=hello# var2=&quot;$(echo $var1 world)&quot;# echo $var2hello world 可见，虽然var1变量没有export声明，但是在子shell中还是可见的。这点与使用bash -c开启的shell是不同的。 用$()可以将子shell嵌入到命令行中，当然，$()是可以嵌套使用的，这样可以用来在子shell中开启它的子shell。 123# A=shell# echo $C$B$A $(B=sub;echo $C$B$A; echo $(C=sub;echo $C$B$A))shell subshell subsubshell 反引号（backticks）在上面我们可以通过$()将子shell嵌入命令行中，为了方便，我们同样可以用反引号` 将子shell嵌入。 12345# var1=hello# echo `var1=world; echo $var1`world# echo $var1hello 但是，使用反引号不能够嵌套子shell，因此如果需要嵌套子shell时，只能使用$()。 反引号跟单引号是本质的不同的，单引号与双引号一样，用来将连续的字串作为整体引起来，只不过单引号中将不执行变量的引用解析，而反引号则是嵌入子shell。 shell选项其实在前面咱们已经使用了不少shell的选项，如set -u在变量不存在是报错，set -x将shell展开的结果显示出来等。此外，可以才用echo $-将当期设置的shell选项打印出来。 shell历史记录在shell中执行命令的时候，shell会将最近的命令使用历史记录下来，这样你可以很方便的查看最近做了什么操作。 查看历史记录命令history可以用来查看shell的历史记录，里面记录了你最近输入的所有命令。当然，很多时候你更加关心最近的几个命令，你可以使用history 10来显示最近的10个命令。另外，shell通常还会将最近的历史记录写在~/.bash_history文件中，因此查看该文件同样可以查看历史记录。 执行历史的命令shell提供了很多高级用法使得你可以很方便的执行以前执行过的命令。 首先，咱们先显示一下过去的10个命令，可以看到每个命令前面都有其对应的序号。 1234567891011# history 10 1000 history 1001 history 10 1002 echo &quot;hello world&quot; 1003 ls -l 1004 ps -ef | grep named 1005 env | grep http 1006 grep hello /var/log/messages 1007 tmux ls 1008 find . -name &quot;hello&quot; 1009 history 10 下面列举比较常用的shell重复执行历史记录中命令的方法： |———–+——————————————————————————————————-|| 命令 | 说明 ||———–+——————————————————————————————————-|| !! | 在shell中输入两个感叹号会执行上一个命令 || !keyword | 输入一个感叹号后跟关键字，会搜索历史记录中最先以该关键字开始的命令。如!find会执行序号为1008的命令。 || !?keyword | 执行历史记录中第一个包括keyword关键字的命令 || !n | 其中n代表历史记录中的序号，表示执行序号为n的命令。 || !-n | 执行倒数第n个命令，如!-1其实就相当于!! || cmd! | 执行命令cmd，其中`!`会以上一条命令的所有参数替代 ||———–+——————————————————————————————————-| 另外，对于!keyword的用法，还有一个高级功能，你可以将符合该条件的命令进行改造后执行，如： 12345# echo &quot;test1&quot;test1# !ec:s/1/2/echo &quot;test2&quot;test2 其中，:s/1/2/将命令echo &quot;test1&quot;替换成echo &quot;test2&quot;然后执行了。对于cmd!*，示例如下： 123456789# ctt /etc/passwd | cut -d: -f1-bash: ctt: command not found# cat !*cat /etc/passwd | cut -d: -f1rootbindaemonadm... 搜索历史记录在shell终端中按Ctrl-r会打开shell的搜索模式，在改模式下输入关键字会显示最近包含改关键字的命令，再按一下Ctrl-r会继续显示前面一条符合条件的命令，找到你需要的命令后回车就可以执行改命令了。 修改历史记录的有关配置有多个配置可以用来改变历史记录的有关信息，通常都是通过有关环境变量来配置： |—————+——————————————————————————————–|| 环境变量 | 说明 ||—————+——————————————————————————————–|| $HISTSIZE | 这个变量用来配置shell应该保持多少行的历史记录，在很多发行版本中，默认值一般为500或者1000 || $HISTFILE | 这个变量用来配置历史记录文件存放的位置，通常来讲，默认路径为~/.bash_history || $HISTFILESIZE | 这个变量用来配置历史记录文件可以存放多少行的历史记录 ||—————+——————————————————————————————–| 阻止记录某些命令在有些时候，我们并不想把某些命令记录在历史记录中，比如有的命令里面包括了敏感信息如密码等。在新版本的shell中，通常我们可以在输入的命令前面加入空格，这样shell就不会记录这样的命令，当然，如果你的发行版本默认并不支持，你可以配置环境变量来打开这个功能： 1export HISTIGNORE=\"[ \\t]*\" 例如： 1234567891011121314151617181920212223242526272829# history 5 1023 ls -l 1024 echo &quot;&quot; 1025 history 5 1026 ls 1027 history 5# echo &quot;password=123456&quot;password=123456# history 5 1025 history 5 1026 ls 1027 history 5 1028 echo &quot;password=123456&quot; 1029 history 5# export HISTIGNORE=&quot;[ \\t]*&quot;# history 5 1027 history 5 1028 echo &quot;password=123456&quot; 1029 history 5 1030 export HISTIGNORE=&quot;[ \\t]*&quot; 1031 history 5# echo &quot;password=123456&quot;password=123456# history 5 1027 history 5 1028 echo &quot;password=123456&quot; 1029 history 5 1030 export HISTIGNORE=&quot;[ \\t]*&quot; 1031 history 5 可见，在设置$HISTIGNORE变量之后，在前面加了空格的命令将不再记录。这在保护敏感信息的时候非常有用。 文件匹配(File Globbing)文件匹配(File Globbing)又成为动态文件名生成，用它可以非常方便的在shell中输入文件名。 *星号*星号在shell中用来匹配任意数量的字符，比如文件名File*.mp4，将匹配以File开头，.mp4结尾的任何文件名。shell在扫描解释命令的时候会自动去查找符合该匹配的所有文件或目录。当然，你也可以只用*来匹配所有的文件及目录，但请注意，只使用*跟不带*还是有所区别的， 1234567# lsdefinition.yaml example __init__.py tags.yaml test.py test_sample.html test_sample.py# ls *definition.yaml __init__.py tags.yaml test.py test_sample.html test_sample.pyexample:testcase 可见，带上*后不仅把当前目录的所有文件及目录显示出来，而且还把目录下的内容显示出来了。 ?问号问号用来匹配一个字符，如File?.mp4可以匹配File1.mp4。 []方括号[]方括号也用来匹配一个字符，但是在括号里面可以指定一个字符集用来限定匹配的字符必须在该字符集内，字符集里面的字符顺序没有关系。 12345678# lsfile1 file2 file3 File4 File55 FileA fileab Fileab FileAB fileabc# ls File[5A]FileA# ls File[A5]FileA# ls File[A5][5b]File55 如果需要匹配不在某个字符集里面的字符，可以在[]第一个字符加入!： 12# ls file[!5]*file1 file2 file3 fileab fileabc 特别的，为了方便，[]中可以使用-来定义一些连续的字符集（Range匹配），常用的这类字符集包括： |——–+——————–|| 字符集 | 说明 ||——–+——————–|| 0-9 | 表示数字字符集 || a-z | 表示小写字母字符集 || A-Z | 表示大写字母字符集 ||——–+——————–| 当然，你也不必要把所有范围都包括在内，如[a-d]可以用来限定从a到d的小写字母集。另外，用-连起来的字符集还可以跟其它字符集一起使用，如[a-d_]表示a到d的小写字母加上_所组成的字符集。 Range匹配的大小写问题 对于[]的Range匹配，还有一点很重要。在很多发行版本中，默认情况下，[]的Range匹配是忽略大小写的 12345678910# lsTest1 test2# ls [a-z]*Test1 test2# ls [A-Z]*Test1 test2# ls [t]*test2# ls [T]*Test1 注意，是[]的Range匹配会忽略大小写，而如果不是Range匹配还是大小写敏感的： 1234567&gt; # ls&gt; Test1 test2&gt; # ls [T]*&gt; Test1&gt; # ls [t]*&gt; test2&gt; 如果需要大小写敏感，可以设置环境变量LC_ALL： 12345# LC_ALL=C# ls [a-z]*test2# ls [A-Z]*Test1 当然，请务必注意，LC_ALL的会改变当前的语言环境，还请慎重使用，建议只在临时的子shell中使用。 阻止文件匹配(File Globbing)有时候我们就是需要输出*等匹配符号，这个时候就需要阻止shell做相应的匹配。可以使用转义符号\\来做到这点，或者将匹配符号放在引号中： 12345678# echo *Test1 test2# echo \\**# echo &apos;*&apos;*# echo &quot;*&quot;* shell快捷键shell中支持非常多的快捷键，可以非常方便我们输入命令： |——–+—————————————————————————|| 快捷键 | 说明 ||——–+—————————————————————————|| Ctrl-d | 表示EOF的意思，在shell终端中输入该快捷键会退出该终端 || Ctrl-z | 该快捷键用来暂停一个在shell终端中正在执行的进程，暂停后可以用fg命令恢复 || Ctrl-a | 输入命令时跳到行首 || Ctrl-e | 跳到行尾 || Ctrl-k | 删除从光标到行尾的部分 || Ctrl-y | 粘贴刚刚删除的部分 || Ctrl-w | 删除从光标至其左边第一个空格处 ||——–+—————————————————————————|","categories":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/tags/Linux/"},{"name":"study","slug":"study","permalink":"http://github.com/tags/study/"}]},{"title":"Linux学习（二）文件系统结构","slug":"Linux学习（二）文件系统结构","date":"2018-04-14T14:57:29.000Z","updated":"2018-04-14T15:02:36.116Z","comments":true,"path":"2018/04/14/Linux学习（二）文件系统结构/","link":"","permalink":"http://github.com/2018/04/14/Linux学习（二）文件系统结构/","excerpt":"概述多数Linux发行版本都是遵循文件系统结构标准（Filesystem Hierarchy Standard, 简称FHS），可以在这里找到该标准。本文对Linux的文件系统结构进行简单的介绍。 根目录/所有的Linux系统都有根目录，由/表示。Linux系统的所有内容都在该目录下。 二进制目录|—————-+——————————————————————————————————————–|| 目录 | 说明 ||—————-+——————————————————————————————————————–|| /bin | 包括了可执行的二进制文件，通常这些二进制文件可以被所有用户访问。FHS规定，该目录至少包括/bin/cat跟/bin/date文件 || /sbin | 包括了系统的二进制文件，通过需要root权限，用来配置系统 || /lib | 包括了/bin所依赖的库 || /lib/modules | Linux将从/lib/modules/$kernel-version/目录下载入内核模块 || /lib32和/lib64 | 顾名思义，分别存放不同位数的库 || /opt | 该目录用来存放一些可选的软件，通常情况下，很多第三方的客户软件会选择安装在该目录下 ||—————-+——————————————————————————————————————–|","text":"概述多数Linux发行版本都是遵循文件系统结构标准（Filesystem Hierarchy Standard, 简称FHS），可以在这里找到该标准。本文对Linux的文件系统结构进行简单的介绍。 根目录/所有的Linux系统都有根目录，由/表示。Linux系统的所有内容都在该目录下。 二进制目录|—————-+——————————————————————————————————————–|| 目录 | 说明 ||—————-+——————————————————————————————————————–|| /bin | 包括了可执行的二进制文件，通常这些二进制文件可以被所有用户访问。FHS规定，该目录至少包括/bin/cat跟/bin/date文件 || /sbin | 包括了系统的二进制文件，通过需要root权限，用来配置系统 || /lib | 包括了/bin所依赖的库 || /lib/modules | Linux将从/lib/modules/$kernel-version/目录下载入内核模块 || /lib32和/lib64 | 顾名思义，分别存放不同位数的库 || /opt | 该目录用来存放一些可选的软件，通常情况下，很多第三方的客户软件会选择安装在该目录下 ||—————-+——————————————————————————————————————–| 配置文件目录|—————-+————————————————————————————————————————–|| 目录 | 说明 ||—————-+————————————————————————————————————————–|| /boot | 顾名思义，用来存放系统启动的配置文件，如grub引导的配置文件/boot/grub/grub.cfg || /etc | 几乎大部分配置文件都放在改目录下。历史上etc的全称是etcetera，不过，现在一般认为是Editable Text Configuration的缩写 || /etc/init.d | 存放daemon启动、停止等的脚本文件。不过在引入systemd之后，启动脚本有所变化 || /etc/skel | 存放创建新用户之后所需的配置文件的模板，如.bashrc文件，默认会从该目录拷贝到用户目录 || /etc/sysconfig | 一般出现在RedHat系列的Linux系统中，存放系统有关配置，如IP的配置文件等 ||—————-+————————————————————————————————————————–| 数据目录|——–+—————————————————————————————————-|| 目录 | 说明 ||——–+—————————————————————————————————-|| /home | 当创建一个新用户的时候，默认情况下，系统会为用户创建一个/home/&lt;username&gt;的目录用来存放个人数据。 || /root | 该目录被很多Linux系统用来存放root用户的个人数据 || /srv | 可以被解释为served by your system。FHS允许rsync，ftp，www等数据存放在改目录 || /media | 该目录通常被用来挂载可移除设备，如CD-ROM，U盘等 || /mnt | 根据FHS，该目录通常被用来作为短期的挂载点 || /tmp | 该目录用来存放一些短期的文件，不要再该目录下存放重要文件，该目录下的文件有可能会被系统回收 ||——–+—————————————————————————————————-| 内存目录Linux系统中，几乎所有的东西都被映射成文件，文件有的是对应着硬盘、设备（CD-ROM等）等，有的则被Linux映射到内存中。这一节介绍映射到内存中的目录。 /dev目录/dev目录映射了各种设备文件，这些文件由系统启动的时候扫描硬件生成。 物理设备文件物理设备包括很多种，如硬盘，CD-ROM等。不同的物理设备映射为/dev目录下不同的文件。如SATA/SCSI设备或USB通常被映射为/dev/sd*，其中*可以为[a-z]中的任意字符；而IDE设备通常被映射为/dev/hd*，其中*为[a-z]中任意字符。 /dev/tty跟/dev/pts首先需要搞清楚tty设备跟pts设备的区别。这两者都是终端设备，所谓终端设备通常指的是能够接受命令输入，并可能同时能够输出的设备，但是这两者是有本质的不同的： tty设备 tty是Teletype的简称，表示原生的终端设备，通常指的是物理终端设备如串口，键鼠接口等，以及系统内核模拟的终端设备。 pts设备 pts是Pseudo Terminal Slave的简称，表示伪终端设备，通常由应用进程模拟出来，如ssh开启的终端等。 tty设备通常被映射为/dev/tty*，其中*代表数字，如/dev/tty1等。而pts设备被映射为/dev/pts/*，其中*表示数字，如/dev/pts/1。 /dev/null该文件在Linux中有着特殊的意义，是一个只有输入的文件，且文件有无限的大小，你不能从该文件读出任何东西，任何写入的内容逻辑上相当于消失了。从实现的角度，实际上任何写入的内容都被系统丢弃了。 /proc目录该目录用来记录内核以及内核进程的实时信息，可以通过它轻而易举的实现对内核状态的获取甚至改变。 |——————+——————————————————————————————————————-|| 目录 | 说明 ||——————+——————————————————————————————————————-|| /proc/ | 几乎每个进程都会在该目录下有映射的文件/proc/*，其中&lt;id&gt;代表进程的ID。该目录记录的该进程的几乎所有的状态信息。 || /proc/cpuinfo | 记录了系统的CPU信息，通常通过该文件可以知道系统有多少个CPU（核数）。 || /proc/meminfo | 记录了系统的内存信息，可以通过它知道系统有多少内存 || /proc/sys | 在/proc目录下的绝大部分文件都是只读的文件，但是在该目录下有些文件是可写的，可以通过它们改变内核状态 || /proc/interrupts | 记录了当前系统的中断信息 || /proc/kcore | 这个文件代表了系统的物理内存，其大小就是物理内存的大小，因此千万不要用cat来试图显示该文件内容 ||——————+——————————————————————————————————————-| /usr目录/usr目录估计是被误解最多的目录，一般大家都以为它是user的简写，感觉应该存放的是用户相关的东西，但是实际上完全不是这样。它其实是Unix System Resources的简写，表示Unix系统资源。通常情况下，该目录以只读的权限被挂载。 |————–+————————————————————————————————————-|| 目录 | 说明 ||————–+————————————————————————————————————-|| /usr/bin | 很多命令都存放在这个目录下面，事实上，在Centos跟Solaris系统中，/bin目录实际上只是一个软连接，连接到此目录 || /usr/include | 存放大量的头文件，可能会被C代码引用 || /usr/lib | 存放库文件，同样，在Centos跟Solaris系统中，/lib其实就是软连接到此目录 || /usr/lib64 | 存放64位的库文件，在Centos中，/lib64也是软连接到此目录 || /usr/sbin | 很多daemon程序都是放在此目录下，在Centos中，/sbin也是软连接到此目录 || /usr/local | 此目录通常用来安装一些本地的应用 || /usr/share | 此目录通常用来存放各种体系无关的数据。/usr/share/man就是用来存放man命令用到的帮助文档 || /usr/src | 此目录通常存放内核的代码文件 ||————–+————————————————————————————————————-| /var目录/var目录用来存放可变的数据，如日志，数据库文件等。 |——————-+————————————————————————————————————-|| 目录 | 说明 ||——————-+————————————————————————————————————-|| /var/log | 此目录用来存放各种日志文件，包括系统跟应用的日志 || /var/log/messages | 在RedHat系列系统中，此文件用来记录系统刚刚发生的事情。在Debian和Ubuntu系统中，对应的文件是/var/log/syslog || /var/cache | 此目录存放很多应用的缓存数据，如yum命令可能会缓存部分数据在此目录 || /var/spool | 一般情况下，该目录会存放邮件cron任务等数据 || /var/lib | 通常此目录下会存放应用的状态信息，如/var/lib/mysql存放mysql数据库，/var/lib/docker存放docker的数据 ||——————-+————————————————————————————————————-|","categories":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/tags/Linux/"},{"name":"study","slug":"study","permalink":"http://github.com/tags/study/"}]},{"title":"Linux学习（一）命令行","slug":"Linux学习（一）命令行","date":"2018-04-14T14:54:30.000Z","updated":"2018-04-14T14:56:29.745Z","comments":true,"path":"2018/04/14/Linux学习（一）命令行/","link":"","permalink":"http://github.com/2018/04/14/Linux学习（一）命令行/","excerpt":"概述随着Linux的发展，现在已经有了非常多的桌面版本，比如著名的Ubuntu。用这些桌面版本系统，可以满足基本的操作，然而对于一些高级点的操作，还是离不开Linux的命令行(Command Line)。而Linux的精髓也更多的体现在命令行上，其强大的功能，海量的工具，可以帮你轻而易举的完成各种复杂的系统管理操作。本文将详细讲述Linux命令行。 基础命令帮助类manLinux有着海量的命令，而每个命令又有很多的不同参数，要记住所有的这些命令是比较困难的，因此，在使用Linux命令行的时候，必须时刻记着查看Linux的帮助，而查看帮助就是采用man命令。","text":"概述随着Linux的发展，现在已经有了非常多的桌面版本，比如著名的Ubuntu。用这些桌面版本系统，可以满足基本的操作，然而对于一些高级点的操作，还是离不开Linux的命令行(Command Line)。而Linux的精髓也更多的体现在命令行上，其强大的功能，海量的工具，可以帮你轻而易举的完成各种复杂的系统管理操作。本文将详细讲述Linux命令行。 基础命令帮助类manLinux有着海量的命令，而每个命令又有很多的不同参数，要记住所有的这些命令是比较困难的，因此，在使用Linux命令行的时候，必须时刻记着查看Linux的帮助，而查看帮助就是采用man命令。 查看命令帮助 以ls命令为例，如果要查看帮助的话可以输入man ls，查看基本的帮助信息也可以直接ls --help。其将以分页的形式显示该命令的完整文档，操作该文档的基本命令有： 按u上翻页 按d下翻页 按空格下翻页 按回车下移一行 按/进入搜索模式，输入要搜索的关键字，按回车搜索。 按n搜索下一个 按N搜索上一个 按q退出查看 查看配置文件的帮助 有些系统的配置文件也同样有对应的帮助文档，可以通过man $configfile来查看，比如/etc/system/sysctl.conf配置文件，查看其帮助可以采用命令man sysctl.conf。 查看后台进程(daemon)的帮助 Linux在后台运行着很多的程序（称为daemon），如果需要查看某个daemon的帮助，可以用命令man $daemon来查看。如man ntpd将查看时间同步daemon的帮助文档。 搜索需要查看的命令 Linux命令实在太多，有时候如果不记得准确的命令的名字，可以采用man -k $keyword来搜索，如man -k syslog将列出相关命令： 12345# man -k syslogipmievd (8) - IPMI event daemon for sending events to sysloglogger (1) - a shell command interface to the syslog(3) system log modulersyslog.conf (5) - rsyslogd(8) configuration filersyslogd (8) - reliable and extended syslogd whatisman命令将展示完整的文档，可以通过whatis来查看命令的简单介绍。 whereis如果需要知道某个命令的完整路径，可以采用whereis $command来查看。 目录操作类|———-+——————————————|| 命令 | 解释 ||———-+——————————————|| pwd | 查看当前目录路径 || cd $path | 切换到其它路径 || cd ~ | 返回home目录 || cd .. | 返回上一级 || cd - | 返回上一次的目录 || ls $path | 查看目录下的内容 || ls -a | 显示目录下所有文件，包括隐藏文件 || ls -lh | 列表的形式显示，-h以可读的方式显示大小 || mkdir | 创建目录，要递归创建采用mkdir -p ||———-+——————————————| 文件操作类说明 大小写敏感 在Linux系统中，文件名都是大小写敏感的。 所有都是文件 Linux基本上将文件，目录，设备等等都视为文件。 file命令查看文件的类型，如： 12# file bugs.tgzbugs.tgz: gzip compressed data, from Unix, last modified: Tue Dec 13 01:38:27 2016 可以显示文件的类型及修改时间等信息。查看特殊文件如设备文件的时候，还可以带上-s的参数，这样可以识别更多的信息： 1234# file /dev/sda/dev/sda: block special# file -s /dev/sda/dev/sda: x86 boot sector; partition 1: ID=0x83, active, starthead 32, startsector 2048, 1024000 sectors; partition 2: ID=0x8e, starthead 221, startsector 1026048, 208689152 sectors, code offset 0x63 touchtouch用来创建空文件，或者用来更新文件时间为当前时间。如果加上-t参数，可以为文件设置指定的时间。 1234567891011121314151617181920# dateMon Oct 9 03:19:24 EDT 2017# ls -ltotal 4-rw-r--r--. 1 root root 6 Jun 19 2016 login.html# touch test.txt# ls -ltotal 4-rw-r--r--. 1 root root 6 Jun 19 2016 login.html-rw-r--r--. 1 root root 0 Oct 9 03:19 test.txt# touch login.html# ls -ltotal 4-rw-r--r--. 1 root root 6 Oct 9 03:19 login.html-rw-r--r--. 1 root root 0 Oct 9 03:19 test.txt# touch -t 201701011010 login.html# ls -ltotal 4-rw-r--r--. 1 root root 6 Jan 1 2017 login.html-rw-r--r--. 1 root root 0 Oct 9 03:19 test.txt 删除、复制、移动|——–+————————————————————————————–|| 命令 | 解释 ||——–+————————————————————————————–|| rm | 永久删除一个文件，对于此命令，没有所谓的垃圾箱，请慎重 || rm -i | 询问是否真的要删除 || rm -rf | 通常rm只是删除文件，如果需要删除目录的时候，必须带上-r参数，-f参数表示强制删除 || cp | 拷贝文件 || cp -rf | 拷贝目录下所有的文件，并强制覆盖 || mv | 移动文件到另一个目录，或者在当前目录下对某个文件改名字 ||——–+————————————————————————————–| 文件内容操作类head查看某个文件的头几行，可以用head命令： 12345678# head -n 5 /var/log/messagesOct 9 03:10:01 traffic-base1 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;697&quot; x-info=&quot;http://www.rsyslog.com&quot;] rsyslogd was HUPedOct 9 03:20:01 traffic-base1 systemd: Started Session 79213 of user root.Oct 9 03:20:01 traffic-base1 systemd: Starting Session 79213 of user root.Oct 9 03:28:26 traffic-base1 puppet-agent[14530]: Unable to fetch my node definition, but the agent run will continue:Oct 9 03:28:26 traffic-base1 puppet-agent[14530]: Connection refused - connect(2)# head -c 5 /var/log/messagesOct 其中-n参数表示显示多少行，不带此参数，默认显示10行。-c表示显示多少个字符，这里显示了前面5个字符。 tail与head相反，tail用来显示文件最后几行。同样-n可以用来限制多少行。 tail有个非常重要的用处，就是用来监听某个动态文件的内容，比如实时查看某个日志文件： 12345678# tail -n 5 -F /var/log/messagesOct 9 03:28:27 traffic-base1 puppet: from /usr/share/ruby/vendor_ruby/puppet/util/command_line.rb:146:in `run&apos;Oct 9 03:28:27 traffic-base1 puppet: from /usr/share/ruby/vendor_ruby/puppet/util/command_line.rb:92:in `execute&apos;Oct 9 03:28:27 traffic-base1 puppet: from /usr/bin/puppet:8:in `&lt;main&gt;&apos;Oct 9 03:30:01 traffic-base1 systemd: Started Session 79218 of user root.Oct 9 03:30:01 traffic-base1 systemd: Starting Session 79218 of user root.Oct 9 03:40:01 traffic-base1 systemd: Started Session 79223 of user root.Oct 9 03:40:01 traffic-base1 systemd: Starting Session 79223 of user root. 它将不停的侦听文件的改变，并实时的将最后新写入的行打印出来。 cat $file1 $file2 $file3 …要显示文件的所有内容，可以用cat命令。cat也可以用来创建新文件： 1234# cat &gt; test.txtToday is a good day!# cat test.txtToday is a good day! 这样就可以直接输入文件内容了，输入完成之后按Ctrl+d结束输入。当然，也可以定制结束符： 12345# cat &gt; test.txt &lt;&lt;stop&gt; It&apos;s a good day!&gt; stop# cat test.txtIt&apos;s a good day! tactac名字其实就是cat倒过来写，所以其作用也是一样，就是把文件以倒着的顺序显示出来。 more跟lesscat会直接把整个文件一次性的显示出来，当文件较大时，显示可能会刷屏，这样不利于查看。如果需要以翻页的形式显示文件的内容，可以采用more或者less命令，其查看方式跟man命令的查看方式类似，可以参考前面的说明。 stringsstrings命令会将文件中的可读字符显示出来，即便改文件是一个二进制文件。 123456# strings a.out | tail -n 5_edata_Znwm@@GLIBCXX_3.4_ZN3Out5InnerC1EPS_main_init 其中，a.out是一个二进制文件。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/tags/Linux/"},{"name":"study","slug":"study","permalink":"http://github.com/tags/study/"}]},{"title":"C++学习(一)","slug":"C++学习(一)","date":"2018-04-14T14:18:42.000Z","updated":"2018-04-14T15:30:07.970Z","comments":true,"path":"2018/04/14/C++学习(一)/","link":"","permalink":"http://github.com/2018/04/14/C++学习(一)/","excerpt":"extern与static的作用 extern可以置于变量或者函数前，以标示变量或者函数的定义在别的文件中，提示编译器遇到此变量和函数时在其他模块中寻找其定义。另外，extern &quot;C&quot;语句实现了类C（类C代表的是跟C语言的编译和链接方式一致的所有语言）和C++的混合编程：在C++源文件中的语句前面加上extern “C”，表明它按照类C的编译和链接规约来编译和链接，而不是C++的编译和链接规约，这样在类C的代码中就可以调用C++的函数或变量等，更多详情参考http://www.cnblogs.com/skynet/archive/2010/07/10/1774964.html。 static的作用则与extern“水火不相容”，它限制变量或函数只能在本文件中被访问。","text":"extern与static的作用 extern可以置于变量或者函数前，以标示变量或者函数的定义在别的文件中，提示编译器遇到此变量和函数时在其他模块中寻找其定义。另外，extern &quot;C&quot;语句实现了类C（类C代表的是跟C语言的编译和链接方式一致的所有语言）和C++的混合编程：在C++源文件中的语句前面加上extern “C”，表明它按照类C的编译和链接规约来编译和链接，而不是C++的编译和链接规约，这样在类C的代码中就可以调用C++的函数或变量等，更多详情参考http://www.cnblogs.com/skynet/archive/2010/07/10/1774964.html。 static的作用则与extern“水火不相容”，它限制变量或函数只能在本文件中被访问。 1234567891011121314151617181920// test1.cppint a = 1;int b = 2;int c = a;// test2.cpp#include &lt;iostream&gt;extern int a;// int b = 4;// error: multiple definition of `b`static int c = 5;int main(void) &#123; std::cout &lt;&lt; \"a == \" &lt;&lt; a &lt;&lt; std::endl; // a == 1 std::cout &lt;&lt; \"c == \" &lt;&lt; c &lt;&lt; std::endl; // c == 5 return 0;&#125; 上述代码中， 以extern声明的变量a相当于是两个文件的“全局变量”。 b没有以extern声明，却同时被两个文件都声明了，所以链接时会产生重复定义的错误。 c以static声明，只能在本文件内访问，两个文件各自有一个独立的c，所以不受影响。 new operator、operator new与placement new new operator就是一般所说的new，用法如A* pa = new A()，它是C++操作符，是关键字。它的内部操作有三步：调用下面要讲的operator new分配空间，然后调用相关对象的初始化函数，最后返回指针。 operator new与malloc作用类似，可看成是一个用于分配内存而不构造对象的函数，如A* ptr = (A*)operator new(sizeof(A))。operator new既然可看成一个函数，所以也可以被重载——一般在强调内存分配效率的情况下会考虑重载operator new。 在上一项中，我用operator new分配了一块内存，然后就遇到了一个问题：怎么在这块内存上面构造对象呢？这就要用到placement new了，它实际上是operator new的一个重载版本，原型是void* operator new (std::size_t size, void* ptr) noexcept;，这里的size参数是被忽略的，只需传入已分配内存的指针ptr参数，目的是在已分配的内存上构造对象，最后将原指针返回。它的用法也与普通函数不同，需在函数后提供构造函数，如，我们可以这样解决上述问题：A* pa = new(ptr) A()。 new和malloc的区别 malloc是库函数，new是C++关键字。 new自行计算空间大小，如int* a = new int[10]；而malloc需要指定空间大小，如int* a = malloc( sizeof(int)*10 )。 new在动态分配空间时会可调用对象的构造函数初始化对象；而malloc只是分配一段给定大小的内存。 new分配失败时会抛出异常；而malloc只会返回NULL。 new可以通过调用malloc来实现，反之则不可以。 C++多态性多态性可以简单理解为“一个接口，多种方法”，程序在运行时才决定调用哪一种方法。C++的多态性是通过虚函数来实现的，虚函数允许子类重新定义父类的方法，即重写（override）。它与重载（overload）的区别是：重写主要针对名称相同、参数列表相同的函数，运行时才决定函数地址；而重载针对名称相同、参数列表不同的函数，编译期即可决定调用哪个函数，不体现多态性。 虚函数的实现虚函数是通过vtable（virtual table，虚函数表）实现的。注意该表是针对类的，而不是针对对象的，也就是说，编译器会为每一个有虚函数的类维护一张vtable，该类的每一个实例都会包含一个表指针，指向同一张表，如下图所示：C1和C2的vtable都分别只创建了一张，它们的实例通过表指针访问对应的vtable。当一个子类重写了虚函数，其vtable的相关条目也会被替换为合适的函数地址。比如，假设上述的C2是C1的子类，C2重写了一些虚函数，也增加了一个虚函数，最终两者的vtable就分别是： 下面再通过一段测试代码实际感受一下。1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;class Base &#123;public: virtual void f() &#123; cout &lt;&lt; \"Base::f\" &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; \"Base::g\" &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; \"Base::h\" &lt;&lt; endl; &#125;&#125;;class Derived: public Base &#123;public: virtual void f() &#123; cout &lt;&lt; \"Derived::f\" &lt;&lt; endl; &#125; virtual void g1() &#123; cout &lt;&lt; \"Derived::g1\" &lt;&lt; endl; &#125; virtual void h1() &#123; cout &lt;&lt; \"Derived::h1\" &lt;&lt; endl; &#125;&#125;;int main(void) &#123; Base* b = new Base(); Base* d1 = new Derived(); Derived* d2 = new Derived(); Derived* d3 = new Derived(); return 0;&#125; 我们可以利用GDB的info vtbl [obj]命令来查看对象所指的vtable：可以看到： 作为Base类的对象b所指的vtable包含了它三个虚函数的地址。 d1是Derived类，对应的vtable中，f()是Derived的重写版本，体现了多态性。而因为它由Base指针指向，所以只能访问vtable中的父类函数。 注意到d1、d2、d3对应的vtable地址是一致的，证明它们都是同一张表。 引用与指针的区别 指针是个实体，有自己的内存空间；引用只是一块内存的别名，编译器没有为其分配空间。 指针可以不初始化，可为空；引用必须初始化，不可为空。 指针可以改变其指向的对象；引用则不可变。 实际上，引用可以做的事情指针都可以完成，但引用更加安全。","categories":[{"name":"C++","slug":"C","permalink":"http://github.com/categories/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://github.com/tags/C/"}]},{"title":"vi常用命令","slug":"vi常用命令","date":"2018-04-14T14:03:27.000Z","updated":"2018-04-14T14:08:59.603Z","comments":true,"path":"2018/04/14/vi常用命令/","link":"","permalink":"http://github.com/2018/04/14/vi常用命令/","excerpt":"vi编辑器拥有众多命令，可以按如下方式分为三类： 移动光标的命令 进入输入模式的命令 进行修改的命令 移动光标移动一个位置 j：向下移动一个位置 k：向上移动一个位置 h：向左移动一个位置 l：向右移动一个位置","text":"vi编辑器拥有众多命令，可以按如下方式分为三类： 移动光标的命令 进入输入模式的命令 进行修改的命令 移动光标移动一个位置 j：向下移动一个位置 k：向上移动一个位置 h：向左移动一个位置 l：向右移动一个位置 行内大范围移动 0：移动至行头 $：移动至行尾 ^：移动至行内第一个非空格字符上 单词间移动 w：移动至下一个单词的词首 e：移动至下一个单词的词尾 b：移动至上一个单词的词首 屏幕内大范围移动 H：移动至屏幕顶部 M：移动至屏幕中部 L：移动至屏幕底部 可联想high、middle、low这三个词。 屏幕间移动 ^F：向下移动一个屏幕 ^B：向上移动一个屏幕 ^D：向下移动半个屏幕 ^U：向上移动半个屏幕 返回前一个位置 ``（两个反引号）：回到前一个位置 ‘’（两个单引号）：回到前一个位置的行头 具体应用如，使用G命令移动到文件末尾后，使用上述命令可以很快速地回到原来的位置。 输入模式 i：在当前光标位置前插入 a：在当前光标位置后插入 I：在当前行开头插入 A：在当前行末尾插入 o：在当前行下一行插入 O：在当前行上一行插入 修改文本简单替换 r：替换一个字符 R：替换多个字符 s：以插入方式替换一个字符 C：以插入方式从当前光标替换到行尾 S或cc：以插入方式替换整行 c[move]：以插入方式从当前光标替换到[move]给出的位置（如cw可以向后替换一个单词，因为w使光标移动到下一个单词词首） 复杂替换 :s/pattern/replace/：替换当前行 :lines/pattern/replace/：替换指定行 :line,lines/pattern/replace/：替换指定范围的行 :%s/pattern/replace/：替换所有行 其中，pattern是替换的正则表达式匹配模式，replace是要替换的文本，line是行号。此外，该命令有几个注意事项： 为了删除特定项，只需将替换文本留空，如删除root为：s/root//。 以上命令默认只匹配每一行的第一项，在命令末尾加上g（global）可匹配所有项。 在命令末尾加上c（confirm）可使vi在改变每一项前发出确认提示。 可用.代表当前行，$代表文本最后一行。 删除文本 x：删除当前光标位置的字符 X：删除当前光标位置前的字符 D：删除从当前光标位置到行尾的所有字符 d[move]：删除从当前光标位置到[move]所给位置的字符（用法同c[move]） dd：删除当前行 :lined：删除指定行 :line,lined：删除指定范围的行 复制文本主要有y和yy两个命令，用法与d和dd相同。 粘贴 p：插入到光标后 P：插入到光标前 两者不仅可插入复制的文本，也可插入刚被删除的文本，充当剪切-粘贴的用途。","categories":[{"name":"工具","slug":"工具","permalink":"http://github.com/categories/工具/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://github.com/tags/Linux/"},{"name":"vi","slug":"vi","permalink":"http://github.com/tags/vi/"}]},{"title":"Segmentation Fault分析","slug":"Segmentation Fault分析","date":"2018-04-14T13:57:07.000Z","updated":"2018-04-14T14:00:14.779Z","comments":true,"path":"2018/04/14/Segmentation Fault分析/","link":"","permalink":"http://github.com/2018/04/14/Segmentation Fault分析/","excerpt":"什么是Segmentation Fault维基百科对此有简单明了的定义： In computing, a segmentation fault (often shortened to segfault) or access violation is a fault, or failure condition, raised by hardware with memory protection, notifying an operating system (OS) the software has attempted to access a restricted area of memory (a memory access violation). 简单地用中文说，就是访问了不属于该进程的内存。而我总是对一个名词的来源感兴趣，为什么这一现象要称为Segmentation Fault呢？起初，我一直以为是与早期操作系统的分段式内存管理机制有关（memory segmentation ），在网上查了一下才发现两者并无直接联系： “Segmentation” isn’t at all related to the old “segmented memory model” used by early x86 processors; it’s an earlier use which just refers to a portion or segment of memory. 原来segmentation仅仅是指一段（segment）内存o(╯□╰)o","text":"什么是Segmentation Fault维基百科对此有简单明了的定义： In computing, a segmentation fault (often shortened to segfault) or access violation is a fault, or failure condition, raised by hardware with memory protection, notifying an operating system (OS) the software has attempted to access a restricted area of memory (a memory access violation). 简单地用中文说，就是访问了不属于该进程的内存。而我总是对一个名词的来源感兴趣，为什么这一现象要称为Segmentation Fault呢？起初，我一直以为是与早期操作系统的分段式内存管理机制有关（memory segmentation ），在网上查了一下才发现两者并无直接联系： “Segmentation” isn’t at all related to the old “segmented memory model” used by early x86 processors; it’s an earlier use which just refers to a portion or segment of memory. 原来segmentation仅仅是指一段（segment）内存o(╯□╰)o 什么情况会产生Segmentation Fault在写C语言的时候，最容易产生Segmentation Fault的大概有两种情况： 访问空指针指向的内存 越界访问数组 第一种情况最简单的示例就是：1234567int main(int argc, char* argv[])&#123; int *p = NULL; *p = 1; return 0;&#125; 这里，空指针p被设为NULL，指向的内存便不属于该进程，对p指向的内存赋值自然就属于非法访问内存了。第二种情况大概是每个学过C语言的人都会遇到的。然而，越界访问并不会必然导致Segmentation Fault，因为有时候你会“幸运”地访问到同属于该进程的一块内存。当然，这种“幸运”其实是一种巨大的不幸，出现这种情况时，运行时环境不会直接了当地告诉你有错误，而是会以莫名其妙地方式暗示你。 如何调试Segmentation FaultSegmentation Fault令人头疼的地方就是，运行时环境并不会直接告诉你代码的哪一行出现了问题。过去，我的做法一直是凭猜测，然后在可能的地方输出特定信息以观察程序是否在该位置出错。直到我意识到可以用强大的调试工具GDB来提高效率。如第一种情况的示例，在编译的时候加入-g参数可令其生成调试信息以便待会用GDB调试：1gcc -g c_test.c 然后就是用GDB执行生成可执行文件：1gdb ./a.out 进入交互界面后输入r让程序开跑，之后就能看到非常醒目的错误信息：123Program received signal SIGSEGV, Segmentation fault.0x00000000004004ed in main (argc=1, argv=0x7fffffffdd38) at c_test.c:77 *p = 1; 于是便瞬间锁定了错误所在的位置，又可以愉快改下一个bug了～","categories":[{"name":"C","slug":"C","permalink":"http://github.com/categories/C/"}],"tags":[{"name":"C","slug":"C","permalink":"http://github.com/tags/C/"}]},{"title":"slim环境下设置gpu_option","slug":"slim环境下设置gpu-option","date":"2018-04-14T13:45:42.000Z","updated":"2018-04-14T13:48:26.129Z","comments":true,"path":"2018/04/14/slim环境下设置gpu-option/","link":"","permalink":"http://github.com/2018/04/14/slim环境下设置gpu-option/","excerpt":"设置gpu_option使用Tensorflow的GPU版本进行深度学习训练时，Tensorflow默认占用对进程可见的所有GPU内存以提高训练效率。然而，在有些情况下，比如在多人共享的机器上训练时，系统管理员要求不能霸占所有GPU资源，否则其他人就无法使用了（博主就是这种情况），这时候我们就想要限制程序对GPU的使用，用英文讲，就是Allow GPU memory growth。根据官网的说明，我们可以通过配置Session的gpu_option来达到上述目的。具体地，有两种参数可设置：","text":"设置gpu_option使用Tensorflow的GPU版本进行深度学习训练时，Tensorflow默认占用对进程可见的所有GPU内存以提高训练效率。然而，在有些情况下，比如在多人共享的机器上训练时，系统管理员要求不能霸占所有GPU资源，否则其他人就无法使用了（博主就是这种情况），这时候我们就想要限制程序对GPU的使用，用英文讲，就是Allow GPU memory growth。根据官网的说明，我们可以通过配置Session的gpu_option来达到上述目的。具体地，有两种参数可设置： allow_growth123config = tf.ConfigProto()config.gpu_options.allow_growth = Truesession = tf.Session(config=config, ...) 上述代码的作用，简单地讲，就是按需分配：进程一开始运行的时候，仅为其分配少量的GPU内存，而随着进程的继续运行，对计算资源的需求加大时再分配更多的GPU内存。 per_process_gpu_memory_fraction123config = tf.ConfigProto()config.gpu_options.per_process_gpu_memory_fraction = 0.4session = tf.Session(config=config, ...) 顾名思义，这是在设置进程使用每个GPU的内存上限，例如，在上述代码里，该进程最多只会占用每个GPU内存的40%。 在slim环境下设置gpu_optionslim是Tensorflow于2016推出的模块，是一种high-level库，讲许多深度学习算法封装起来，极大地简化了Tensorflow的代码。对于一般的神经网络训练，slim封装了slim.learning.train方法，程序员连Session都不需要自己创建了，然而，按照上述方法，gpu_option需要在创建Session时设置，这就产生了问题。所幸的是，slim.learning.train提供的参数已经考虑到了这个问题： session_config: An instance of tf.ConfigProto that will be used to configure the Session. If left as None, the default will be used. 所以，我们的设置方法就是：123session_config = tf.ConfigProto()session_config.gpu_options.allow_growth = Trueslim.learning.train(..., session_config=session_config) 或者123session_config = tf.ConfigProto()session_config.per_process_gpu_memory_fraction = 0.4slim.learning.train(..., session_config=session_config)","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://github.com/categories/深度学习/"}],"tags":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://github.com/tags/Tensorflow/"},{"name":"slim","slug":"slim","permalink":"http://github.com/tags/slim/"},{"name":"深度学习","slug":"深度学习","permalink":"http://github.com/tags/深度学习/"}]},{"title":"Hexo + GitHub Pages 搭建个人博客","slug":"Hexo + GitHub Pages 搭建个人博客","date":"2018-04-13T14:08:49.000Z","updated":"2018-04-13T14:09:53.864Z","comments":true,"path":"2018/04/13/Hexo + GitHub Pages 搭建个人博客/","link":"","permalink":"http://github.com/2018/04/13/Hexo + GitHub Pages 搭建个人博客/","excerpt":"Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other languages) and Hexo generates static files with a beautiful theme in seconds. Documentationhexo.io 这一篇 note 讲解如何使用 Hexo + Github Pages 搭建个人博客，并用 GitHub 进行版本控制。其中源文件位于 hexo 分支，静态文件位于 master 分支。 准备 安装最新版的 Git。在命令行输入 git version 检查 git 是否安装成功。 安装 LTS 版的 Node.js。同样在命令行输入 node -v 和 npm -v以检查 node.js 是否安装成功。 注册 GitHub 账号，新建一个 repository，一般命名为 username.github.io，这样 GitHub 会自动开启 GitHub Pages 功能。勾选 Initialize this repository with a README 的话即可访问个人主页，否则需要添加内容才能访问，建议暂时不要勾选。 GitHub 添加 SSH（推荐），可参考 Connecting to GitHub with SSH。","text":"Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other languages) and Hexo generates static files with a beautiful theme in seconds. Documentationhexo.io 这一篇 note 讲解如何使用 Hexo + Github Pages 搭建个人博客，并用 GitHub 进行版本控制。其中源文件位于 hexo 分支，静态文件位于 master 分支。 准备 安装最新版的 Git。在命令行输入 git version 检查 git 是否安装成功。 安装 LTS 版的 Node.js。同样在命令行输入 node -v 和 npm -v以检查 node.js 是否安装成功。 注册 GitHub 账号，新建一个 repository，一般命名为 username.github.io，这样 GitHub 会自动开启 GitHub Pages 功能。勾选 Initialize this repository with a README 的话即可访问个人主页，否则需要添加内容才能访问，建议暂时不要勾选。 GitHub 添加 SSH（推荐），可参考 Connecting to GitHub with SSH。 Hexo安装 Hexo1npm install hexo-cli -g 使用 hexo version 检查是否安装成功。 建站选择一个目录，比如 D:\\github，键入以下命令： 123hexo init username.github.iocd username.github.ionpm install 这样就创建了一个名为 username.github.io 的 Hexo 工程（文件夹）。注意，hexo init &lt;folder&gt; 命令要求 folder 为空文件夹，否则会报错。 启动服务器1hexo server (简写为 hexo s) 默认情况下，访问网址为 http://localhost:4000/。打开网址，可以看到一篇 landscape 主题的 Hello World 博客。一般修改 Markdown 文件，不需要重启服务器，直接刷新浏览器即可，除非你修改配置文件。 修改配置站点配置工程根目录下的 _config.yml 称为站点配置文件，可以配置一些个人信息等，具体可参考Configuration。 主题配置每个主题的目录下也会有一个 _config.yml 文件，称为主题配置文件。Hexo 有丰富多彩的主题，这里以 hexo-theme-hiker 为例，说明如何更换主题。 安装主题： 12cd username.github.iogit clone git@github.com:iTimeTraveler/hexo-theme-hiker.git themes/hiker PS：这样安装主题并不能 push 到 GitHub 中去，可使用 fork + subtree 的方法解决，具体参考 Hexo 主题同步。感谢 @Tyrion Yu 的帮助。 修改站点配置文件，将 theme 修改为 hiker： # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: hiker 重启服务器，即可查看效果。在某些情况（尤其是更换主题后），如果发现对站点的更改无论如何也不生效，可能需要 clean 一下。 12hexo cleanhexo server PS：如果不需要 landscape 主题，直接删除 themes 下的对应文件夹即可。 部署配置安装 hexo-deployer-git。 1npm install hexo-deployer-git --save 然后修改站点配置文件： # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repo: git@github.com:username/username.github.io.git # 这种配置需使用 SSH branch: master message: message # 默认为 Site updated: {{ now('YYYY-MM-DD HH:mm:ss') }} 其中 branch 为静态文件所在的分支，必须为 master 分支。message 表示自定义提交信息，一般不需要配置，删除该行即可。 GitGit 初始化为工程创建 Git 仓库： 12cd username.github.iogit init 创建分支此时 Git 仓库为空，不能直接运行 git branch hexo 来创建新的分支，可通过以下命令创建： 1git checkout -b hexo push 源文件添加所有文件，提交到本地仓库： 12git add .git commit -m &quot;first commit&quot; 添加远程仓库，并push： 12git remote add origin git@github.com:username.github.io.gitgit push -u origin hexo 部署静态文件先生成静态文件，再部署： 123hexo cleanhexo generate （简写为 hexo g）hexo delpoy (简写为 hexo d) 此时整个部署过程就结束啦，你可以通过 https://username.github.io/ 访问自己的 Github Pages。 推荐阅读 How to use Hexo and deploy to GitHub Pages Hexo Documentation 知乎：使用hexo，如果换了电脑怎么更新博客？ An attractive theme for Hexo. called “Hiker”, short for “HikerNews” Hexo 主题同步 使用 git subtree 集成项目到子目录 Git subtree: the alternative to Git submodule","categories":[{"name":"blog","slug":"blog","permalink":"http://github.com/categories/blog/"}],"tags":[{"name":"Git笔记","slug":"Git笔记","permalink":"http://github.com/tags/Git笔记/"}]},{"title":"Git--命令(二)","slug":"Git--命令(二)","date":"2018-04-13T14:04:29.000Z","updated":"2018-04-13T14:06:01.044Z","comments":true,"path":"2018/04/13/Git--命令(二)/","link":"","permalink":"http://github.com/2018/04/13/Git--命令(二)/","excerpt":"Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. Documentationgit-scm.com Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。它是由 Linux 之父 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。本文介绍了 Git 的常用命令。 三种状态在学习 Git 命令之前，首先要理解它的三种状态：已提交（committed）、已修改（modified）和已暂存（staged）。已提交表示数据已经安全的保存在本地数据库中；已修改表示修改了文件，但还没保存到数据库中，增加、删除文件也相当于已修改；已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 由此引入 Git 项目的三个工作区域的概念：Git 仓库、工作目录以及暂存区域。","text":"Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. Documentationgit-scm.com Git 是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。它是由 Linux 之父 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。本文介绍了 Git 的常用命令。 三种状态在学习 Git 命令之前，首先要理解它的三种状态：已提交（committed）、已修改（modified）和已暂存（staged）。已提交表示数据已经安全的保存在本地数据库中；已修改表示修改了文件，但还没保存到数据库中，增加、删除文件也相当于已修改；已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 由此引入 Git 项目的三个工作区域的概念：Git 仓库、工作目录以及暂存区域。 它们之间的关系可以参考 Git 工作区、暂存区和版本库。 在阅读下面的内容之前，最好在自己的电脑上安装 Git，然后按照顺序操作。如果你想先感受一下 Git 的魅力， Try Git 是一个不错的选择。 Git 配置安装完 Git，初次运行前需要做一些配置，比如用户信息： 12git config --global user.name \"Your Name\"git config --global user.email email@example.com Windows 环境下，推荐使用文本编辑器 Notepad++： 12# 注意更改为自己的安装目录git config --global core.editor \"'C:\\Program Files\\Notepad++\\notepad++.exe' -multiInst -nosession\" 配置完成后，可以通过 git config --list 查看所有的配置信息，或者使用 git config user.name 查看单个信息。 另外，还可以自定义配置一些命令的别名，方便记忆。 1git config --global alias.last 'log -1' 这样 git last 就相当于 git log -1，用于查看最后一次的提交记录。我比较喜欢这样配置，用于查看提交历史： 1git config --global alias.lg \"log --oneline --decorate --graph --all\" 创建版本库创建版本库有两种方式，一种是使用 git clone 从现有 Git 仓库中拷贝项目，格式如下： 1git clone &lt;repo&gt; &lt;directory&gt; 另一种是通过 git init 初始化一个 Git 仓库，省略 directory 会在当前文件夹中创建。 1git init &lt;directory&gt; 例如，在 D:\\test 文件夹下执行 git init 命令，这样会生成一个 隐藏 的 .git 目录。 12$ git initInitialized empty Git repository in D:/test/.git/ Git 工作流程基本的 Git 工作流程如下： 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 使用 Git 时文件的生命周期如下： 上图来源于 Pro Git，这里的 Add the file 应该理解为使用 git add 命令，Reomve the file 则是手动删除文件。 First Commit在 D:\\test 中手动添加 a.txt 文件，使用 Notepad++ 编辑（不要用记事本），然后运行 git status 命令，查看当前状态： 1234567891011$ git statusOn branch masterNo commits yetUntracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) a.txtnothing added to commit but untracked files present (use \"git add\" to track) Git 的提示十分人性化，可以看出 a.txt 处于 Untracked 状态。执行 git add 命令： 1234567891011$ git add a.txt$ git statusOn branch masterNo commits yetChanges to be committed: (use \"git rm --cached &lt;file&gt;...\" to unstage) new file: a.txt 此时 a.txt 处于 Staged 状态，可以通过 git rm --cached &lt;file&gt;... 使其回到 Untracked 状态。最后执行 git commit 命令，进行第一次提交。 1234$ git commit -m \"Add a.txt\"[master (root-commit) 3fbc25c] Add a.txt 1 file changed, 1 insertion(+) create mode 100644 a.txt 其中 -m 是参数，后面跟着提交信息。如果配置了文本编辑器，执行不带参数的 git commit 后，可在弹出的编辑器中填写提交信息。注意只有 保存文件 并 退出编辑器，commit 才会生效。 另外，在只 修改文件 时，使用 -a 可以跳过 Staged 状态直接提交，可以和 -m 一起使用： 1git commit -am \"Update file\" Second Commit添加 b.txt，然后修改 a.txt，查看此时的状态： 1234567891011121314$ git statusOn branch masterChanges not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: a.txtUntracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) b.txtno changes added to commit (use \"git add\" and/or \"git commit -a\") 此时 a.txt 处于 Modified 状态，可通过 git checkout -- &lt;file&gt;... 放弃更改，但是要 慎用，这些更改是找不回来的。 而 b.txt 处于 Untracked 状态。 git diff 命令用于比较工作目录中当前文件和暂存区域快照之间的差异，也就是修改之后还没有暂存起来的变化内容。 git diff --cached（Git 1.6.1 及更高版本还允许使用 git diff --staged，效果是相同的，但更好记些）可以查看已暂存的将要添加到下次提交里的内容。 123456789$ git diffdiff --git a/a.txt b/a.txtindex 69dd9b9..b0c1f18 100644--- a/a.txt+++ b/a.txt@@ -1 +1,2 @@ aaaaaaaaaa # a.txt 原本的内容+AAAAAAAAAA # a.txt 添加的内容$ git diff --staged # nothing 添加这两个文件到暂存区： 123456789$ git add \"*.txt\" # git add .(一个点，表示添加所有文件)$ git statusOn branch masterChanges to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: a.txt new file: b.txt 同理，git reset HEAD &lt;file&gt;... 命令可使文件回到 add 之前的状态。此时再次执行 diff： 1234567891011121314151617$ git diff # nothing$ git diff --stageddiff --git a/a.txt b/a.txtindex 69dd9b9..b0c1f18 100644--- a/a.txt+++ b/a.txt@@ -1 +1,2 @@ aaaaaaaaaa+AAAAAAAAAAdiff --git a/b.txt b/b.txtnew file mode 100644index 0000000..817e5ca--- /dev/null+++ b/b.txt@@ -0,0 +1 @@+bbbbbbbbbb # b.txt 中添加的内容 以上对比可以看出不同 diff 的差别。执行 commit 命令进行第二次提交： 1234$ git commit -m \"Update a.txt and add b.txt\"[master 24e0903] Update a.txt and add b.txt 2 files changed, 2 insertions(+) create mode 100644 b.txt 删除为了演示删除操作，先添加 c.txt： 123456$ git add c.txt$ git commit -m \"Add c.txt\"[master 9d8751a] Add c.txt 1 file changed, 1 insertion(+) create mode 100644 c.txt 手动删除后的状态为 Untracked。 12345678$ git statusChanges not staged for commit: (use \"git add/rm &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) deleted: c.txtno changes added to commit (use \"git add\" and/or \"git commit -a\") 使用 git checkout -- &lt;file&gt;... 撤销，然后执行 git rm 命令，此时的状态为 Staged。这就是两者的差别吧。 12345678$ git rm c.txtrm 'c.txt'$ git statusOn branch masterChanges to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) deleted: c.txt 提交删除： 1234$ git commit -m \"Delete c.txt\"[master 95d6e7e] Delete c.txt 1 file changed, 1 deletion(-) delete mode 100644 c.txt 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除 git rm -f &lt;file&gt;。 这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。 而 git rm --cached 命令只会将文件从 Git 仓库中删除，但仍然保留在当前工作目录中。当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆无关的文件添加到暂存区时，这一做法尤其有用。 版本回退在 Git 中，用 HEAD 表示当前版本，上一个版本就是 HEAD^（HEAD~）。有关 ~ 和 ^ 的区别，请参考 What’s the difference between HEAD^ and HEAD~ in Git? 注意，Windows 环境下 ^ 识别不了，必须加 双引号 才行，像这样 &quot;HEAD^&quot;。 假如又要用到 c.txt，想反悔，怎么办？Git 允许我们在版本的历史之间穿梭，使用 git reset --hard &lt;commit_id&gt; 命令。如果不知道 commit_id，git log 可以查看提交历史。 12345678910111213$ git lg # 自定义的 git log* 95d6e7e (HEAD -&gt; master) Delete c.txt* 9d8751a Add c.txt* 24e0903 Update a.txt and add b.txt* 3fbc25c Add a.txt$ git reset --hard HEAD~HEAD is now at 9d8751a Add c.txt$ git lg* 9d8751a (HEAD -&gt; master) Add c.txt* 24e0903 Update a.txt and add b.txt* 3fbc25c Add a.txt 其中 3fbc25c 为版本号（commit_id），它是一个由 SHA-1 计算出来的校验和，用十六进制表示，而且每次都不一样。因为我使用了自定义的 git lg， 这里只显示 7 位，其实它是 3fbc25c7d58e06169a45b587a9c6164234efd43c。 git log 功能十分强大，可参考 Git Basics - Viewing the Commit History。 另外，可以使用命令 git reflog 查看命令历史。如果想回到 Delete c.txt 的版本，直接 reset 对应的 commit_id 即可。 123456$ git reflog9d8751a (HEAD -&gt; master) HEAD@&#123;0&#125;: reset: moving to HEAD~95d6e7e HEAD@&#123;1&#125;: commit: Delete c.txt9d8751a HEAD@&#123;2&#125;: commit: Add c.txt24e0903 HEAD@&#123;3&#125;: commit: Update a.txt and add b.txt3fbc25c HEAD@&#123;4&#125;: commit (initial): Add a.txt Reset其实 reset 分三类，分别为 --soft、--mixed（默认，可不加）和 --hard，它们之间到底有什么区别呢？我们做个试验。注意此时是 Add c.txt 的版本。 soft12345678$ git reset --soft HEAD~$ git statusOn branch masterChanges to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) new file: c.txt --soft 参数使文件回到了 Staged 的状态。 mixed重新回到 Add c.txt 的版本，执行 --mixed 命令： 12345678910$ git reset --mixed HEAD~$ git statusOn branch masterUntracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) c.txtnothing added to commit but untracked files present (use \"git add\" to track) --mixed 参数使文件回到了 Untracked 状态。 hard重新回到 Add c.txt 的版本，执行 --hard 命令： 12345$ git reset --hard HEAD~HEAD is now at 24e0903 Update a.txt and add b.txt$ git statusOn branch masternothing to commit, working tree clean 而 --hard 参数直接回到了上一个版本。 想要了解更多关于 Reset 的知识，请参考 Git Tools - Reset Demystified。 Git 分支几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。有人把 Git 的分支模型称为它的“必杀技特性”，也正因为这一特性，使得 Git 从众多版本控制系统中脱颖而出。为何 Git 的分支模型如此出众呢？Git 处理分支的方式可谓是难以置信的轻量，创建新分支这一操作几乎能在瞬间完成，并且在不同分支之间的切换操作也是一样便捷。 下面演示了 Git 分支的工作流程。创建并切换到 dev 分支： 1234$ git branch dev$ git checkout devSwitched to branch 'dev' 简单地，这两个命令可以合并为一个命令： 12$ git checkout -b devSwitched to a new branch 'dev' 在 dev 分支添加 d.txt，修改 c.txt，提交： 123456$ git add .$ git commit -m \"Add d.txt and update c.txt\"[dev 7f5d2b1] Add d.txt and update c.txt 2 files changed, 2 insertions(+), 1 deletion(-) create mode 100644 d.txt 切换到 master 分支，合并 dev 分支： 123456789$ git checkout master$ git merge devUpdating 9d8751a..7f5d2b1Fast-forward c.txt | 2 +- d.txt | 1 + 2 files changed, 2 insertions(+), 1 deletion(-) create mode 100644 d.txt 最后删除 dev 分支： 12$ git branch -d devDeleted branch dev (was 7f5d2b1). Git 远程仓库为了能在任意 Git 项目上协作，需要知道如何管理自己的远程仓库。远程仓库是指托管在因特网或其他网络中的你的项目的版本库。 你可以有好几个远程仓库，通常有些仓库对你只读，有些则可以读写。与他人协作涉及管理远程仓库以及根据需要推送或拉取数据。 这里以 GitHub 为例，演示如何使用远程仓库。在 GitHub 上创建一个新的 Repository，不要添加任何内容，完成后如下图所示： 添加远程仓库： 1git remote add origin git@github.com:muwednesday/git-learning.git 使用命令 git push 将本地仓库推送到 GitHub，其中 -u 为设置当前本地分支的默认远程分支。 12345678910$ git push -u origin masterCounting objects: 14, done.Delta compression using up to 8 threads.Compressing objects: 100% (7/7), done.Writing objects: 100% (14/14), 913 bytes | 304.00 KiB/s, done.Total 14 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), done.To github.com:muwednesday/git-learning.git * [new branch] master -&gt; masterBranch 'master' set up to track remote branch 'master' from 'origin'. 刷新页面后即可看到文件。然后在 GitHub 上创建一个 README.md 的文件，提交。 返回本地仓库，查看状态，这里居然显示 up to date。本来应该落后才对，为什么呢？原因参见 Why does git status show branch is up-to-date when changes exist upstream? 12345$ git statusOn branch masterYour branch is up to date with 'origin/master'.nothing to commit, working tree clean 最后使用命令 git pull 来自动的抓取然后合并远程分支到当前分支。 123456789101112$ git pullremote: Counting objects: 3, done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), done.From github.com:muwednesday/git-learning 7f5d2b1..ad27849 master -&gt; origin/masterUpdating 7f5d2b1..ad27849Fast-forward README.md | 1 + 1 file changed, 1 insertion(+) create mode 100644 README.md 推荐阅读 Pro Git GitHub Cheat Sheet Reference Manual 廖雪峰的 Git 教程 What’s the difference between HEAD^ and HEAD~ in Git? Reset, Checkout, and Revert What is the difference between ‘git pull’ and ‘git fetch’?","categories":[{"name":"工具","slug":"工具","permalink":"http://github.com/categories/工具/"}],"tags":[{"name":"git","slug":"git","permalink":"http://github.com/tags/git/"}]},{"title":"hiker博客主题配置","slug":"hiker博客主题配置","date":"2018-04-13T02:01:03.000Z","updated":"2018-04-13T04:34:32.000Z","comments":true,"path":"2018/04/13/hiker博客主题配置/","link":"","permalink":"http://github.com/2018/04/13/hiker博客主题配置/","excerpt":"HikerAn attractive, exquisite theme for Hexo. named “Hiker”, short for “HikerNews”. ☞ 在线预览 | Hiker问题交流群","text":"HikerAn attractive, exquisite theme for Hexo. named “Hiker”, short for “HikerNews”. ☞ 在线预览 | Hiker问题交流群 以上Demo站点的源文件在这里，大家有需要的可以参考：https://github.com/iTimeTraveler/hexo-theme-hiero/tree/site-source 安装步骤 从GitHub上获取代码 1$ git clone https://github.com/iTimeTraveler/hexo-theme-hiker.git themes/hiker 启用 把Hexo主目录下的 _config.yml 文件中的字段 theme 修改为 hiker. 1234# Extensions## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/theme: hiker 更新 12$ cd themes/Hiker$ git pull 特性自定义首页背景您可以将选择的大图放到 YOUR_HEXO_SITE\\themes\\hiker\\source\\css\\images 文件夹下. 然后更改 hiker/_config.yml文件里的home_background_image字段. 12345678# Homepage# eg. home_background_image: [css/images/home-bg.jpg, http://t.cn/RMbvEza]# eg. mode: image | polyline | trianglifyhome_background_image: enable: true mode: image rolling: true url: [css/images/home-bg.jpg, css/images/sample.jpg, https://source.unsplash.com/collection/954550/1920x1080] 首页背景填充方式有三种可选mode： image: 大图模式 trianglify: 多边形渐变背景 polyline: 随机彩色折线 默认配置为image模式，也就是大图模式。多边形渐变背景trianglify模式来自Trianglify大致如下图： 如果你不中意以上两种背景填充方式，可以选择随机彩色折线polyline模式，长相参考下图。 ！！注意：如果在使用image模式时url为空（enable仍然保持true）, 主题也会自动使用下面这种漂亮的随机线条 填充（也就是会自动退化为polyline模式）： Code 色彩主题Hiker 使用Tomorrow Theme 作为代码高亮的配色. 总共有六种选择: default, normal, night, night blue, night bright, night eighties 默认高亮配色如上图。 另外的五种配色如下. Modify highlight_theme in hiker/_config.yml. 12345# Code Highlight theme# Available value:# default | normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: default 博客主题色Hiker 为你的博客提供了五种可选的主题色，可以配置成random, 每次生成博客时会自动随机使用一个主题色. orange blue red green black You can modify theme_color in hiker/_config.yml. 1234# Article theme color# Available value:# random | orange | blue | red | green | blacktheme_color: random 夜间模式只有在文章阅读页面，点击左上角的logo图片，就能打开设置对话框，操作如下图 站内搜索Hiker 使用 Insight Search 实现了站内搜索，在_config.yml文件中启用如下. 12345# Searchsearch: insight: true # you need to install `hexo-generator-json-content` before using Insight Search swiftype: # enter swiftype install key here baidu: false # you need to disable other search engines to use Baidu search, options: true, false ！注意: 在使用搜索功能前必须在Hexo目录下使用以下命令安装 hexo-generator-json-content 插件. 1$ npm install -S hexo-generator-json-content FancyboxHiker使用Fancybox来浏览展示您文章中的图片，支持以下方式在文章中添加图片： 123![img caption](img url)&#123;% fancybox img_url [img_thumbnail] [img_caption] %&#125; 侧边栏sidebar（侧边栏位置）可以设置为 left , right, bottom. Hiker 有以下5种侧边栏插件: category tag tagcloud archives recent_posts All of them are enabled by default. You can edit them in widget setting. 打赏捐赠按钮 每篇文章最后显示打赏按钮，目前仅支持微信支付和支付宝两种打赏方式。您可以在文件 hiker/_config.yml 中配置您的微信、支付宝付款二维码图片的URL: 123456# donation buttondonate: enable: true message: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!' wechatImage: https://your_WECHAT_PAY_ImageUrl alipayImage: https://your_ALIPAY_ImageUrl 评论已完全支持原生Disqus、livere（来必力）、wumii（无觅）评论系统。因多说、网易云跟帖均已停止服务，在国内建议大家使用相对稳定的来必力评论系统。在文件 hiker/_config.yml 中修改以下代码片段: 1234567# comment ShortName, you can choose only ONE to display.gentie_productKey: #网易云跟帖your-gentie-product-keyduoshuo_shortname:disqus_shortname:livere_shortname: MTAyMC8yOTQ4MS82MDQ5uyan_uid:wumii: 网易云跟帖说明（已停止服务） 登陆 网易云跟帖 获取你的 Product Key。请注意，您在云跟帖管理后台设置的域名必须跟您站点的域名一致。在本地测试时，需要做两步骤前置设定： 修改 hosts 文件，将您域名的请求指向本地。例如：127.0.0.1 yoursite.com 修改 Hexo 监听的端口为 80：hexo s --debug -p 80 测试完成后请将 hosts 文件中的域名映射删除即可。 支持的浏览器 Contributing欢迎大家有各种问题和改进建议的，直接提issue或者评论，或者pull request都行。我会尽量抽时间和大家交流。刚接触Hexo不久，疏忽不足之处，还望大家海涵！","categories":[{"name":"blog","slug":"blog","permalink":"http://github.com/categories/blog/"}],"tags":[{"name":"blog config","slug":"blog-config","permalink":"http://github.com/tags/blog-config/"}]},{"title":"背包问题","slug":"背包问题","date":"2018-04-12T16:57:50.000Z","updated":"2018-04-13T07:38:39.541Z","comments":true,"path":"2018/04/13/背包问题/","link":"","permalink":"http://github.com/2018/04/13/背包问题/","excerpt":"0/1背包问题 有N件物品和一个容量为V的背包。放入第i件物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大？ 将每一件物品从1到n编号，从第1件物品开始，每一件物品就只有两个状态：放进背包了 / 没有放进背包。 我们画一张表格，行对应着每一件物品，列对应着背包的重量，那么pack[i][j]就表示 前i件物品，背包最大承重j 这个子问题的解。","text":"0/1背包问题 有N件物品和一个容量为V的背包。放入第i件物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大？ 将每一件物品从1到n编号，从第1件物品开始，每一件物品就只有两个状态：放进背包了 / 没有放进背包。 我们画一张表格，行对应着每一件物品，列对应着背包的重量，那么pack[i][j]就表示 前i件物品，背包最大承重j 这个子问题的解。 给一组数据作为样例： 5 10 6 2 3 2 5 6 4 5 6 4 第一行表示有5件物品，10为最大承重，2-6行为5个物品的价值和重量。 生成以下的表格 0 6 6 6 6 6 6 6 6 6 0 6 6 9 9 9 9 9 9 9 0 6 6 9 9 9 9 11 11 14 0 6 6 9 9 9 10 11 13 14 0 6 6 9 9 12 12 15 15 15 所以最终的结果是最后一行最后一列的 15 给出代码： 12345678910111213141516171819202122232425262728293031/* 01 package problem */#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;int pack[100][1000];int c[100],w[100];void make(int n, int r)&#123; memset(pack,0,sizeof(pack)); for (int i = 1; i &lt;= n; i++) for (int j = w[i]; j &lt;= r; j++) pack[i][j] = max(pack[i - 1][j - c[i]] + w[i], pack[i - 1][j]); cout&lt;&lt;pack[n][r];&#125;int main()&#123; int t,n,V; cin&gt;&gt;t; while(t--)&#123; //多组数据 cin&gt;&gt;n&gt;&gt;V; for (int i = 1; i &lt;= n; i++) cin&gt;&gt;c[i]&gt;&gt;w[i]; make(n,V); &#125; return 0;&#125; 代码优化 这个代码在时间上应该已经不能再优化了，但是还可以考虑空间复杂度的优化。 优化的基本思路： 考虑所用到的状态转移方程: pack[i][j] = max(pack[i-1][j-c[i]] + w[i], pack[i-1][j]); 可以发现 pack[i][j] 的值并不和整个二维表的每一个数字的值都有关，而是仅仅和上面一行的值有关，所以可以使用 pack[2][n] 这么大的数组来存储结果。 考虑状态转移方程的实际情况，还可以使用一维数组来进行运算，但是要注意的是，此时，循环应该从后往前进行。因为如果是按从前往后的顺序，那么 pack[i][j] = max(pack[i][j-c[i]] + w[i] , pack[i][j]); 中进行比较的两个值 pack[i][j] 是没有更新的，也就是 pack[i-1][j] 的值，而 pack[i][j - c[i]]一定是前面被更新过的，也就是 pack[i][j-w[i]] 的值。这就是说，max() 比较的两个数是属于原来二维数组中不同的两行，而不是我们期望的相同的两行。 如果上面的说法不能理解我们不妨这样：有一件物品的性价比很高，在pack数组的某个位置，我们第一次将这个物品放入背包中，但是按照从前往后的顺序，很可能在这个位置的后面某个位置我们会再次将这个物品添加进去。 优化后的代码 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int pack[10000],c[1000],w[1000];void make(int n, int r)&#123; memset(pack,0,sizeof(pack)); for (int i = 1; i &lt;= n; i++) for (int j = r; j &gt;= w[i]; j--) pack[j] = max(pack[j], pack[j - c[i]] + w[i]); cout&lt;&lt;pack[r]&lt;&lt;endl;&#125;int main()&#123; int n,t,V; cin&gt;&gt;t; while(t--)&#123; cin&gt;&gt;n&gt;&gt;V; for (int i = 1; i &lt;= n; i++) cin&gt;&gt;c[i]&gt;&gt;w[i]; make(n,V); &#125; return 0;&#125; 初始化问题： 如果限定背包必须装满，那么需要将数组初始化为 -∞ （负无穷大） 如果背包可以不装满，那么数组初始化为0 为了后面的书写方便，我们把代码改成这样1234void ZeroOnePack(int c,int w)&#123; for (int i = V; i &gt;= c; i--) pack[i] = max(pack[i], pack[i - c] + w);&#125; 这样01背包问题的主要代码就是这样： 12for (int i = 0; i &lt; n; i++) ZeroOnePack(c[i],w[i]); 这样ZeroOnePack()这个函数就专门解决了“放一个物品”的问题 完全背包问题 完全背包问题和0/1背包问题几乎一模一样，不同的就是物品不再是一个，而是无数个 思路 完全背包不同处是原来的一个物品变成了无数个，但是我们还是可以把它变成0/1背包问题的，试想一下，即使拥有无数个物品，但是真的可以用无数个吗？ 不可能，因为背包的容量有限，所以每个物品c,w最多可以使用[V/c]个，所以以下面的数据为例： c: 3 2 5 4 w: 7 4 2 5 V = 10 我们完全可以把这组数据改成这样： c: 3 3 3 2 2 2 2 2 5 5 4 4 w: 7 7 7 4 4 4 4 4 2 2 5 5 原因自然是背包容量最大为10,所以占用空间为3的物品最多放3个，修改过后的数据就可以用0/1背包的方法处理 那难道完全背包需要重开一个c2[],w2[]，然后按0/1背包处理吗？ 当然不是，还记得我们将0/1背包进行优化时说的如果循环从前向后进行会发生什么后果吗？ 这一句 “但是按照从前往后的顺序，很可能在这个位置的后面某个位置我们会再次将这个物品添加进去。” 看到了？0/1背包时为了避免重复，我们将循环改为从后往前，但是完全背包是可以重复使用物品的，对吧？所以代码： 1234void CompletePack(c,w)&#123; for (int i = c; i &lt;= V; i++) pack[i] = max(pack[i],pack[i - c] + w )&#125; 怎么样，和0/1背包只有一点点的差别对不对？ 3.多重背包问题 多重背包和0/1背包不同的地方就是物品不是一个而是有m个 所以我们还是就一个物品c,w,m分析： 对于m可能有两种情况： m &gt;= [V/c]，这种情况明显是完全背包 0 &lt; m &lt; [v/c]，对于这种情况需要认真分析一下 我们仍然需要按照0/1背包的思路把这些物品拆开，而且我们要保证我们拆出来的这些物品可以通过组合表示出1到m任意件物。 我们可以考虑二进制的计数方法，这样我们把物品拆成(c,w) , (2c,2w) , (4c,4w) …… [(m-2^k)*c , (m-2^k)*w)] 不管最优解会在这件物品中取几件，我们都可以用我们拆出来的这些物品来表示（请自己证明，二进制的思想） 所以，有了思路，代码就简单了： 12345678910111213void MultiplePack(c,w,m)&#123; if (c * m &gt;= V) &#123; CompletePack(c,w); return; &#125; k = 1; while (k &lt; m) &#123; ZeroOnePack(c*k,w*k); m = m - k; k = 2 * k; &#125; ZeroOnePack(c * m, w * m);&#125; 其实就是0/1背包和完全背包的组合，有木有？","categories":[{"name":"算法","slug":"算法","permalink":"http://github.com/categories/算法/"}],"tags":[{"name":"背包问题","slug":"背包问题","permalink":"http://github.com/tags/背包问题/"},{"name":"算法","slug":"算法","permalink":"http://github.com/tags/算法/"},{"name":"C/C+","slug":"C-C","permalink":"http://github.com/tags/C-C/"}]},{"title":"Markdown文档中mathjax的问题","slug":"markdown文档中mathjax的问题","date":"2018-04-12T14:35:54.000Z","updated":"2018-04-12T15:08:49.644Z","comments":true,"path":"2018/04/12/markdown文档中mathjax的问题/","link":"","permalink":"http://github.com/2018/04/12/markdown文档中mathjax的问题/","excerpt":"在写markdown文档时经常会需要插入数学公式，我之前只会使用图片插入，上次在看到mathjax后，我开始了使用mathjax的历程，但在实际写文档的过程中遇到了一些问题。","text":"在写markdown文档时经常会需要插入数学公式，我之前只会使用图片插入，上次在看到mathjax后，我开始了使用mathjax的历程，但在实际写文档的过程中遇到了一些问题。 关于有一些公式无法正确的显示在写机器学习的文章中遇到的一个关于范数的公式写出来编辑器上显示没有问题，但是一旦放进文档里就不行了，这个问题困扰了我很长时间。 这是代码：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \\lim_&#123;k\\to\\infty&#125;\\left( \\sum_&#123;i=1&#125;^n\\mid p_i-q_i\\mid ^k\\right)^\\frac&#123;1&#125;&#123;k&#125; $$ 这是效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \\lim{k\\to\\infty}\\left( \\sum{i=1}^n\\mid p_i-q_i\\mid ^k\\right)^\\frac{1}{k} $$ 这里haroopad显示的公式是正确的，但是hexo编译过后的网页显示就不对了。 把代码剪裁一下，看看什么样子的公式是可以的：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \\lim_&#123;k\\to\\infty&#125;\\left( \\sum_i \\right) $$ 效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \\lim_{k\\to\\infty}\\left( \\sum_i \\right) $$ 这个好像就可以，但是貌似sum后面的i一旦加上花括号就不行：12&gt; 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&gt; $$ \\lim_&#123;k\\to\\infty&#125;\\left( \\sum_&#123;i&#125; \\right) $$ 效果： 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义$$ \\lim{k\\to\\infty}\\left( \\sum{i} \\right) $$ 于是我点开了两个网页的源代码，定位到这一行：1&lt;p&gt;严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&lt;br&gt;$$ \\lim&lt;em&gt;&#123;k\\to\\infty&#125;\\left( \\sum&lt;/em&gt;&#123;i&#125; \\right) $$&lt;/p&gt; 1&lt;p&gt;严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义&lt;br&gt;$$ \\lim_&#123;k\\to\\infty&#125;\\left( \\sum_i \\right) $$&lt;/p&gt; 可以发现最明显的不同就算lim后面的 &lt;em&gt;，这时我们注意到，hexo在编译的时候将lim和sum后面的下划线 _翻译成强调的 &lt;em&gt; 了，仔细观察前面的公式，确实可以发现一部分变成了斜体。所以我们要在所有的下划线 _ 前面加上 \\ 转义就可以了。 OK，搞定 p.s 我的chrome上显示的公式后面都有一个竖线，firefox没有，内啥，一般平时用chrome习惯，所以有人知道怎么弄咩？ 上面的问题在重新配置Hexo之后就没有了，个人觉得应该是版本的问题？","categories":[{"name":"Markdown","slug":"Markdown","permalink":"http://github.com/categories/Markdown/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://github.com/tags/Markdown/"}]},{"title":"Convolutional Neural Networks / Week 3","slug":"Convolutional-Neural-Networks-Week-3","date":"2018-04-12T09:09:44.000Z","updated":"2018-04-12T14:57:16.915Z","comments":true,"path":"2018/04/12/Convolutional-Neural-Networks-Week-3/","link":"","permalink":"http://github.com/2018/04/12/Convolutional-Neural-Networks-Week-3/","excerpt":"Object LocalizationObject localization用来识别图像中是否包含特定对象以及该对象的位置，并最终使用一个矩形框在图像中标出该特定对象。为了简化问题，在这里我们假设图片中最多包含一个待识别的对象。下面对问题进行形式化描述。 定义目标变量$y$ (同时也是神经网络的输出层)，$$y = [P_c~b_x~b_y~b_h~b_w~C_1~C_2~C_3]^T\\tag{1}$$","text":"Object LocalizationObject localization用来识别图像中是否包含特定对象以及该对象的位置，并最终使用一个矩形框在图像中标出该特定对象。为了简化问题，在这里我们假设图片中最多包含一个待识别的对象。下面对问题进行形式化描述。 定义目标变量$y$ (同时也是神经网络的输出层)，$$y = [P_c~b_x~b_y~b_h~b_w~C_1~C_2~C_3]^T\\tag{1}$$ 其中，$P_c$表示图像中是否包含特定对象，$(b_x, b_y)$表示特定对象的中心位置在图像中的坐标（图像左上角坐标为$(0,0)$，右下角坐标为$(1,1)$），$b_h,b_w$分别表示特定对象的高度和宽度，$C_1-C_3$表示特定对象的类型（行人，汽车，摩托车）。 定义损失函数$\\mathcal{L(\\hat{y}, y)}$，$$\\mathcal{L}(\\hat{y}, y) =\\begin{split}\\begin{cases}\\sum_{i=1}^{i=8} (\\hat{y}_i - y_i)^2,&amp;~if~y_1=1 \\\\(\\hat{y}_1 - y_1)^2,&amp;~if~y_1=0\\end{cases}\\end{split}$$这里针对不同的维度都使用了平方差损失函数，可以针对不同的维度使用不同的损失函数。 Landmark Detection有时我们需要识别图中的一些关键点的坐标，这些坐标称为Landmarks。这时候，我们可以定义如下的目标变量$y$$$y = [P~l_{x1}~l_{y1}~\\dots~l_{xn}~l_{yn}]^T$$以识别人面部眼角嘴角为例，其中$P$代表是否包含人脸，$(l_{xi}, l_{yi})$代表关键点的坐标。 Object Detection Object Detction的其中一种办法叫做Sliding windows detection，采用不同尺寸的矩形框，从左至右、从上到下遍历枚举图像的子图，判断子图中是否包含需要的目标对象。很明显，这种办法比较笨，需要消耗大量的计算量。 Convolutional Implementation of Sliding Windows全连接是可以通过卷积来实现的，并且两者直接是等价的。例如，如果$5\\times 5 \\times 16$的卷积层之后接的是一个$400$个神经元的全连接层，那么它等价于$5 \\times 5 \\times 16$的卷积层之后采用400个$5 \\times 5 \\times 16$的filters得到的$1 \\times 1 \\times 400$的卷积层。 得益于卷积的存在，Sliding windows detection可以做到同时预测同一张图像不同子图中是否包含特定对象。但是这样做的不利条件是预测出来的对象的边界（bounding box）会相对不准确。因为这种办法采用的是子图的边界来作为待预测对象的边界。 Bounding Box Predictions这里介绍了YOLO algorithm (You Only Look Once)，该算法用来识别同一张图像上的多个目标简单。它将图像切分为了$M \\times N$的网格并在此基础上构造了卷积神经网络。该网络的输入依然为整张图片，切分并不影响输入，而是决定了网络的输出尺寸为$M \\times N \\times 8$。这样，每个子图就拥有了一个$1 \\times 1 \\times 8$的预测结果，用来表示图像中是否包含特定的对象，如果包含的话，该特定对象的中心位置、长宽以及类别分别是什么。 该算法利用了卷积操作提高了对同一张图像上不同子图的模型训练预测的效率，使得一次训练就可以完成对多个子图的建模（这里有个假设，就是每个子图上只包含最多一个特定对象）。 Intersection Over Union$$Intersection over Union (loU) = \\frac{size~of~intersection}{size~of~union}$$ 通过loU，我们可以知道两个矩形在大小和位置上的相像程度。这样，我们就可以用它来评价object detection算法的优劣。 Non-max Suppression有时候，我们的算法会将相同的对象识别多次，non-max suppression算法用来解决这个问题。举例， 假设卷积神经网络最后的输出为$19 \\times 19 \\times 5$，也就是说图像被切分为了$19 \\times 19$的子图，每个子图的预测结果为一个5维的向量，该向量如下，$$y = [p_c~b_x~b_y~b_h~b_w]^T$$那么，在训练结束之后，non-max suppression算法会执行如下步骤， 扔掉所有$p_c \\le 0.6$的bounding boxes 取出剩余bounding boxes中$p_c$最大的那个bounding box，作为新检测到的目标 删除剩余所有与该box的loU值$\\ge 0.5$的bounding boxes 重复(2-3)步，直到没有bounding boxes剩余 从上可以看出，non-max suppression其实是个简单的贪心算法。 Anchor Boxes在Object detection问题中，还有一个难点就是图像划分出网格后，每个网格中只能最多识别一个对象。为了让单个网格识别多个对象，可以采用Anchor boxes方法。 Anchor boxes方法的思想很简单，将式(1)改为如下形式，$$y = [P_c~b_x~b_y~b_h~b_w~C_1~C_2~C_3~P_c~b_x~b_y~b_h~b_w~C_1~C_2~C_3]^T\\tag{2}$$式(2)表示在识别的过程中采用了两个Anchor box。每个Anchor box都负责识别所有类别的对象。","categories":[{"name":"deep-learning","slug":"deep-learning","permalink":"http://github.com/categories/deep-learning/"}],"tags":[]},{"title":"Convolutional Neural Networks / Week 1","slug":"Convolutional-Neural-Networks-Week-1","date":"2018-04-12T09:09:44.000Z","updated":"2018-04-12T12:42:44.005Z","comments":true,"path":"2018/04/12/Convolutional-Neural-Networks-Week-1/","link":"","permalink":"http://github.com/2018/04/12/Convolutional-Neural-Networks-Week-1/","excerpt":"Computer VisionComputer Vision Problems include: Image Classication Object Detection … … One of the challenges of computer vision problems is that the input can be very big. For example, a 1000 by 1000 image can have $1000 \\times 64 \\times 3 = 12288$ dimensions because there are three color channels. If the size of hidden layer is 1000, the number of parameters from input layer to hidden layer could be 3 billion. This will cause these problems: data size requirements; computational requirements; memory requirements.","text":"Computer VisionComputer Vision Problems include: Image Classication Object Detection … … One of the challenges of computer vision problems is that the input can be very big. For example, a 1000 by 1000 image can have $1000 \\times 64 \\times 3 = 12288$ dimensions because there are three color channels. If the size of hidden layer is 1000, the number of parameters from input layer to hidden layer could be 3 billion. This will cause these problems: data size requirements; computational requirements; memory requirements. PaddingThe problems of convolutional operation: shrinking output throwing away a lot of information from the edges of the image In order to fix these problems, what we need to do is pad the image. 通常有两种padding的方式： Valid convolution: 意思是不采用padding的方式。 Same convolution：意思是输出的尺寸和输入的尺寸相同。 在这种情况下可以推导出$p = \\frac{f-1}{2}$，所以在计算机视觉的模型中，filter的尺寸通常是奇数而不是偶数。 Filter的尺寸是奇数还有另外一个好处，就是filter可以有中心像素，可以很方便的用来定位filter的位置。 Strided Convolutions给定如下条件，$$\\begin{split}&amp;n\\times n~image~~~~&amp;f\\times f~filter\\\\&amp;padding~p&amp;stride~s\\end{split}$$经过Strided Convolutions之后得到的tensor的尺寸为，$$\\lfloor \\frac{n + 2p - f}{s} + 1 \\rfloor \\times \\lfloor \\frac{n + 2p - f}{s} + 1 \\rfloor$$ NG在这里提到，我们所谓的convolution并不是真正意义上的卷积，而是应该称为cross-correlation，它之前实际上应该有一个针对卷积核的变换操作，这些操作再加上cross-correlation才是真正的convolution。但是这个变换操作没什么用处，所以通常情况下就省略了。 Convolutions Over Volume在RGB类型的多通道图像中使用Multiple filters：$$n \\times n \\times n_c \\ast f\\times f \\times n_c \\rightarrow (n - f + 1) \\times (n - f + 1) \\times {n_c}’$$其中，$n$表示图像的长宽，$f$表示filter的长宽，$n_c$表示图像的通道数，$n_c’$表示filter的个数。 One Layer of a Convolutional Network普通的BP神经网络的数学表达形式如下：$$\\begin{split}z^{[1]} &amp;= w^{[1]} a^{[0]} + b^{[1]} \\\\a^{[1]} &amp;= g(z^{[1]})\\end{split}$$在CNN中，convolution operation相当于$w^{[1]}a^{[0]}$，也就是充当了原先线性变换的角色。 这里对卷积层中涉及到的符号进行总结，$$\\begin{split}f^{[l]} &amp;= filter~size \\\\p^{[l]} &amp;= padding \\\\s^{[l]} &amp;= stride \\\\n_{C}^{[l]} &amp;= number~of~filters\\end{split}\\tag{1}$$接着定义卷积层的输入和输出表示，$$\\begin{split}Input:~&amp;n_H^{[l-1]} \\times n_W^{[l-1]} \\times n_C^{[l-1]} \\\\Output:~&amp;n_H^{[l]} \\times n_W^{[l]} \\times n_C^{[l]}\\end{split}\\tag{2}$$ 基于(1)和(2)，我们可以进行如下定义，$$\\begin{split}&amp;Each~filter~is:~ &amp;f^{[l]} \\times f^{[l]} \\times n_C^{[l-1]} \\\\&amp;Activations:~ &amp;a^{[l]} \\rightarrow n_H^{[l]} \\times n_W^{[l]} \\times n_C^{[l]} \\\\&amp;Weights:~ &amp;f^{[l]} \\times f^{[l]} \\times n_C^{[l-1]} \\times n_C^{[l]} \\\\&amp;bias:~ &amp;n_C^{[l]}\\end{split}\\tag{3}$$在式(2)中，$n_H^{[l]}$与$n_H^{[l-1]}$的关系如下，$$n_H^{[l]} = \\lfloor \\frac{n_H^{[l - 1]} + 2p^{[l]} - f^{[l]}}{s^{l}} + 1 \\rfloor$$在式(3)中，Activations是单个样本的形式，batch的形式如下，$$A^{[l]} \\rightarrow m \\times n_H^{[l]} \\times n_W^{[l]} \\times n_C^{[l]}$$ Simple Convolution Network Example以图像分类为例（识别图片中是否有猫），经过若干卷积层之后，为了得到最终的$0/1$分类结果，会将最后一层卷积的tensor展开并拉长成vector，经过logistic/softmax单元后得到代表预测结果的概率值。 在使用ConvNet的过程中，比较麻烦的地方在于如何确定超参。有一个常用的指导方针是，activations的长和宽需要越来越小（也就是图片的尺寸越来越小），同时通道数需要越来越多（也就是activations的第三个维度）。之后会详细介绍怎么需选择超参。 在ConvNet中，通常有三种类型的网络层， Convolution (CONV) Pooling (POOL) Fully connected (FC) Pooling LayersPooling Layer有如下好处， 减少图像representation的尺寸，提高计算速度 提高鲁棒性 很有意思的地方在于，对于pooling layer来说，我们只需要确定超参数$f^{[l]}$和$s^{[l]}$，以及是max pooling 还是average pooling，并不需要进行参数的学习。 在pooling layer中，超参$p^{[l]}$通常设置为0。 CNN Example神经网络中常用的一种模式是，若干卷积层之后加池化层，再若干层卷积层之后接池化层，然后接全连接层，最后给softmax单元。NG在课上画了一个例子如下， Why Convolutions卷积层最显著的特点就是参数数量大大小于全连接层的数量，因为： Parameter sharing: 图像的不同位置共享filters。 Sparsity of connections: 每个输出值只取决于很小的一部分输入。这样也降低了过拟合的风险。 卷积神经网络的损失函数定义如下所示，$$Cost~J = \\frac{1}{m} \\sum_{i-1}^{m} \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)})$$ Programming AssignmentsConvolutional Model: step by step卷积层和池化层的区别： 卷积层中的每个filter都会同时作用在不同的channel上 在池化层中，filter与channel一一对应，作用在对应的channel上 References MarkDown中使用Latex数学公式 Hexo博客(13)添加MathJax数学公式渲染 解释了Markdown和Mathjax渲染冲突问题","categories":[{"name":"deep-learning","slug":"deep-learning","permalink":"http://github.com/categories/deep-learning/"}],"tags":[]},{"title":"Convolutional Neural Networks / Week 4","slug":"Convolutional-Neural-Networks-Week-4","date":"2018-04-12T09:09:44.000Z","updated":"2018-04-12T15:06:09.549Z","comments":true,"path":"2018/04/12/Convolutional-Neural-Networks-Week-4/","link":"","permalink":"http://github.com/2018/04/12/Convolutional-Neural-Networks-Week-4/","excerpt":"What is Face Recognition这里区分两个概念，Face verification和Face recognition， Verification 输入：图像 + 名字/ID 输出：输入的图像上是否有名字/ID表示的那个人 Recognition 数据库中有$K$个人 输入：图像 输出：图像上有的数据库中的人的名字/ID 很明显，Recognition比Verification的难度要大得多。","text":"What is Face Recognition这里区分两个概念，Face verification和Face recognition， Verification 输入：图像 + 名字/ID 输出：输入的图像上是否有名字/ID表示的那个人 Recognition 数据库中有$K$个人 输入：图像 输出：图像上有的数据库中的人的名字/ID 很明显，Recognition比Verification的难度要大得多。 One Shot Learning什么是One-shot learning， Learning from one example to recognize the person again. 很多时候公司的数据库中只有一张员工的照片，那么我们在做人脸识别系统的时候怎么根据这一张照片来再次识别相同的人的影像？如果用传统的卷积神经网络来做的话，因为训练数据很小，所以通常效果并不理想。 在这种情况下，我们应该学习”similarity” function,$$d(img1, img2) = degree~of~difference~between~images$$然后可以根据Similarity function完成verification,$$\\begin{split}If~d(img1, img2) &amp;\\le \\tau~same\\\\&amp;&gt; \\tau~different\\end{split}$$ Siamese NetworkParameters of NN define an encoding $f(x^{(i)})$ Learn parameters so that: If $x^{(i)}, x^{(j)}$ are the same person, $| f(x^{(i)}) - f(x^{(j)}) |^2$ is small If $x^{(i)}, x^{(j)}$ are the different person, $| f(x^{(i)}) - f(x^{(j)}) |^2$ is large 那么，该网络学习的目标函数应该怎么定义呢？ Triple Loss在Triple loss中，基准人脸图像称为Anchor image，正样本为Positive image，负样本为Negative image，那么我们希望得到的是，$$|f(A) - f(P) | ^2 \\le | f(A) - f(N) | ^2$$也就是，$$|f(A) - f(P) | ^2 - | f(A) - f(N) | ^2 \\le 0$$这里有个问题，如果$f$始终预测0，那么上述条件始终满足。为了防止这种情况发生，所以需要增加一个超参$\\alpha$，也称为margin，$$|f(A) - f(P) | ^2 - | f(A) - f(N) | ^2 + \\alpha \\le 0$$下面对Loss function进行形式化定义，给定3个图像 A, P, N，$$\\mathcal{L}(A, P, N) = max(|f(A) - f(P)|^2 -|f(A) - f(N)|^2 + \\alpha, 0)$$在整体样本上的损失为，$$J = \\sum_{i=1}^{M} \\mathcal{L}(A^{(i)}, P^{(i)}, N^{(i)})$$很明显，在训练样本中，一个人需要有多张照片才能组合出这样的三元组。 那么，应该怎么选择三元组呢， During training, if A, P, N are chsen randomly, $d(A, P) + \\alpha \\le d(A, N)$ is easily satisfied. 这种方法容易选择，但是训练出来的模型效果一般 Choose triplets that’re “hard” to train on. 这种方法不容易选择，但是模型能学习到更多的信息。 Face Verification and Binary Classification另一种similarity function，以一对图像作为输入，$$\\hat{y} = \\delta ( \\sum_{k=1}^{128} w_i | f(x^{(i)})_k - f(x^{(j)})_k | + b )$$其中，$f(x^{(i)})$表示对第i张图像的128维的embedding表达。 What are deep ConvNets Learning这里介绍了怎么将卷积神经网络的hidden layer可视化。以第一层为例， Pick a unit in layer 1. Find the nine image patches that maximize the unit’s activation. Repeat for other units. 可以看到，每个unit’s activation针对的方向不同，有的是颜色，有的是不同方向的边。随着网络深度的增加，每个unit’s activation可以看到的图像的范围越来越大。 Neural Style Transfer Cost Function原始内容图片为C，风格图片为S，目标图片为G，那么，$G_{kk’}^{[l]}$$$J(G) = \\alpha J_{content}(C, G) + \\beta J_{style}(S, G)$$ 下面介绍Style matrix,$$\\begin{split}&amp; Let~a_{i,j,k}^{[l]} &amp;= activation~at~(i,j,k). G^{[l]}~is~n_c^{[l]} \\times n_c^{[l]} \\\\\\rightarrow &amp; G_{kk’}^{[l]} &amp;= \\sum_{i=1}^{n_H^{[l]}} \\sum_{j=1}^{[n_W]^{[l]}} a_{ijk}^{[l]} a_{ijk’}^{[l]}\\end{split}$$其中，$G^{[l]}$为Style matrix。","categories":[{"name":"deep-learning","slug":"deep-learning","permalink":"http://github.com/categories/deep-learning/"}],"tags":[]},{"title":"Convolutional Neural Networks / Week 2","slug":"Convolutional-Neural-Networks-Week-2","date":"2018-04-12T09:09:44.000Z","updated":"2018-04-12T13:57:00.925Z","comments":true,"path":"2018/04/12/Convolutional-Neural-Networks-Week-2/","link":"","permalink":"http://github.com/2018/04/12/Convolutional-Neural-Networks-Week-2/","excerpt":"Classic NetworksLeNet-5的网络结构如下，","text":"Classic NetworksLeNet-5的网络结构如下， AlexNet的网络结构如下， VGG-16的网络结构如下， ResNets在一般的神经网络中，两层神经网络的数学表达如下，$$\\begin{split}&amp; z^{[l+1]} = W^{[l+1]}a^{[l]} + b^{[l+1]} \\\\&amp; a^{[l+1]} = g(z^{[l+1]}) \\\\&amp; z^{[l+2]} = W^{[l+2]}a^{[l + 1]} + b^{[l+2]} \\\\&amp; a^{[l+2]} = g(z^{[l+2]})\\end{split}$$而在ResNets中，修改了$a^{[l+2]}$的生成方式，变成了，$$a^{[l+2]} = g(z^{[l + 2]} + a^{[l]})\\tag{1}$$这样的两层神经网络称为Residual block，将这样的Residual block串联起来就构成了ResNets。 ResNets解决了传统神经网络中存在的层数不能过深的问题。在传统的神经网络中，随着深度的增加，训练误差会先降后升，而对于ResNets，随着网络层数达到一百甚至一千层，训练误差也可以平缓的下降（也可能出现收敛的现象）。 Why ResNets Work首先来解释一下为什么在传统的网络后面加一个Residual block不会降低原有网络的性能，$$\\begin{split}a^{[l+2]} &amp;= g(z^{[l + 2]} + a^{[l]}) \\\\ &amp;= g((w^{[l+2]}a^{[l + 1]} + b^{[l + 2]}) + a^{[l]})\\end{split}$$假设我们采用的激活函数为RELU，同时$w^{[l+2]}$和$b^{[l+2]}$为0，那么，$$a^{[l+2]} = g(a^{[l]}) = a^{[l]}$$所以由于Residual block的存在，网络在第$l+2$层的时候，很容易退回到$l$层去。这样可以达到一个效果，在最差情况下，后边加上的Residual block仿佛不存在一样，这样就不会影响原先的效果。 Residual block中还有一点值得注意，对于式(1)来说，$z^{[l+2]}$和$a^{[l]}$的维度需要一致，那如果出现维度不一致的情况怎么办呢？增加一个$W_s$矩阵，$$a^{[l+2]} = g(z^{[l + 2]} + W_s a^{[l]})$$$W_s$有两种方式生成， 随机生成的参数矩阵，跟随其他参数一起训练学习。 $a^{[l]}$的基础上采用padding操作生成，比如补0。 Networks in Networks and 1x1 Convolutions1x1 Convolutons也称为Networks in networks，它是一个1x1的filters并使用了Relu非线性变换。 Inception Network Motivation在构造神经网络的时候，我们有时候会很困惑，用$1\\times1$的卷积效果好，还是$f^{[l]}\\times f^{[l]}$的卷积效果好，或者用Max-pooling效果会更好呢？Inception Network的思想是，那就把他们在同一层中都用一遍，这样就会得到若干tensor的输出，然后再把这些tensor在channel的纬度上拼在一起，组合一个大的tensor。最后，用数据去训练学习，决定这些filters的参数。 这样会有如下问题， 如何让这些tensor在除了channel之外的其他维度上保持尺寸一致？ 会不会造成计算量的显著增加？ 对于问题(1)其实很好解决，采用padding的方式就可以让这些tensor的$n_H$和$n_W$保持一致。 对于问题(2)可以通过在两层网络中间增加一层$1\\times1$ filter来解决。下面详细描述原理。 假设我们有这样两层网络， 那么从左到右需要的乘法运算的数量为，$$(28 \\times 28 \\times 32) \\times (5 \\times 5 \\times 192) \\approx 120~million$$如果我们在图(1)两层网络中间加入一层使用了$1\\times1$ filter的卷积层，如图(2)所示， 那么从左到右所需要的乘法运算的数量为，$$\\begin{split}&amp;1st~layer \\rightarrow 2nd~layer：&amp;(28 \\times 28 \\times 16) \\times (1 \\times 1 \\times 192) \\approx 2.4~million \\\\&amp;2nd~layer \\rightarrow 3rd~layer：&amp;(28 \\times 28 \\times 32) \\times (5 \\times 5 \\times 16) \\approx 10~million\\end{split}$$也就是共需要$12.4~million$的乘法运算。从中可以看到，加入”bottleneck layer”之后，所需要的计算量减少为了原来的十分之一。 Transfer Learning当我们有一个比较小的训练数据集的时候，我们可以在别人训练好的模型的基础上来达到我们的目的：删除最后的softmax layers，保留之前的layers的模型结构和权重，并在之后增加我们自己的softmax layers。然后用较小的训练数据集来训练我们新增加的layers的参数。这样就可以用较少的数据来得到不错的预测效果。 其中，我们可以预先存储训练数据集中的样本经过之前的layers (删除原先的softmax layers)之后得到的activations，这样就不用在之后训练新的softmax layers参数的时候反复计算，从而节省计算量并提高效率。 随着我们拥有的训练数据的增加，我们可以保留较少层数的参数不发生改变，其余网络层以原先权重为初始参数，然后在新的训练数据集上进行训练调整。如果我们的训练数据足够大，那么原先所有层的参数都可以只作为初始参数，让它们在新的数据集上进行训练调整。 Data Augmentation通常在机器学习中，我们需要大量的训练数据，因此有一些常用的有效的增加数据集的方法， Mirroring: 镜像处理 Random Cropping: 随机图像裁剪 Rotation: 图像旋转 Shearing: Local warping: 局部变形 Color Shifting: 在不同的颜色通道上增减一定的数值，例如$R+20, G-20, B+20$","categories":[{"name":"deep-learning","slug":"deep-learning","permalink":"http://github.com/categories/deep-learning/"}],"tags":[]},{"title":"利用GitHub搭建一个你的博客","slug":"利用GitHub搭建一个你的博客","date":"2018-04-12T08:04:26.000Z","updated":"2018-04-12T08:14:41.109Z","comments":true,"path":"2018/04/12/利用GitHub搭建一个你的博客/","link":"","permalink":"http://github.com/2018/04/12/利用GitHub搭建一个你的博客/","excerpt":"为什么要写博客作为一只程序猿，踩到坑是一件非常正常的事，当我们踩到坑的时候就会花心思去研究它，可能我们能够在当时把问题弄懂并把问题给解决掉。可是过一段时间我们又遇到了同样的坑的时候，难道还要再去 百毒 Google 重新搜索一遍吗？这样做效率难免太低了，倒不如在第一次解决问题的时候就把解决方法写到我们的博客了，当我们再一次遇到相同的坑的时候翻一翻我们之前写的博客就能快速的把问题给解决掉，何乐而不为。而且我们学习新技术的时候也可以将当时学到的内容写到我们的博客，再次遇到的时候我们就可以找回当时学习的思路，继续学习。废话不多说，马上开始行动起来，搭建博客！ 声明：本文在Windows下进行操作的，Mac以及其它操作系统请做参考 多图警告！","text":"为什么要写博客作为一只程序猿，踩到坑是一件非常正常的事，当我们踩到坑的时候就会花心思去研究它，可能我们能够在当时把问题弄懂并把问题给解决掉。可是过一段时间我们又遇到了同样的坑的时候，难道还要再去 百毒 Google 重新搜索一遍吗？这样做效率难免太低了，倒不如在第一次解决问题的时候就把解决方法写到我们的博客了，当我们再一次遇到相同的坑的时候翻一翻我们之前写的博客就能快速的把问题给解决掉，何乐而不为。而且我们学习新技术的时候也可以将当时学到的内容写到我们的博客，再次遇到的时候我们就可以找回当时学习的思路，继续学习。废话不多说，马上开始行动起来，搭建博客！ 声明：本文在Windows下进行操作的，Mac以及其它操作系统请做参考 多图警告！ 1.环境搭建首先需要下载两个东西 node.js git 具体的下载，安装就不用多说了，基本上下载完默认安装即可，安装的路径最好先记住。Git 安装的时候会弹出下面的窗口，我们选择第二个即可。这样我们在Windows的命令窗口也可以进行Git操作了。两个都安装完了之后，打开命令窗口（按住Win+R后输入CMD即可打开命令窗口），分别输入 node -v 、npm -v 及 git –version 这三个命令是为了查看刚才我们安装的软件的版本，如果你能够看到他们的版本号（如同下图，也许版本号会有不同），那么恭喜你，环境搭建这一个大难关你已经过了，可以进入下一步骤了。 1.1有问题看这里 打开我们刚才安装软件的路径，例如我的路径“D:\\Program Files\\nodejs”、“D:\\Program Files\\Git”。复制我们刚才安装的路径,打开计算机&gt;右键单击属性，选择高级系统设置&gt;选择环境变量&gt;双击 PATH &gt;将我们安装的路径追加到变量值之后 ！注意分号以及确定保存这个时候再试一下 node -v 、npm -v 及 git –version 这三个命令，一般都不会有问题的了。 2.配置 GitHub2.1注册 GitHub先到GitHub官网Sign up(注册)一个账号。填好用户名、邮箱、密码进入下一步 2.2SSH授权注册好账号之后我们可以随意的查看其他人的项目，甚至是clone下载，但是要提交代码就必须完成SSH授权，如果可以不用授权就提交代码的话，那么Github岂不是乱了套。 2.2.1生成SSH key打开Git Bash，输入ssh-keygen -t rsa然后按三下回车，如下图所示接着就会在C:\\Users\\Administrator.ssh目录下生成到id_rsa和id_rsa.pub两个文件，id_rsa是密钥，id_rsa.pub是公钥，接下来需要将id_rsa.pub的内容添加到GitHub上，这样本地的id_rsa密钥才能跟GitHub上的id_rsa.pub公钥进行配对，才能够授权成功。 2.2.2在GitHub上添加SSH Key首先点击右上角的倒三角进入Settings紧接着选择左侧SSH and GPG keys,然后选择右上角的New SSH key，再把id_sra.pub的内容复制粘贴到key（id_sra.pub可以使用 sublime 或者 记事本打开），最后Add SSH key就可以了。SSH key 添加成功之后，输入 ssh -T git@github.com 进行测试，如果出现以下提示证明添加成功了。 这一步一般没什么问题，有问题的话留言评论（顺便来一波打赏）就好了。直接进入下一步！ 3.创建 GitHub 仓库 需要特别注意的是，项目名称一定要使用 你的名字 + .github.io这一步也没什么问题，如果有问题，一定是你没有给我打赏(∩_∩) 4.设置本地博客的配置4.1安装Hexo在你认为合适的地方创建一个文件夹，然后在文件夹空白处按住 Shift+鼠标右键，然后点击在此处打开命令行窗口。（同样要记住啦，下文中会使用在当前目录打开命令行来代指上述的操作）在命令行输入npm install -g hexo然后输入 npm install hexo –save 这时候你会看到命令窗口刷了一堆白字，然后输入 hexo -v 查看hexo是否安装成功了。如果出现与上图一样的情况的话，就说明你离成功就近在咫尺了。 4.2初始化Hexo同样是在命令窗口中，继续输入 hexo init，等待下载好了之后输入 hexo s这时候我们就可以打开浏览器了，在地址栏中输入 http://localhost:4000/ 我们就可以看到如下图的界面，这个就是我们的博客。没错，我们的博客就这样建好了。不过这个只是我们本地的博客，下面就要考虑怎么把我们的本地博客上传到我们的GitHub上了。接下来先看一下我们的博客文章放在哪里。打开我们的文件夹下面的source文件夹，你会发现里面有一个_posts文件夹，再进入就会看到一片初始化的文章hello-world.md也就是上图显示在页面的文章。如果我们想新建文章的话，可以通过命令窗口输入hexo new ‘filename’我们的文件夹下面就会生成一个新的md文件，然后我们打开编辑就可以了。 4.3发布博客首先复制我们的GitHub项目地址，如下图。然后打开我们新建的文件夹下面生成的_config.yml文件，在最下方作如下修改。deploy 是部署的意思，type: git 就是使用 git 进行部署，repo: github仓库地址 注意：repo 原本是没有的，在最后自己加上就好。冒号之后有一个空格 冒号之后有一个空格 冒号之后有一个空格 接下来回到命令窗口，输入 npm install hexo-deployer-git –save安装好Git上传插件之后，输入 hexo g，然后输入 hexo d就可以将我们的博客上传到我们的GitHub了，而且以后更新文章就只需要用这两个命令就可以了。这样别人也可以通过 https://yourname.github.io 来访问我们的博客了（开头一定要用https，yourname是你的github的名字）。 5.个性化设置（更换主题）有木有觉得这个博客的默认主题特别的丑，如果不觉得可以忽略这一步（哈哈）。这里以我使用的主题为例。第一步去找我们想要的主题，然后下载下来。我用的是next主题，在命令窗口输入git clone https://github.com/iissnan/hexo-theme-next themes/next然后打开配置文件，找到 theme 将原来默认的 landscape 替换 next。然后在命令窗口输入 hexo clean 、hexo g 及 hexo s，先看一下本地博客是什么样子，确认好了在输入 hexo d 部署到GitHub每一个主题都有一个使用文档，next的使用文档为 http://theme-next.iissnan.com/getting-started.html 我们可以为我们的主题修改名字，添加评论等等，具体的你们就自己去研究了。 如果文章对你有所帮助，那么请您点一下❤由于本人水平有限，如有错误，欢迎大家指正。如果你在操作过程中发现一些没有讲到的错误或者问题，欢迎在评论留言，一起探讨，共同学习进步！有钱的来波赞赏，没钱的来波Star","categories":[{"name":"blog","slug":"blog","permalink":"http://github.com/categories/blog/"}],"tags":[{"name":"Git笔记","slug":"Git笔记","permalink":"http://github.com/tags/Git笔记/"}]},{"title":"Git--命令(一)","slug":"Git--命令(一)","date":"2018-04-12T07:02:42.000Z","updated":"2018-04-13T14:02:27.347Z","comments":true,"path":"2018/04/12/Git--命令(一)/","link":"","permalink":"http://github.com/2018/04/12/Git--命令(一)/","excerpt":"git命令学习 Git笔记 GitHub介绍GitHub 是为开发者提供 Git 仓库的托管服务。这是一个让开发者与朋友、同事、同学及陌生人共享代码的完美场所。总结一下，GitHub 最大的特征是“面向人” Git是一个“分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过“回撤”这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用“回撤”是找不回来的。而“版本管理工具”能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。 统一概念 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了’本地仓库’，每个commit，我叫它为一个‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了‘远程仓库’（GitHub等) 分支：Git鼓励你使用branch完成某个任务，合并后再删掉分支，过程更安全。 commit-id：输出命令：git log，最上面那行commit xxxxxx，后面的字符串就是commit-id 参考tips项目,和廖雪峰老师的git网站。","text":"git命令学习 Git笔记 GitHub介绍GitHub 是为开发者提供 Git 仓库的托管服务。这是一个让开发者与朋友、同事、同学及陌生人共享代码的完美场所。总结一下，GitHub 最大的特征是“面向人” Git是一个“分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过“回撤”这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用“回撤”是找不回来的。而“版本管理工具”能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。 统一概念 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了’本地仓库’，每个commit，我叫它为一个‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了‘远程仓库’（GitHub等) 分支：Git鼓励你使用branch完成某个任务，合并后再删掉分支，过程更安全。 commit-id：输出命令：git log，最上面那行commit xxxxxx，后面的字符串就是commit-id 参考tips项目,和廖雪峰老师的git网站。 Git介绍 Git是分布式版本控制系统 集中式VS分布式，SVN VS Git SVN和Git主要的区别在于历史版本维护的位置 Git本地仓库包含代码库还有历史库，在本地的环境开发就可以记录历史而SVN的历史库存在于中央仓库，每次对比与提交代码都必须连接到中央仓库才能进行。 这样的好处在于： 自己可以在脱机环境查看开发的版本历史。 多人开发时如果充当中央仓库的Git仓库挂了，可以随时创建一个新的中央仓库然后同步就立刻恢复了中央库。 Git命令Git配置12$ git config --global user.name \"Your Name\"$ git config --global user.email \"email@example.com\" git config命令的--global参数，表明这台机器上的所有Git仓库都会使用这个配置，也可以对某个仓库指定不同的用户名和邮箱地址。 创建版本库初始化一个Git仓库1$ git init 添加文件到Git仓库包括两步：12$ git add &lt;file&gt;$ git commit -m \"description\" 12345678#把工作时的所有变化提交到暂存区，包括文件内容修改(modified)以及新文件(new)，但不包括被删除的文件。$ git add . #仅监控已经被add的文件,不会提交新文件（untracked file）$ git add -u#是上面两个功能的合集（git add --all的缩写）$ git add -A git add可以反复多次使用，添加多个文件，git commit可以一次提交很多文件，-m后面输入的是本次提交的说明，可以输入任意内容。 显示文件树形结构1234567$ tree /f #指定tree使用字符而不是图形字符显示链接子目录的行$ tree /a #显示每个目录中的文件名``### 查看工作区状态```bash$ git status 查看修改内容1$ git diff 1$ git diff --cached 1$ git diff HEAD -- &lt;file&gt; git diff 可以查看工作区(work dict)和暂存区(stage)的区别 git diff --cached 可以查看暂存区(stage)和分支(master)的区别 git diff HEAD -- &lt;file&gt; 可以查看工作区和版本库里面最新版本的区别 查看提交日志1$ git log 简化日志输出信息1$ git log --pretty=oneline 查看命令历史1$ git reflog 版本回退1$ git reset --hard HEAD^ 以上命令是返回上一个版本，在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上一个版本是HEAD^^，往上100个版本写成HEAD~100。 回退指定版本号1$ git reset --hard commit_id commit_id是版本号，是一个用SHA1计算出的序列 工作区、暂存区和版本库工作区：在电脑里能看到的目录；版本库：在工作区有一个隐藏目录.git，是Git的版本库。Git的版本库中存了很多东西，其中最重要的就是称为stage（或者称为index）的暂存区，还有Git自动创建的master，以及指向master的指针HEAD。 进一步解释一些命令： git add实际上是把文件添加到暂存区 git commit实际上是把暂存区的所有内容提交到当前分支 撤销修改丢弃工作区的修改1$ git checkout -- &lt;file&gt; 该命令是指将文件在工作区的修改全部撤销，这里有两种情况： 一种是file自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是file已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 总之，就是让这个文件回到最近一次git commit或git add时的状态。 丢弃暂存区的修改分两步：第一步，把暂存区的修改撤销掉(unstage)，重新放回工作区：1$ git reset HEAD &lt;file&gt; 第二步，撤销工作区的修改1$ git checkout -- &lt;file&gt; 小结： 当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- &lt;file&gt;。 当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD &lt;file&gt;，就回到了第一步，第二步按第一步操作。 已经提交了不合适的修改到版本库时，想要撤销本次提交，进行版本回退，前提是没有推送到远程库。 删除文件1$ git rm &lt;file&gt; git rm &lt;file&gt;相当于执行12$ rm &lt;file&gt;$ git add &lt;file&gt; 进一步的解释Q：比如执行了rm text.txt 误删了怎么恢复？A：执行git checkout -- text.txt 把版本库的东西重新写回工作区就行了Q：如果执行了git rm text.txt我们会发现工作区的text.txt也删除了，怎么恢复？A：先撤销暂存区修改，重新放回工作区，然后再从版本库写回到工作区12$ git reset head text.txt$ git checkout -- text.txt Q：如果真的想从版本库里面删除文件怎么做？A：执行git commit -m &quot;delete text.txt&quot;，提交后最新的版本库将不包含这个文件 远程仓库创建SSH Key1$ ssh-keygen -t rsa -C \"youremail@example.com\" 关联远程仓库1$ git remote add origin https://github.com/username/repositoryname.git 推送到远程仓库1$ git push -u origin master -u 表示第一次推送master分支的所有内容，此后，每次本地提交后，只要有必要，就可以使用命令git push origin master推送最新修改。 从远程克隆1$ git clone https://github.com/usern/repositoryname.git 分支创建分支1$ git branch &lt;branchname&gt; 查看分支1$ git branch git branch命令会列出所有分支，当前分支前面会标一个*号。 切换分支1$ git checkout &lt;branchname&gt; 创建+切换分支1$ git checkout -b &lt;branchname&gt; 合并某分支到当前分支1$ git merge &lt;branchname&gt; 删除分支1$ git branch -d &lt;branchname&gt; 查看分支合并图1$ git log --graph 当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。用git log --graph命令可以看到分支合并图。 普通模式合并分支1$ git merge --no-ff -m \"description\" &lt;branchname&gt; 因为本次合并要创建一个新的commit，所以加上-m参数，把commit描述写进去。合并分支时，加上--no-ff参数就可以用普通模式合并，能看出来曾经做过合并，包含作者和时间戳等信息，而fast forward合并就看不出来曾经做过合并。 保存工作现场1$ git stash 查看工作现场1$ git stash list 恢复工作现场1$ git stash pop 丢弃一个没有合并过的分支1$ git branch -D &lt;branchname&gt; 查看远程库信息1$ git remote -v 在本地创建和远程分支对应的分支1$ git checkout -b branch-name origin/branch-name， 本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联1$ git branch --set-upstream branch-name origin/branch-name； 从本地推送分支1$ git push origin branch-name 如果推送失败，先用git pull抓取远程的新提交； 从远程抓取分支1$ git pull 如果有冲突，要先处理冲突。 标签tag就是一个让人容易记住的有意义的名字，它跟某个commit绑在一起。 新建一个标签1$ git tag &lt;tagname&gt; 命令git tag &lt;tagname&gt;用于新建一个标签，默认为HEAD，也可以指定一个commit id。 指定标签信息1$ git tag -a &lt;tagname&gt; -m &lt;description&gt; &lt;branchname&gt; or commit_id git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;可以指定标签信息。 PGP签名标签1$ git tag -s &lt;tagname&gt; -m &lt;description&gt; &lt;branchname&gt; or commit_id git tag -s &lt;tagname&gt; -m &quot;blablabla...&quot;可以用PGP签名标签。 查看所有标签1$ git tag 推送一个本地标签1$ git push origin &lt;tagname&gt; 推送全部未推送过的本地标签1$ git push origin --tags 删除一个本地标签1$ git tag -d &lt;tagname&gt; 删除一个远程标签1$ git push origin :refs/tags/&lt;tagname&gt;","categories":[{"name":"工具","slug":"工具","permalink":"http://github.com/categories/工具/"}],"tags":[{"name":"git","slug":"git","permalink":"http://github.com/tags/git/"}]},{"title":"Markdown语法","slug":"Markdown语法","date":"2018-04-12T02:39:01.000Z","updated":"2018-04-12T03:29:16.648Z","comments":true,"path":"2018/04/12/Markdown语法/","link":"","permalink":"http://github.com/2018/04/12/Markdown语法/","excerpt":"针对中文,演示Markdown的语法 大标题 大标题一般显示工程名，类似html的h1 你只要在标题下面跟上=====即可（超过3个=即可，长度不限） 或者你可以在标题前面加一个 # 来实现（# 大标题）","text":"针对中文,演示Markdown的语法 大标题 大标题一般显示工程名，类似html的h1 你只要在标题下面跟上=====即可（超过3个=即可，长度不限） 或者你可以在标题前面加一个 # 来实现（# 大标题） 中标题 中标题一般显示重点项，类似html的h2 你只要在标题下面输入—–即可（超过3个-即可，长度不限） 或者你可以在标题前面加两个 # 来实现（## 中标题） 小标题 小标题类似html的h3 你只要在标题前面加三个 # 即可（### 小标题） 注意，下面所有语法的提示我都先用小标题提醒了！ 四级标题五级标题六级标题 四、五、六级标题类似html的h4、h5、h6 由前面类推，你只要在标题前面加四个、五个、六个 # 来实现 水平标尺 你只要在一个空行画上—–即可（超过3个-即可，长度不限） 但注意，前一行不能有纯文字，否者会当作中标题处理！ 文本框这是一个有多行的文本框 常用来在这里写入代码 只要每行文字前面输入一个Tab（或四个空格） 再输入文字，即可实现效果 比如我们可以在多行文本框里输入一段代码,来一个C++版本的HelloWorld吧 #include &lt;iostream&gt; using namespace std; int main(){ cout&lt;&lt;&quot;HelloWorld!&quot;&lt;&lt;endl; return 0; } 代码块 书写示例： 1234// 代码区域的上下分别用三个 ` 括起来public class Person &#123; // 代码缩进请使用 四个空格，不要使用 Tab&#125; 效果： 1234// 代码区域的上下分别用三个 ` 括起来public class Person &#123; // 代码缩进请使用 四个空格，不要使用 Tab&#125; 链接1.点击这里你可以链接到Google2.点击这里我你可以链接到我的GitHub链接插入的格式是：[链接的显示文字](链接URL) 图片图片插入的格式是：![图像替代文本](图片URL “图片说明文字”) 图片链接比如我想点击GitHub的图片，然后再进入GitHub首页图片链接插入的格式是：![[图像替代文本](图片URL “图片说明文字”)](链接URL) 引用 段落前面用竖线来框定要引用的文字只要再文字前面加上&gt; 即可但&gt; 只能放在行首才有效 多重引用 段落前面用竖线来框定要引用的文字 只要再文字前面加上&gt; 即可 但&gt; 只能放在行首才有效 无序列表 在行首加点 行首输入* 再空格，输入内容即可 有序列表 在行首加数字标号 行首输入数字和一个点（2.） 再空格，输入内容即可 二级列表（不带序号）书写示例： 1234- 列表 1（一级列表：减号 + 空格） - 列表 1.1（二级列表：四个空格 + 减号 + 空格） - 列表 1.2- 列表 2 效果： 列表 1（一级列表：减号 + 空格） 列表 1.1（二级列表：四个空格 + 减号 + 空格） 列表 1.2 列表 2 二级列表（带序号）书写示例： 1234- 列表（一级列表：减号 + 空格） 1. 列表（二级列表：四个空格 + 序号 + 点 + 空格） 2. 列表- 列表 2 效果： 列表 1（一级列表：减号 + 空格） 列表（二级列表：四个空格 + 自然数 + 点 + 空格） 列表 列表 2 字体 斜体只需要在要加斜体的文字前后各加上一个*号即可（*要加斜体的文字*） 粗体只需要在要加粗体的文字前后各加上两个*号即可（**要加粗体的文字**） 特殊字符有一些特殊字符如&lt;,#等,只要在特殊字符前面加上转义字符\\即可你想换行的话其实可以直接用html标签\\ 换行书写示例： 12我是第一行（后面有两个空格） 我是第二行 效果： 我是第一行（后面有两个空格）我是第二行 标亮书写示例： 1`请把我标亮` 效果： 请把我标亮 表格书写示例： 1234567|Prefix |Framework ||--------|------------||NS |Foundation (OS X and iOS) and Application Kit (OS X) ||UI |UIKit (iOS) ||AB |Address Book ||CA |Core Animation ||CI |Core Image | 效果： Prefix Framework NS Foundation (OS X and iOS) and Application Kit (OS X) UI UIKit (iOS) AB Address Book CA Core Animation CI Core Image 免费编辑器Windows 平台MarkdownPadhttp://markdownpad.com Mac 平台MacDownhttp://macdown.uranusjr.com/ 注：不推荐 Mou，原因 文件大了超级卡。","categories":[{"name":"工具","slug":"工具","permalink":"http://github.com/categories/工具/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://github.com/tags/Markdown/"}]},{"title":"【machine Learning】机器学习(一)","slug":"【machine Learning】机器学习(一)","date":"2018-04-11T08:00:08.000Z","updated":"2018-04-14T15:34:33.905Z","comments":true,"path":"2018/04/11/【machine Learning】机器学习(一)/","link":"","permalink":"http://github.com/2018/04/11/【machine Learning】机器学习(一)/","excerpt":"科学算法库的安装(linux) 1.安装Numpysudo apt-get install python-numpy 2.安装Scipysudo apt-get install python-numpy 3.Matplotlibsudo apt-get install tk-dev sudo apt-get install python-gtk2-dev sudo apt-get install python-pyside 4.spyder GUI环境sudo apt-get install spyder","text":"科学算法库的安装(linux) 1.安装Numpysudo apt-get install python-numpy 2.安装Scipysudo apt-get install python-numpy 3.Matplotlibsudo apt-get install tk-dev sudo apt-get install python-gtk2-dev sudo apt-get install python-pyside 4.spyder GUI环境sudo apt-get install spyder 上述安装完毕后，可以利用 1234567891011#! /usr/bin/pythonimport numpy as npimport matplotlib.pyplot as pltx = np.linspace(0,4*3.1415,100)y = np.sin(x)plt.figure(figsize=(8,4))plt.plot(x,y,label=\"$sin(x)$\",color=\"red\",linewidth=2)plt.legend()plt.show() 进行测试。若生成正弦曲线窗口，则配置完成. NumPy的基本操作 Numpy 的导入import numpy as np 这种写法在使用相关函数的时候需要写明是哪个包的，如: myZero = np.zeros([3,5]) 还可以导入包全局使用 from numpy import * NumPy 的基本操作 创建全0矩阵和全1矩阵 12myZero = zeros([n,m])myOne = ones([n,m]) 生成随机矩阵 1myRand = random.rand(n,m) # n 行 m 列的 0～1 之间的随机数矩阵 生成单位矩阵 1myEye = eye(n) # n * n 的单位阵 将一个数组转化为一个矩阵 1myMatrix = mat([[1,2,3],[4,5,6],[7,8,9]]) 矩阵所有元素求和 1S = sum(myMatrix) 矩阵各元素的乘积 1matrix = multiply(matrix1, matrix2) # matrix1 和 matrix2 对应元素相乘的矩阵 求矩阵的 n 次幂 1matrix = power(myMatrix, n) #生成一个矩阵，矩阵内部的元素是原矩阵对应元素的n次幂 矩阵的转置 12print matrix.T #打印转置后的矩阵，不改变原矩阵matrix.transpose() #同上 矩阵的其他操作 1234567[m, n] = shape(matrix) # m, n为矩阵的行列数myscl1 = matrix[0] # 矩阵的切片操作，取第一行myscl2 = matrix.T[0] # 矩阵的切片操作，取第一列mycpmat = matrix.copy() # 矩阵的复制print matrix1 &lt; matrix2 # 矩阵的比较，会逐一比较对应的每一个元素，并输出一个仅包含True, False 的相同大小的矩阵dot(m1,m2) #计算m1,m2的点积norm(v) #计算向量V的范数 Linalg线性代数库 矩阵的行列式 1print linalg.det(matrix) 矩阵的逆 1print linalg.inv(matrix) 矩阵的对称 1print matrix * matrix.T 矩阵的秩 1print linalg.matrix_rank(A) 可逆矩阵求解 1print linalg.solve(A,b.T) # 如果b已经是一列的就不用转置了 各类距离的python实现 各类距离会在后面说明 Euclidean Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print sqrt((vector1-vector2)*(vector1-vector2).T) Manhattan Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print sum(abs(vector1-vector2)) Chebyshev Distance 123vector1 = mat([1,2,3])vector2 = mat([4,5,6])print abs(vector1-vector2).max() Cosine 12cosV12 = dot(vector1,vector2)/(linalg.norm(vector1)*linalg.norm(vector2))print cosV12 Hamming Distance 123matV = mat([[1,1,0,1,0,1,0,0,1], [0,1,1,0,0,0,1,1,1]])smstr = nonzero(matV[0] - matV[1]);print shape(smstr[0])[1] Jaccard Distance 123import scipy.spatial.distance as distmatV = mat([[1,1,0,1,0,1,0,0,1], [0,1,1,0,0,0,1,1,1]])print dist.pdist(matV, 'jaccard') 机器学习的数学基础 范数 向量的范数可以简单、形象的理解为向量的长度，或者向量到坐标系原点的距离，或者相应空间内的两点之间的距离 向量的范数定义 : 向量的范数是一个函数 $ \\parallel x\\parallel $ ,满足非负性 $ \\parallel x\\parallel &gt; 0 $ , 齐次性 $ \\parallel cx\\parallel = \\mid c\\mid\\parallel x\\parallel $ ,三角不等式 $ \\parallel x+y\\parallel \\leq\\parallel x\\parallel +\\parallel y\\parallel $ 。 L1范数： $\\parallel x\\parallel $为 $ x $向量各个元素绝对值之和。L2范数： $\\parallel x\\parallel $为 $ x $向量各个元素平方和的开方，又称 Euclidean 范数或者 Frobenius 范数。Lp范数： $\\parallel x\\parallel $为 $ x $向量各个元素绝对值 $ p $次方和的 $ 1\\over p $ 次方L $\\infty $范数： $\\parallel x\\parallel $为 $ x $向量各个元素绝对值最大的那个元素，如下：$$ \\lim_{k\\to\\infty}\\left( \\sum_{i=1}^n\\mid p_i-q_i\\mid ^k\\right)^\\frac{1}{k}$$ Minkowski Distance (闵可夫斯基距离) 严格意义上讲，Minkowski Distance 不是一种距离，而是一组距离的定义。两个n维向量 $ A(x_{11},x_{12},\\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\\cdots,x_{2n}) $ 间的Minkowski距离定义为：$$ d_{12}=\\sqrt[p]{\\sum_{k=1}^n(x_{1k}-x_{2k})^p} $$其中p是一个变参数。 当 p=1 时，就是 Manhattan Distance (曼哈顿距离) 当 p=2 时，就是 Euclidean Distance (欧氏距离) 当 $ p\\to\\infty $ 时，就是 Chebyshev Distance (切比雪夫距离) Euclideam Distance 欧氏距离（L2范数）是最易于理解的一种距离计算方法，源于欧氏空间的两点距离公式两个n维向量 $ A(x_{11},x_{12},\\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\\cdots,x_{2n}) $ 之间的欧氏距离：$$ d_{12}=\\sqrt{\\sum_{k=1}^n(x_{1k}-x_{2k})^2} $$表示为向量运算的形式：$$ d_{12}=\\sqrt{(A - B)(A - B)^T} $$ Manhattan Distance 曼哈顿距离（L1范数）可以理解为计算网格中两点路径的距离二维平面两点 $ A(x_1,y_1) $ 和 $ B(x_2,y_2) $ 间的曼哈顿距离:$$ d_{12}=\\mid x_1-x_2\\mid +\\mid y_1-y_2\\mid $$两个n维向量 $ A(x_{11},x_{12},\\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\\cdots,x_{2n}) $ 之间的曼哈顿距离：$$ d_{12}=\\sum_{k=1}^n\\mid x_{1k}-x_{2k}\\mid $$ Chebyshev Distance 切比雪夫距离类似与棋盘上国王从一点到另一点移动的最少次数，即 $ max(\\mid x_1-x_2\\mid,\\mid y_1-y_2\\mid) $两个n维向量 $ A(x_{11},x_{12},\\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\\cdots,x_{2n}) $ 之间的切比雪夫距离：$$ d_{12}=max_i(\\mid x_{1i}-x_{2i}\\mid) $$该公式的另一个等价公式：$$ d_{12}=\\lim_{k\\to\\infty}\\left(\\sum_{i=1}^n\\mid x_{1i}-x_{2i}\\mid^k\\right)^\\frac{1}{k} $$ Cosine 夹角余弦可以用来两个向量方向的差异，机器学习中借用这一概念来衡量样本之间的差异两个n维向量 $ A(x_{11},x_{12},\\cdots,x_{1n}) $ 与 $ B(x_{21},x_{22},\\cdots,x_{2n}) $ 之间的夹角余弦：$$ \\cos\\theta=\\frac{AB}{\\mid A\\mid\\mid B\\mid} $$即：$$ \\cos\\theta=\\frac{\\sum_{k=1}^nx_{1k}x_{2k}}{\\sqrt{\\sum_{k=1}^nx_{1k}^2}\\sqrt{\\sum_{k=1}^nx_{2k}^2}} $$ Hamming Distance 汉明距离的定义：两个等长字符串s1,s2,将其中一个变成另一个需要的最小替换次数。应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大） Jaccard Similarity Coefficient(杰卡德相似系数) 杰卡德相似系数：两个集合A,B的交集元素在并集元素中所占的比例，用符号 $ J(A,B) $ 表示$$ J(A,B)=\\frac{\\mid A\\cap B\\mid}{\\mid A\\cup B\\mid} $$杰卡德距：与杰卡德相似系数相反的概念：$$ J_\\delta(A,B)=1-J(A,B)=\\frac{\\mid A\\cup B\\mid-\\mid A\\cap B\\mid}{\\mid A\\cup B\\mid} $$ 特征间的相关性 相关系数与相关距离 相关系数： $$ \\rho_{XY}=\\frac{Cov(X,Y)}{\\sqrt{D(X)}\\sqrt{D(Y)}}=\\frac{E((X-EX)(Y-EY))}{\\sqrt{D(X)}\\sqrt{D(Y)}} $$ 相关距离： $$ D_{XY}=1-\\rho_{XY} $$python实现： 12345678910featuremat = mat(...) # 初始化矩阵# 计算均值mv1 = mean(featuremat[0]) # 计算第一列的均值mv2 = mean(featuremat[1]) # 计算第二列的均值#计算两列的标准差dv1 = std(featuremat[0])dv2 = std(featuremat[1])corref = mean(multiply(featuremat[0]-mv1,featuremat[1]-mv2))/(dv1*dv2)print corref #输出相关系数print corrcoef(featuremat) #输出相关系数矩阵 马氏距离","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://github.com/categories/Machine-Learning/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://github.com/tags/机器学习/"},{"name":"Python","slug":"Python","permalink":"http://github.com/tags/Python/"}]},{"title":"【Machine Learning】机器学习：简明入门指南","slug":"【Machine Learning】机器学习：简明入门指南","date":"2017-10-11T08:00:08.000Z","updated":"2018-04-11T06:07:49.209Z","comments":true,"path":"2017/10/11/【Machine Learning】机器学习：简明入门指南/","link":"","permalink":"http://github.com/2017/10/11/【Machine Learning】机器学习：简明入门指南/","excerpt":"本文是一篇转载自伯乐在线的译文，英文原文是这里：Machine Learning is Fun! — by Adam Geitgey 在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！ 本指南的读者对象是所有对机器学习有求知欲但却不知道如何开头的朋友。我猜很多人已经读过了“机器学习” ——维基百科词条，倍感挫折，以为没人能给出一个高层次的解释。本文就是你们想要的东西。 本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于ML更感兴趣，任务也就完成了。","text":"本文是一篇转载自伯乐在线的译文，英文原文是这里：Machine Learning is Fun! — by Adam Geitgey 在听到人们谈论机器学习的时候，你是不是对它的涵义只有几个模糊的认识呢？你是不是已经厌倦了在和同事交谈时只能一直点头？让我们改变一下吧！ 本指南的读者对象是所有对机器学习有求知欲但却不知道如何开头的朋友。我猜很多人已经读过了“机器学习” ——维基百科词条，倍感挫折，以为没人能给出一个高层次的解释。本文就是你们想要的东西。 本文目标在于平易近人，这意味着文中有大量的概括。但是谁在乎这些呢？只要能让读者对于ML更感兴趣，任务也就完成了。 何为机器学习？机器学习这个概念认为，对于待解问题，你无需编写任何专门的程序代码，遗传算法（generic algorithms）能够在数据集上为你得出有趣的答案。对于遗传算法，不用编码，而是将数据输入，它将在数据之上建立起它自己的逻辑。 举个例子，有一类算法称为分类算法，它可以将数据划分为不同的组别。一个用来识别手写数字的分类算法，不用修改一行代码，就可以用来将电子邮件分为垃圾邮件和普通邮件。算法没变，但是输入的训练数据变了，因此它得出了不同的分类逻辑。 机器学习算法是个黑盒，可以重用来解决很多不同的分类问题。 “机器学习”是一个涵盖性术语，覆盖了大量类似的遗传算法。 两类机器学习算法你可以认为机器学习算法分为两大类：监督式学习（Supervised Learning）和非监督式学习（Unsupervised Learning）。两者区别很简单，但却非常重要。 监督式学习假设你是一名房产经纪，生意越做越大，因此你雇了一批实习生来帮你。但是问题来了——你可以看一眼房子就知道它到底值多少钱，实习生没有经验，不知道如何估价。 为了帮助你的实习生（也许是为了解放你自己去度个假），你决定写个小软件，可以根据房屋大小、地段以及类似房屋的成交价等因素来评估你所在地区房屋的价值。 你把3个月来城里每笔房屋交易都写了下来，每一单你都记录了一长串的细节——卧室数量、房屋大小、地段等等。但最重要的是，你写下了最终的成交价： 这是我们的“训练数据”: 我们要利用这些训练数据来编写一个程序来估算该地区其他房屋的价值： 这就称为监督式学习。你已经知道每一栋房屋的售价，换句话说，你知道问题的答案，并可以反向找出解题的逻辑。 为了编写软件，你将包含每一套房产的训练数据输入你的机器学习算法。算法尝试找出应该使用何种运算来得出价格数字。 这就像是算术练习题，算式中的运算符号都被擦去了：天哪！一个阴险的学生将老师答案上的算术符号全擦去了。 看了这些题，你能明白这些测验里面是什么样的数学问题吗？你知道，你应该对算式左边的数字“做些什么”以得出算式右边的答案。 在监督式学习中，你是让计算机为你算出数字间的关系。而一旦你知道了解决这类特定问题所需要的数学方法后，你就可以解答同类的其它问题了。 非监督式学习让我们回到开头那个房地产经纪的例子。要是你不知道每栋房子的售价怎么办？即使你所知道的只是房屋的大小、位置等信息，你也可以搞出很酷的花样。这就是所谓的非监督式学习。 即使你不是想去预测未知的数据（如价格），你也可以运用机器学习完成一些有意思的事。 这就有点像有人给你一张纸，上面列出了很多数字，然后对你说:“我不知道这些数字有什么意义，也许你能从中找出规律或是能将它们分类，或是其它什么-祝你好运！” 你该怎么处理这些数据呢？首先，你可以用个算法自动地从数据中划分出不同的细分市场。也许你会发现大学附近的买房者喜欢户型小但卧室多的房子，而郊区的买房者偏好三卧室的大户型。这些信息可以直接帮助你的营销。 你还可以作件很酷的事，自动找出房价的离群数据，即与其它数据迥异的值。这些鹤立鸡群的房产也许是高楼大厦，而你可以将最优秀的推销员集中在这些地区，因为他们的佣金更高。 本文余下部分我们主要讨论监督式学习，但这并不是因为非监督式学习用处不大或是索然无味。实际上，随着算法改良，不用将数据和正确答案联系在一起，因此非监督式学习正变得越来越重要。 老学究请看:还有很多其它种类的机器学习算法。但初学时这样理解不错了。 太酷了，但是评估房价真能被看作“学习”吗？作为人类的一员，你的大脑可以应付绝大多数情况，并且没有任何明确指令也能够学习如何处理这些情况。如果你做房产经纪时间很长，你对于房产的合适定价、它的最佳营销方式以及哪些客户会感兴趣等等都会有一种本能般的“感觉”。强人工智能（Strong AI）研究的目标就是要能够用计算机复制这种能力。 但是目前的机器学习算法还没有那么好——它们只能专注于非常特定的、有限的问题。也许在这种情况下，“学习”更贴切的定义是“在少量范例数据的基础上找出一个等式来解决特定的问题”。 不幸的是，“机器在少量范例数据的基础上找出一个等式来解决特定的问题”这个名字太烂了。所以最后我们用“机器学习”取而代之。 当然，要是你是在50年之后来读这篇文章，那时我们已经得出了强人工智能算法，而本文看起来就像个老古董。未来的人类，你还是别读了，叫你的机器仆人给你做份三明治吧。 让我们写代码吧!前面例子中评估房价的程序，你打算怎么写呢？往下看之前，先思考一下吧。 如果你对机器学习一无所知，很有可能你会尝试写出一些基本规则来评估房价，如下： 123456789101112131415161718192021222324252627def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # In my area, the average house costs $200 per sqft price_per_sqft = 200 if neighborhood == \"hipsterton\": # but some areas cost a bit more price_per_sqft = 400 elif neighborhood == \"skid row\": # and some areas cost less price_per_sqft = 100 # start with a base price estimate based on how big the place is price = price_per_sqft * sqft # now adjust our estimate based on the number of bedrooms if num_of_bedrooms == 0: # Studio apartments are cheap price = price — 20000 else: # places with more bedrooms are usually # more valuable price = price + (num_of_bedrooms * 1000) return price 假如你像这样瞎忙几个小时，也许会取得一点成效，但是你的程序永不会完美，而且当价格变化时很难维护。 如果能让计算机找出实现上述函数功能的办法，这样岂不更好？只要返回的房价数字正确，谁会在乎函数具体干了些什么呢？ 1234def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = &lt;computer, plz do some math for me&gt; return price 考虑这个问题的一种角度是将房价看做一碗美味的汤，而汤中成分就是卧室数、面积和地段。如果你能算出每种成分对最终的价格有多大影响，也许就能得到各种成分混合起来形成最终价格的具体比例。 这样可以将你最初的程序（全是疯狂的if else语句）简化成类似如下的样子： 12345678910111213141516def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # a little pinch of this price += num_of_bedrooms * .841231951398213 # and a big pinch of that price += sqft * 1231.1231231 # maybe a handful of this price += neighborhood * 2.3242341421 # and finally, just a little extra salt for good measure price += 201.23432095 return price 请注意那些用粗体标注的神奇数字——.841231951398213, 1231.1231231,2.3242341421, 和201.23432095。它们称为权重。如果我们能找出对每栋房子都适用的完美权重，我们的函数就能预测所有的房价！ 找出最佳权重的一种笨办法如下所示： 步骤1：首先，将每个权重都设为1.0： 12345678910111213141516def estimate_house_sales_price(num_of_bedrooms, sqft, neighborhood): price = 0 # a little pinch of this price += num_of_bedrooms * 1.0 # and a big pinch of that price += sqft * 1.0 # maybe a handful of this price += neighborhood * 1.0 # and finally, just a little extra salt for good measure price += 1.0 return price 步骤2：将每栋房产带入你的函数运算，检验估算值与正确价格的偏离程度： 运用你的程序预测房屋价格。 例如：上表中第一套房产实际成交价为25万美元，你的函数估价为17.8万，这一套房产你就差了7.2万。 再将你的数据集中的每套房产估价偏离值平方后求和。假设数据集中有500套房产交易，估价偏离值平方求和总计为86,123,373美元。这就反映了你的函数现在的“正确”程度。 现在，将总计值除以500，得到每套房产的估价偏离平均值。将这个平均误差值称为你函数的代价。 如果你能调整权重使得这个代价变为0，你的函数就完美了。它意味着，根据输入的数据，你的程序对每一笔房产交易的估价都是分毫不差。而这就是我们的目标——尝试不同的权重值以使代价尽可能的低。 步骤3：不断重复步骤2，尝试所有可能的权重值组合。哪一个组合使得代价最接近于0，它就是你要使用的，你只要找到了这样的组合，问题就得到了解决! 思想扰动时间这太简单了，对吧？想一想刚才你做了些什么。你取得了一些数据，将它们输入至三个通用的简单步骤中，最后你得到了一个可以对你所在区域的房屋进行估价的函数。房价网，要当心咯！但是下面的事实可能会扰乱你的思想： 1.过去40年来，很多领域（如语言学/翻译学）的研究表明，这种通用的“搅动数据汤”（我编造的词）式的学习算法已经胜过了需要利用真人明确规则的方法。机器学习的“笨”办法最终打败了人类专家。 2.你最后写出的函数真是笨，它甚至不知道什么是“面积”和“卧室数”。它知道的只是搅动，改变数字来得到正确的答案。 3.很可能你都不知道为何一组特殊的权重值能起效。所以你只是写出了一个你实际上并不理解却能证明的函数。 4.试想一下，你的程序里没有类似“面积”和“卧室数”这样的参数，而是接受了一组数字。假设每个数字代表了你车顶安装的摄像头捕捉的画面中的一个像素，再将预测的输出不称为“价格”而是叫做“方向盘转动度数”，这样你就得到了一个程序可以自动操纵你的汽车了！ 太疯狂了，对吧？ 步骤3中的“尝试每个数字”怎么回事？好吧，当然你不可能尝试所有可能的权重值来找到效果最好的组合。那可真要花很长时间，因为要尝试的数字可能无穷无尽。 为避免这种情况，数学家们找到了很多聪明的办法（比如Gradient descent算法）来快速找到优秀的权重值，而不需要尝试过多。下面是其中一种： 首先，写出一个简单的等式表示前述步骤2，这是你的代价函数： 接着，让我们将这同一个等式用机器学习的数学术语（现在你可以忽略它们）进行重写： θ表示当前的权重值。 J(θ) 意为“当前权重值对应的代价”。 这个等式表示我们的估价程序在当前权重值下偏离程度的大小。如果将所有赋给卧室数和面积的可能权重值以图形形式显示，我们会得到类似下图的图表： 代价函数的图形像一支碗。纵轴表示代价。 图中蓝色的最低点就是代价最低的地方——即我们的程序偏离最小。最高点意味着偏离最大。所以，如果我们能找到一组权重值带领我们到达图中的最低点，我们就找到了答案！ 因此，我们只需要调整权重值使我们在图上能向着最低点“走下坡路”。如果对于权重的细小调节能一直使我们保持向最低点移动，那么最终我们不用尝试太多权重值就能到达那里。 如果你还记得一点微积分的话，你也许记得如果你对一个函数求导，结果会告诉你函数在任一点的斜率。换句话说，对于图上给定一点，它告诉我们那条路是下坡路。我们可以利用这一点朝底部进发。 所以，如果我们对代价函数关于每一个权重求偏导，那么我们就可以从每一个权重中减去该值。这样可以让我们更加接近山底。一直这样做，最终我们将到达底部，得到权重的最优值。（读不懂？不用担心，接着往下读）。 这种找出最佳权重的办法被称为批量梯度下降，上面是对它的高度概括。如果想搞懂细节，不要害怕，继续深入下去吧。 当你使用机器学习算法库来解决实际问题，所有这些都已经为你准备好了。但明白一些具体细节总是有用的。 还有什么你随便就略过了？上面我描述的三步算法被称为多元线性回归。你估算等式是在求一条能够拟合所有房价数据点的直线。然后，你再根据房价在你的直线上可能出现的位置用这个等式来估算从未见过的房屋的价格。这个想法威力强大，可以用它来解决“实际”问题。 但是，我为你展示的这种方法可能在简单的情况下有效，它不会在所有情况下都有用。原因之一是因为房价不会一直那么简单地跟随一条连续直线。 但是，幸运的是，有很多办法来处理这种情况。对于非线性数据，很多其他类型的机器学习算法可以处理（如神经网络或有核向量机）。还有很多方法运用线性回归更灵活，想到了用更复杂的线条来拟合。在所有的情况中，寻找最优权重值这一基本思路依然适用。 还有，我忽略了过拟合的概念。很容易碰上这样一组权重值，它们对于你原始数据集中的房价都能完美预测，但对于原始数据集之外的任何新房屋都预测不准。这种情况的解决之道也有不少（如正则化以及使用交叉验证数据集）。学会如何处理这一问题对于顺利应用机器学习至关重要。 换言之，基本概念非常简单，要想运用机器学习得到有用的结果还需要一些技巧和经验。但是，这是每个开发者都能学会的技巧。 机器学习法力无边吗？一旦你开始明白机器学习技术很容易应用于解决貌似很困难的问题（如手写识别），你心中会有一种感觉，只要有足够的数据，你就能够用机器学习解决任何问题。只需要将数据输入进去，就能看到计算机变戏法一样找出拟合数据的等式。 但是很重要的一点你要记住，机器学习只能对用你占有的数据实际可解的问题才适用。 例如，如果你建立了一个模型来根据每套房屋内盆栽数量来预测房价，它就永远不会成功。房屋内盆栽数量和房价之间没有任何的关系。所以，无论它怎么去尝试，计算机也推导不出两者之间的关系。 你只能对实际存在的关系建模。 怎样深入学习机器学习我认为，当前机器学习的最大问题是它主要活跃于学术界和商业研究组织中。对于圈外想要有个大体了解而不是想成为专家的人们，简单易懂的学习资料不多。但是这一情况每一天都在改善。 吴恩达教授（Andrew Ng）在Coursera上的机器学习免费课程非常不错。我强烈建议由此入门。任何拥有计算机科学学位、还能记住一点点数学的人应该都能理解。 另外，你还可以下载安装SciKit-Learn，用它来试验成千上万的机器学习算法。它是一个python框架，对于所有的标准算法都有“黑盒”版本。","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://github.com/categories/Machine-Learning/"}],"tags":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://github.com/tags/Machine-Learning/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-09-22T11:48:15.570Z","updated":"2018-04-12T03:30:36.790Z","comments":true,"path":"2017/09/22/hello-world/","link":"","permalink":"http://github.com/2017/09/22/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}